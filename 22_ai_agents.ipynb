{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 7.2: AI Agents and Tool Use\n",
    "\n",
    "An LLM that can only generate text is like a brilliant advisor locked in a room â€” full of knowledge but unable to *do* anything. **AI agents** break out of this limitation by giving LLMs the ability to take actions: search the web, execute code, call APIs, and interact with the world through **tools**.\n",
    "\n",
    "Agent architectures are behind the most capable AI systems today â€” from coding assistants that edit files and run tests, to research agents that browse the web and synthesize findings. Understanding agents means understanding how AI goes from \"answering questions\" to \"completing tasks.\"\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "- [ ] Understand the agent paradigm: observe, reason, act, repeat\n",
    "- [ ] Implement tool definitions and a tool execution framework\n",
    "- [ ] Build a ReAct (Reasoning + Acting) agent from scratch\n",
    "- [ ] Understand chain-of-thought reasoning and why it improves agent performance\n",
    "- [ ] Implement multi-step planning and execution\n",
    "- [ ] Build a simple code-execution agent\n",
    "- [ ] Understand agent failure modes and safety considerations\n",
    "- [ ] Compare single-turn vs. multi-turn agent architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import json\n",
    "import re\n",
    "import math\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Part 7.2: AI Agents and Tool Use\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. What is an AI Agent?\n",
    "\n",
    "An **agent** is a system that uses an LLM as its reasoning engine to:\n",
    "1. **Observe** the current state (user request, tool outputs, environment)\n",
    "2. **Reason** about what to do next (chain-of-thought)\n",
    "3. **Act** by calling tools or generating responses\n",
    "4. **Repeat** until the task is complete\n",
    "\n",
    "### Agent vs. Chatbot\n",
    "\n",
    "| Feature | Chatbot | Agent |\n",
    "|---------|---------|-------|\n",
    "| **Interaction** | Single response per turn | Multi-step execution |\n",
    "| **Tools** | None (text only) | Can call APIs, run code, search |\n",
    "| **Planning** | React to each message | Plan ahead, decompose tasks |\n",
    "| **State** | Conversation history | + tool outputs, environment state |\n",
    "| **Autonomy** | User drives every step | Agent decides what to do next |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization: The Agent Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n",
    "ax.set_xlim(0, 12)\n",
    "ax.set_ylim(0, 10)\n",
    "ax.axis('off')\n",
    "ax.set_title('The AI Agent Loop', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Central LLM\n",
    "circle = plt.Circle((6, 5), 1.5, color='#3498db', alpha=0.9, zorder=5)\n",
    "ax.add_patch(circle)\n",
    "ax.text(6, 5.2, 'LLM', ha='center', va='center', fontsize=16,\n",
    "        fontweight='bold', color='white')\n",
    "ax.text(6, 4.6, '(Reasoning\\nEngine)', ha='center', va='center', fontsize=9, color='white')\n",
    "\n",
    "# Surrounding components\n",
    "components = [\n",
    "    (2, 8, '1. Observe', '#2ecc71', 'Read user request\\n+ tool outputs'),\n",
    "    (10, 8, '2. Reason', '#9b59b6', 'Chain-of-thought\\nplanning'),\n",
    "    (10, 2, '3. Act', '#e74c3c', 'Call tools or\\ngenerate response'),\n",
    "    (2, 2, '4. Update', '#f39c12', 'Add result to\\ncontext'),\n",
    "]\n",
    "\n",
    "for x, y, label, color, desc in components:\n",
    "    box = mpatches.FancyBboxPatch((x - 1.2, y - 0.5), 2.4, 1, boxstyle=\"round,pad=0.2\",\n",
    "                                   facecolor=color, edgecolor='black', linewidth=2, alpha=0.9)\n",
    "    ax.add_patch(box)\n",
    "    ax.text(x, y, label, ha='center', va='center', fontsize=10,\n",
    "            fontweight='bold', color='white')\n",
    "    ax.text(x, y - 0.9, desc, ha='center', va='center', fontsize=8, color='gray')\n",
    "\n",
    "# Arrows forming a cycle\n",
    "arrow_pairs = [(3.2, 8, 8.8, 8), (10, 7.5, 10, 2.5),\n",
    "               (8.8, 2, 3.2, 2), (2, 2.5, 2, 7.5)]\n",
    "for x1, y1, x2, y2 in arrow_pairs:\n",
    "    ax.annotate('', xy=(x2, y2), xytext=(x1, y1),\n",
    "               arrowprops=dict(arrowstyle='->', lw=2.5, color='gray'))\n",
    "\n",
    "# Tools\n",
    "tools = ['Search', 'Calculator', 'Code Exec', 'API Call']\n",
    "for i, tool in enumerate(tools):\n",
    "    x = 5 + i * 1.8\n",
    "    ax.text(x, 0.5, f'ðŸ”§ {tool}', ha='center', fontsize=9,\n",
    "            bbox=dict(boxstyle='round', facecolor='#ecf0f1', edgecolor='gray'))\n",
    "\n",
    "ax.text(7.8, 1.2, 'Available Tools', ha='center', fontsize=10,\n",
    "        fontweight='bold', color='gray')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Tool Definitions\n",
    "\n",
    "Tools are the agent's interface to the world. Each tool has:\n",
    "- A **name** and **description** (so the LLM knows when to use it)\n",
    "- **Parameters** with types and descriptions\n",
    "- An **execute** function that runs the tool\n",
    "\n",
    "This is the same format used by OpenAI function calling, Anthropic tool use, and most agent frameworks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tool:\n",
    "    \"\"\"Base class for agent tools.\"\"\"\n",
    "    \n",
    "    def __init__(self, name, description, parameters):\n",
    "        self.name = name\n",
    "        self.description = description\n",
    "        self.parameters = parameters  # Dict of {param_name: {type, description}}\n",
    "    \n",
    "    def execute(self, **kwargs):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def schema(self):\n",
    "        \"\"\"Return tool schema (like OpenAI function calling format).\"\"\"\n",
    "        return {\n",
    "            'name': self.name,\n",
    "            'description': self.description,\n",
    "            'parameters': self.parameters\n",
    "        }\n",
    "\n",
    "\n",
    "class CalculatorTool(Tool):\n",
    "    \"\"\"Evaluate mathematical expressions safely.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            name='calculator',\n",
    "            description='Evaluate a mathematical expression. Supports +, -, *, /, **, sqrt, sin, cos, log.',\n",
    "            parameters={'expression': {'type': 'string', 'description': 'Math expression to evaluate'}}\n",
    "        )\n",
    "    \n",
    "    def execute(self, expression):\n",
    "        \"\"\"Safely evaluate a math expression.\"\"\"\n",
    "        # Whitelist of safe operations\n",
    "        allowed = {'sqrt': math.sqrt, 'sin': math.sin, 'cos': math.cos,\n",
    "                   'log': math.log, 'pi': math.pi, 'e': math.e,\n",
    "                   'abs': abs, 'round': round, 'pow': pow}\n",
    "        try:\n",
    "            result = eval(expression, {\"__builtins__\": {}}, allowed)\n",
    "            return {'status': 'success', 'result': result}\n",
    "        except Exception as e:\n",
    "            return {'status': 'error', 'error': str(e)}\n",
    "\n",
    "\n",
    "class SearchTool(Tool):\n",
    "    \"\"\"Simulated web search tool.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            name='search',\n",
    "            description='Search for information on a topic. Returns relevant snippets.',\n",
    "            parameters={'query': {'type': 'string', 'description': 'Search query'}}\n",
    "        )\n",
    "        # Simulated search index\n",
    "        self.knowledge = {\n",
    "            'transformer': 'The Transformer was introduced in 2017 by Vaswani et al. in \"Attention Is All You Need\". It uses self-attention instead of recurrence.',\n",
    "            'attention': 'Self-attention computes Query, Key, Value matrices. Attention(Q,K,V) = softmax(QK^T/sqrt(d_k))V.',\n",
    "            'rlhf': 'RLHF uses three stages: SFT on demonstrations, reward model training on preferences, and PPO optimization.',\n",
    "            'backpropagation': 'Backpropagation computes gradients using the chain rule, propagating error backwards through the network.',\n",
    "            'gpt': 'GPT models are decoder-only transformers trained with autoregressive language modeling. GPT-4 was released in March 2023.',\n",
    "            'embedding': 'Embeddings map discrete tokens to dense vectors. Modern sentence embeddings capture semantic meaning.',\n",
    "            'python': 'Python is a high-level programming language known for its readability. It is widely used in AI/ML.',\n",
    "            'pytorch': 'PyTorch is an open-source deep learning framework developed by Meta. It uses dynamic computation graphs.',\n",
    "        }\n",
    "    \n",
    "    def execute(self, query):\n",
    "        \"\"\"Simulate searching for information.\"\"\"\n",
    "        query_lower = query.lower()\n",
    "        results = []\n",
    "        for key, value in self.knowledge.items():\n",
    "            if key in query_lower or any(word in query_lower for word in key.split()):\n",
    "                results.append({'title': key.title(), 'snippet': value})\n",
    "        \n",
    "        if not results:\n",
    "            return {'status': 'success', 'results': [], 'message': 'No results found.'}\n",
    "        return {'status': 'success', 'results': results[:3]}\n",
    "\n",
    "\n",
    "class LookupTool(Tool):\n",
    "    \"\"\"Look up a specific fact from a knowledge base.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            name='lookup',\n",
    "            description='Look up a specific fact or definition.',\n",
    "            parameters={'term': {'type': 'string', 'description': 'Term to look up'}}\n",
    "        )\n",
    "        self.facts = {\n",
    "            'relu': 'ReLU(x) = max(0, x). Most common activation function in deep learning.',\n",
    "            'softmax': 'softmax(x_i) = exp(x_i) / sum(exp(x_j)). Converts logits to probabilities.',\n",
    "            'adam': 'Adam optimizer combines momentum and RMSprop. Default lr=0.001, betas=(0.9, 0.999).',\n",
    "            'cross entropy': 'Cross-entropy loss: L = -sum(y_i * log(p_i)). Standard for classification.',\n",
    "            'batch normalization': 'Normalizes layer inputs to zero mean, unit variance. Speeds up training.',\n",
    "            'dropout': 'Randomly zeros elements with probability p during training. Regularization technique.',\n",
    "        }\n",
    "    \n",
    "    def execute(self, term):\n",
    "        term_lower = term.lower().strip()\n",
    "        if term_lower in self.facts:\n",
    "            return {'status': 'success', 'definition': self.facts[term_lower]}\n",
    "        # Fuzzy match\n",
    "        for key, value in self.facts.items():\n",
    "            if term_lower in key or key in term_lower:\n",
    "                return {'status': 'success', 'definition': value}\n",
    "        return {'status': 'not_found', 'message': f'No definition found for \"{term}\"'}\n",
    "\n",
    "\n",
    "# Create our tool registry\n",
    "tools = {\n",
    "    'calculator': CalculatorTool(),\n",
    "    'search': SearchTool(),\n",
    "    'lookup': LookupTool(),\n",
    "}\n",
    "\n",
    "print(\"Available tools:\")\n",
    "for name, tool in tools.items():\n",
    "    print(f\"  {name}: {tool.description}\")\n",
    "\n",
    "# Test tools\n",
    "print(\"\\nTool tests:\")\n",
    "print(f\"  calculator('2**10'): {tools['calculator'].execute(expression='2**10')}\")\n",
    "print(f\"  search('transformer'): {tools['search'].execute(query='transformer architecture')}\")\n",
    "print(f\"  lookup('relu'): {tools['lookup'].execute(term='relu')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. The ReAct Pattern\n",
    "\n",
    "**ReAct** (Reasoning + Acting) interleaves chain-of-thought reasoning with tool use:\n",
    "\n",
    "```\n",
    "Thought: I need to find out when the Transformer was introduced.\n",
    "Action: search(\"transformer architecture origin\")\n",
    "Observation: The Transformer was introduced in 2017...\n",
    "Thought: Now I know it was 2017. Let me calculate how many years ago that was.\n",
    "Action: calculator(\"2026 - 2017\")\n",
    "Observation: 9\n",
    "Thought: I have all the information I need.\n",
    "Answer: The Transformer was introduced 9 years ago, in 2017.\n",
    "```\n",
    "\n",
    "The key insight: by verbalizing its reasoning, the agent makes better decisions about *which* tool to use and *when*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReActAgent:\n",
    "    \"\"\"ReAct agent: Reasoning + Acting with tool use.\n",
    "    \n",
    "    Uses a simulated LLM (rule-based) to demonstrate the pattern.\n",
    "    In production, this would be an actual LLM like Claude or GPT-4.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, tools, max_steps=5):\n",
    "        self.tools = tools\n",
    "        self.max_steps = max_steps\n",
    "        self.trace = []  # Full execution trace\n",
    "    \n",
    "    def _simulate_reasoning(self, query, observations):\n",
    "        \"\"\"Simulate LLM reasoning to decide next action.\n",
    "        \n",
    "        In production, this is where you'd call the LLM API.\n",
    "        Here we use heuristics to demonstrate the pattern.\n",
    "        \"\"\"\n",
    "        query_lower = query.lower()\n",
    "        \n",
    "        # If we already have observations, try to answer\n",
    "        if len(observations) >= 2:\n",
    "            return {'type': 'answer', 'content': self._synthesize(query, observations)}\n",
    "        \n",
    "        # Decide which tool to use based on query\n",
    "        if any(word in query_lower for word in ['calculate', 'compute', 'how many', 'what is', 'evaluate'])\\\n",
    "           and any(c in query for c in '0123456789+-*/^'):\n",
    "            # Extract math expression\n",
    "            expr = re.findall(r'[\\d\\+\\-\\*/\\(\\)\\. \\*\\*]+', query)\n",
    "            if expr:\n",
    "                expression = expr[0].strip()\n",
    "                return {\n",
    "                    'type': 'action',\n",
    "                    'thought': f'I need to calculate {expression}.',\n",
    "                    'tool': 'calculator',\n",
    "                    'args': {'expression': expression}\n",
    "                }\n",
    "        \n",
    "        if any(word in query_lower for word in ['what is', 'define', 'explain']):\n",
    "            # Try lookup first\n",
    "            terms = re.findall(r'what is (\\w+(?:\\s+\\w+)?)', query_lower)\n",
    "            if terms and not observations:\n",
    "                return {\n",
    "                    'type': 'action',\n",
    "                    'thought': f'Let me look up the definition of \"{terms[0]}\".',\n",
    "                    'tool': 'lookup',\n",
    "                    'args': {'term': terms[0]}\n",
    "                }\n",
    "        \n",
    "        # Default: search\n",
    "        if not observations:\n",
    "            return {\n",
    "                'type': 'action',\n",
    "                'thought': f'I need to search for information about this topic.',\n",
    "                'tool': 'search',\n",
    "                'args': {'query': query}\n",
    "            }\n",
    "        \n",
    "        return {'type': 'answer', 'content': self._synthesize(query, observations)}\n",
    "    \n",
    "    def _synthesize(self, query, observations):\n",
    "        \"\"\"Synthesize a final answer from observations.\"\"\"\n",
    "        parts = []\n",
    "        for obs in observations:\n",
    "            if isinstance(obs.get('result'), dict):\n",
    "                if 'results' in obs['result']:\n",
    "                    for r in obs['result']['results']:\n",
    "                        parts.append(r.get('snippet', ''))\n",
    "                elif 'definition' in obs['result']:\n",
    "                    parts.append(obs['result']['definition'])\n",
    "                elif 'result' in obs['result']:\n",
    "                    parts.append(f\"Calculation result: {obs['result']['result']}\")\n",
    "        \n",
    "        return ' '.join(parts) if parts else 'I could not find enough information to answer.'\n",
    "    \n",
    "    def run(self, query):\n",
    "        \"\"\"Execute the ReAct loop.\"\"\"\n",
    "        self.trace = []\n",
    "        observations = []\n",
    "        \n",
    "        self.trace.append({'step': 'query', 'content': query})\n",
    "        \n",
    "        for step in range(self.max_steps):\n",
    "            # Reason about what to do\n",
    "            decision = self._simulate_reasoning(query, observations)\n",
    "            \n",
    "            if decision['type'] == 'answer':\n",
    "                self.trace.append({\n",
    "                    'step': 'answer',\n",
    "                    'thought': 'I have enough information to answer.',\n",
    "                    'content': decision['content']\n",
    "                })\n",
    "                return decision['content']\n",
    "            \n",
    "            # Execute tool\n",
    "            tool_name = decision['tool']\n",
    "            tool_args = decision['args']\n",
    "            \n",
    "            self.trace.append({\n",
    "                'step': 'thought',\n",
    "                'content': decision.get('thought', '')\n",
    "            })\n",
    "            self.trace.append({\n",
    "                'step': 'action',\n",
    "                'tool': tool_name,\n",
    "                'args': tool_args\n",
    "            })\n",
    "            \n",
    "            result = self.tools[tool_name].execute(**tool_args)\n",
    "            \n",
    "            self.trace.append({\n",
    "                'step': 'observation',\n",
    "                'result': result\n",
    "            })\n",
    "            \n",
    "            observations.append({'tool': tool_name, 'args': tool_args, 'result': result})\n",
    "        \n",
    "        return self._synthesize(query, observations)\n",
    "    \n",
    "    def show_trace(self):\n",
    "        \"\"\"Display the execution trace.\"\"\"\n",
    "        colors = {'query': '\\033[94m', 'thought': '\\033[93m',\n",
    "                  'action': '\\033[91m', 'observation': '\\033[92m',\n",
    "                  'answer': '\\033[95m'}\n",
    "        reset = '\\033[0m'\n",
    "        \n",
    "        for entry in self.trace:\n",
    "            step = entry['step']\n",
    "            if step == 'query':\n",
    "                print(f\"Query: {entry['content']}\")\n",
    "            elif step == 'thought':\n",
    "                print(f\"  Thought: {entry['content']}\")\n",
    "            elif step == 'action':\n",
    "                args_str = ', '.join(f'{k}=\"{v}\"' for k, v in entry['args'].items())\n",
    "                print(f\"  Action: {entry['tool']}({args_str})\")\n",
    "            elif step == 'observation':\n",
    "                result = entry['result']\n",
    "                result_str = json.dumps(result, indent=None)[:120]\n",
    "                print(f\"  Observation: {result_str}\")\n",
    "            elif step == 'answer':\n",
    "                print(f\"  Thought: {entry.get('thought', '')}\")\n",
    "                print(f\"  Answer: {entry['content'][:200]}\")\n",
    "\n",
    "\n",
    "# Test the ReAct agent\n",
    "agent = ReActAgent(tools)\n",
    "\n",
    "queries = [\n",
    "    \"Tell me about the transformer architecture\",\n",
    "    \"What is relu?\",\n",
    "    \"Tell me about RLHF and how it works\",\n",
    "]\n",
    "\n",
    "for query in queries:\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    answer = agent.run(query)\n",
    "    agent.show_trace()\n",
    "    print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization: ReAct Execution Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a ReAct trace\n",
    "fig, ax = plt.subplots(1, 1, figsize=(14, 6))\n",
    "ax.set_xlim(0, 14)\n",
    "ax.set_ylim(0, 7)\n",
    "ax.axis('off')\n",
    "ax.set_title('ReAct Execution Trace', fontsize=14, fontweight='bold')\n",
    "\n",
    "steps = [\n",
    "    (1, 5.5, 'Query', '#95a5a6', '\"Tell me about\\ntransformers\"'),\n",
    "    (3.5, 5.5, 'Thought', '#f39c12', '\"I need to search\\nfor this topic\"'),\n",
    "    (6, 5.5, 'Action', '#e74c3c', 'search(\"transformer\\narchitecture\")'),\n",
    "    (8.5, 5.5, 'Observation', '#2ecc71', '\"Introduced in 2017\\nby Vaswani et al...\"'),\n",
    "    (11, 5.5, 'Thought', '#f39c12', '\"I have enough\\ninfo to answer\"'),\n",
    "]\n",
    "\n",
    "steps2 = [\n",
    "    (3.5, 2.5, 'Answer', '#9b59b6', '\"The Transformer was\\nintroduced in 2017...\"'),\n",
    "]\n",
    "\n",
    "for x, y, label, color, text in steps + steps2:\n",
    "    box = mpatches.FancyBboxPatch((x - 1, y - 0.6), 2, 1.2, boxstyle=\"round,pad=0.15\",\n",
    "                                   facecolor=color, edgecolor='black', linewidth=1.5, alpha=0.9)\n",
    "    ax.add_patch(box)\n",
    "    ax.text(x, y + 0.2, label, ha='center', va='center', fontsize=9,\n",
    "            fontweight='bold', color='white')\n",
    "    ax.text(x, y - 0.25, text, ha='center', va='center', fontsize=7, color='white')\n",
    "\n",
    "# Arrows\n",
    "for i in range(len(steps) - 1):\n",
    "    ax.annotate('', xy=(steps[i+1][0] - 1, steps[i+1][1]),\n",
    "               xytext=(steps[i][0] + 1, steps[i][1]),\n",
    "               arrowprops=dict(arrowstyle='->', lw=2, color='gray'))\n",
    "\n",
    "# Arrow to answer\n",
    "ax.annotate('', xy=(steps2[0][0], steps2[0][1] + 0.6),\n",
    "           xytext=(steps[-1][0], steps[-1][1] - 0.6),\n",
    "           arrowprops=dict(arrowstyle='->', lw=2, color='gray',\n",
    "                          connectionstyle='arc3,rad=0.3'))\n",
    "\n",
    "# Labels\n",
    "ax.text(7, 4.2, 'Reasoning + Acting Loop', ha='center', fontsize=11,\n",
    "        style='italic', color='gray')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Chain-of-Thought Reasoning\n",
    "\n",
    "**Chain-of-thought (CoT)** prompting dramatically improves reasoning by making the model \"think step by step.\" For agents, CoT serves as the planning mechanism:\n",
    "\n",
    "- **Without CoT**: LLM jumps to an action immediately (often wrong)\n",
    "- **With CoT**: LLM reasons about what it knows, what it needs, then acts\n",
    "\n",
    "### Why CoT Works for Agents\n",
    "\n",
    "1. **Decomposition**: Breaks complex tasks into manageable steps\n",
    "2. **Self-correction**: The model can catch its own errors mid-reasoning\n",
    "3. **Tool selection**: Explicit reasoning helps choose the right tool\n",
    "4. **Transparency**: Users can understand *why* the agent took an action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate CoT benefit with a multi-step problem\n",
    "\n",
    "class PlanningAgent:\n",
    "    \"\"\"Agent that creates an explicit plan before acting.\"\"\"\n",
    "    \n",
    "    def __init__(self, tools):\n",
    "        self.tools = tools\n",
    "    \n",
    "    def plan(self, query):\n",
    "        \"\"\"Create a step-by-step plan (simulated).\"\"\"\n",
    "        query_lower = query.lower()\n",
    "        plan_steps = []\n",
    "        \n",
    "        # Analyze what's needed\n",
    "        needs_search = any(w in query_lower for w in ['tell me', 'how', 'what', 'explain', 'when'])\n",
    "        needs_calc = any(c in query for c in '0123456789+-*/') or 'calculate' in query_lower\n",
    "        needs_lookup = any(w in query_lower for w in ['define', 'definition'])\n",
    "        \n",
    "        if needs_search:\n",
    "            # Extract key topics\n",
    "            topics = [w for w in query_lower.split() if len(w) > 3 and w not in \n",
    "                     {'tell', 'about', 'what', 'how', 'does', 'this', 'that', 'with', 'from'}]\n",
    "            plan_steps.append({\n",
    "                'step': 1,\n",
    "                'description': f'Search for information about: {\", \".join(topics[:3])}',\n",
    "                'tool': 'search',\n",
    "                'args': {'query': ' '.join(topics[:3])}\n",
    "            })\n",
    "        \n",
    "        if needs_lookup:\n",
    "            terms = re.findall(r'define\\s+(\\w+)', query_lower)\n",
    "            if terms:\n",
    "                plan_steps.append({\n",
    "                    'step': len(plan_steps) + 1,\n",
    "                    'description': f'Look up definition of: {terms[0]}',\n",
    "                    'tool': 'lookup',\n",
    "                    'args': {'term': terms[0]}\n",
    "                })\n",
    "        \n",
    "        if needs_calc:\n",
    "            expr = re.findall(r'[\\d\\+\\-\\*/\\(\\)\\. \\*\\*]+', query)\n",
    "            if expr:\n",
    "                plan_steps.append({\n",
    "                    'step': len(plan_steps) + 1,\n",
    "                    'description': f'Calculate: {expr[0].strip()}',\n",
    "                    'tool': 'calculator',\n",
    "                    'args': {'expression': expr[0].strip()}\n",
    "                })\n",
    "        \n",
    "        plan_steps.append({\n",
    "            'step': len(plan_steps) + 1,\n",
    "            'description': 'Synthesize findings into a coherent answer',\n",
    "            'tool': None,\n",
    "            'args': {}\n",
    "        })\n",
    "        \n",
    "        return plan_steps\n",
    "    \n",
    "    def execute_plan(self, query):\n",
    "        \"\"\"Plan then execute.\"\"\"\n",
    "        plan = self.plan(query)\n",
    "        results = []\n",
    "        \n",
    "        print(f\"Query: {query}\")\n",
    "        print(f\"\\nPlan ({len(plan)} steps):\")\n",
    "        for step in plan:\n",
    "            print(f\"  Step {step['step']}: {step['description']}\")\n",
    "        \n",
    "        print(f\"\\nExecution:\")\n",
    "        for step in plan:\n",
    "            if step['tool'] and step['tool'] in self.tools:\n",
    "                result = self.tools[step['tool']].execute(**step['args'])\n",
    "                results.append(result)\n",
    "                print(f\"  Step {step['step']}: {step['tool']}() -> {json.dumps(result)[:100]}\")\n",
    "            else:\n",
    "                print(f\"  Step {step['step']}: Synthesizing answer...\")\n",
    "        \n",
    "        return results\n",
    "\n",
    "\n",
    "planning_agent = PlanningAgent(tools)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "planning_agent.execute_plan(\"Tell me about attention in transformers\")\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "planning_agent.execute_plan(\"What is backpropagation and how does it relate to gradient descent?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Agent Architectures Compared\n",
    "\n",
    "Different agent architectures suit different tasks:\n",
    "\n",
    "| Architecture | Description | Best For |\n",
    "|-------------|-------------|----------|\n",
    "| **ReAct** | Interleave reasoning and acting | General tool use |\n",
    "| **Plan-then-Execute** | Full plan upfront, then execute | Well-defined tasks |\n",
    "| **Reflexion** | Act, evaluate, reflect, retry | Tasks needing self-correction |\n",
    "| **Tree of Thoughts** | Explore multiple reasoning paths | Complex problem solving |\n",
    "| **Multi-Agent** | Multiple specialized agents collaborate | Complex workflows |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize agent architecture comparison\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# ReAct: Linear interleave\n",
    "ax = axes[0]\n",
    "ax.set_xlim(0, 4)\n",
    "ax.set_ylim(0, 8)\n",
    "ax.axis('off')\n",
    "ax.set_title('ReAct', fontsize=13, fontweight='bold')\n",
    "\n",
    "react_steps = [\n",
    "    (2, 7, 'Think', '#f39c12'),\n",
    "    (2, 5.5, 'Act', '#e74c3c'),\n",
    "    (2, 4, 'Observe', '#2ecc71'),\n",
    "    (2, 2.5, 'Think', '#f39c12'),\n",
    "    (2, 1, 'Answer', '#9b59b6'),\n",
    "]\n",
    "for x, y, label, color in react_steps:\n",
    "    box = mpatches.FancyBboxPatch((x - 0.8, y - 0.35), 1.6, 0.7,\n",
    "                                   boxstyle=\"round,pad=0.1\", facecolor=color,\n",
    "                                   edgecolor='black', linewidth=1.5)\n",
    "    ax.add_patch(box)\n",
    "    ax.text(x, y, label, ha='center', va='center', fontsize=10, fontweight='bold', color='white')\n",
    "\n",
    "for i in range(len(react_steps) - 1):\n",
    "    ax.annotate('', xy=(2, react_steps[i+1][1] + 0.35),\n",
    "               xytext=(2, react_steps[i][1] - 0.35),\n",
    "               arrowprops=dict(arrowstyle='->', lw=1.5, color='gray'))\n",
    "\n",
    "# Plan-then-Execute\n",
    "ax = axes[1]\n",
    "ax.set_xlim(0, 4)\n",
    "ax.set_ylim(0, 8)\n",
    "ax.axis('off')\n",
    "ax.set_title('Plan-then-Execute', fontsize=13, fontweight='bold')\n",
    "\n",
    "box = mpatches.FancyBboxPatch((0.5, 6), 3, 1.2, boxstyle=\"round,pad=0.1\",\n",
    "                               facecolor='#f39c12', edgecolor='black', linewidth=1.5)\n",
    "ax.add_patch(box)\n",
    "ax.text(2, 6.6, 'Plan', ha='center', va='center', fontsize=11, fontweight='bold', color='white')\n",
    "\n",
    "for i, y in enumerate([4.5, 3.2, 1.9]):\n",
    "    box = mpatches.FancyBboxPatch((0.5, y), 3, 0.7, boxstyle=\"round,pad=0.1\",\n",
    "                                   facecolor='#e74c3c', edgecolor='black', linewidth=1.5)\n",
    "    ax.add_patch(box)\n",
    "    ax.text(2, y + 0.35, f'Execute Step {i+1}', ha='center', va='center',\n",
    "            fontsize=9, fontweight='bold', color='white')\n",
    "\n",
    "ax.annotate('', xy=(2, 5.2), xytext=(2, 6),\n",
    "           arrowprops=dict(arrowstyle='->', lw=1.5, color='gray'))\n",
    "for y1, y2 in [(4.5, 3.2), (3.2, 1.9)]:\n",
    "    ax.annotate('', xy=(2, y2 + 0.7), xytext=(2, y1),\n",
    "               arrowprops=dict(arrowstyle='->', lw=1.5, color='gray'))\n",
    "\n",
    "box = mpatches.FancyBboxPatch((0.5, 0.5), 3, 0.7, boxstyle=\"round,pad=0.1\",\n",
    "                               facecolor='#9b59b6', edgecolor='black', linewidth=1.5)\n",
    "ax.add_patch(box)\n",
    "ax.text(2, 0.85, 'Answer', ha='center', va='center', fontsize=10, fontweight='bold', color='white')\n",
    "ax.annotate('', xy=(2, 1.2), xytext=(2, 1.9),\n",
    "           arrowprops=dict(arrowstyle='->', lw=1.5, color='gray'))\n",
    "\n",
    "# Reflexion\n",
    "ax = axes[2]\n",
    "ax.set_xlim(0, 4)\n",
    "ax.set_ylim(0, 8)\n",
    "ax.axis('off')\n",
    "ax.set_title('Reflexion', fontsize=13, fontweight='bold')\n",
    "\n",
    "refl_steps = [\n",
    "    (2, 7, 'Act', '#e74c3c'),\n",
    "    (2, 5.5, 'Evaluate', '#3498db'),\n",
    "    (2, 4, 'Reflect', '#f39c12'),\n",
    "    (2, 2.5, 'Retry', '#e74c3c'),\n",
    "    (2, 1, 'Answer', '#9b59b6'),\n",
    "]\n",
    "\n",
    "for x, y, label, color in refl_steps:\n",
    "    box = mpatches.FancyBboxPatch((x - 0.8, y - 0.35), 1.6, 0.7,\n",
    "                                   boxstyle=\"round,pad=0.1\", facecolor=color,\n",
    "                                   edgecolor='black', linewidth=1.5)\n",
    "    ax.add_patch(box)\n",
    "    ax.text(x, y, label, ha='center', va='center', fontsize=10, fontweight='bold', color='white')\n",
    "\n",
    "for i in range(len(refl_steps) - 1):\n",
    "    ax.annotate('', xy=(2, refl_steps[i+1][1] + 0.35),\n",
    "               xytext=(2, refl_steps[i][1] - 0.35),\n",
    "               arrowprops=dict(arrowstyle='->', lw=1.5, color='gray'))\n",
    "\n",
    "# Loop arrow for reflexion\n",
    "ax.annotate('', xy=(3.3, 7), xytext=(3.3, 4),\n",
    "           arrowprops=dict(arrowstyle='->', lw=1.5, color='#f39c12',\n",
    "                          connectionstyle='arc3,rad=-0.5'))\n",
    "ax.text(3.8, 5.5, 'retry', fontsize=8, color='#f39c12', rotation=90, va='center')\n",
    "\n",
    "plt.suptitle('Agent Architecture Patterns', fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Agent Safety and Failure Modes\n",
    "\n",
    "Agents are powerful but dangerous â€” they can take **irreversible actions**. Understanding failure modes is critical.\n",
    "\n",
    "| Failure Mode | Example | Mitigation |\n",
    "|-------------|---------|------------|\n",
    "| **Infinite loops** | Agent keeps searching without converging | Max step limit |\n",
    "| **Wrong tool** | Uses calculator when should search | Better tool descriptions |\n",
    "| **Hallucinated actions** | Calls a tool that doesn't exist | Strict tool validation |\n",
    "| **Unsafe actions** | Deletes files, sends emails | Permission system, sandboxing |\n",
    "| **Goal drift** | Wanders from original task | Task decomposition, checkpoints |\n",
    "| **Cascading errors** | Error in step 1 propagates | Error handling, retries |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SafeAgent:\n",
    "    \"\"\"Agent with safety guardrails.\"\"\"\n",
    "    \n",
    "    def __init__(self, tools, max_steps=5, max_tool_calls=10):\n",
    "        self.tools = tools\n",
    "        self.max_steps = max_steps\n",
    "        self.max_tool_calls = max_tool_calls\n",
    "        self.tool_call_count = 0\n",
    "        self.errors = []\n",
    "    \n",
    "    def validate_tool_call(self, tool_name, args):\n",
    "        \"\"\"Validate a tool call before execution.\"\"\"\n",
    "        # Check tool exists\n",
    "        if tool_name not in self.tools:\n",
    "            return False, f\"Unknown tool: {tool_name}\"\n",
    "        \n",
    "        # Check rate limit\n",
    "        if self.tool_call_count >= self.max_tool_calls:\n",
    "            return False, \"Tool call limit exceeded\"\n",
    "        \n",
    "        # Check required parameters\n",
    "        tool = self.tools[tool_name]\n",
    "        for param in tool.parameters:\n",
    "            if param not in args:\n",
    "                return False, f\"Missing required parameter: {param}\"\n",
    "        \n",
    "        return True, \"OK\"\n",
    "    \n",
    "    def safe_execute(self, tool_name, **args):\n",
    "        \"\"\"Execute a tool with error handling.\"\"\"\n",
    "        valid, message = self.validate_tool_call(tool_name, args)\n",
    "        if not valid:\n",
    "            self.errors.append(message)\n",
    "            return {'status': 'blocked', 'reason': message}\n",
    "        \n",
    "        try:\n",
    "            self.tool_call_count += 1\n",
    "            result = self.tools[tool_name].execute(**args)\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            self.errors.append(str(e))\n",
    "            return {'status': 'error', 'error': str(e)}\n",
    "\n",
    "\n",
    "# Demonstrate safety features\n",
    "safe = SafeAgent(tools, max_tool_calls=3)\n",
    "\n",
    "print(\"Safety demonstrations:\")\n",
    "print(\"\\n1. Valid tool call:\")\n",
    "print(f\"   {safe.safe_execute('calculator', expression='2+2')}\")\n",
    "\n",
    "print(\"\\n2. Invalid tool name:\")\n",
    "print(f\"   {safe.safe_execute('delete_database', target='all')}\")\n",
    "\n",
    "print(\"\\n3. Missing parameters:\")\n",
    "print(f\"   {safe.safe_execute('calculator')}\")\n",
    "\n",
    "# Exhaust rate limit\n",
    "safe.safe_execute('calculator', expression='1+1')\n",
    "safe.safe_execute('calculator', expression='1+1')\n",
    "print(\"\\n4. Rate limit exceeded:\")\n",
    "print(f\"   {safe.safe_execute('calculator', expression='1+1')}\")\n",
    "\n",
    "print(f\"\\nErrors logged: {safe.errors}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Agent Evaluation Metrics\n",
    "\n",
    "How do we measure if an agent is good? Key metrics:\n",
    "\n",
    "| Metric | What It Measures | How |\n",
    "|--------|-----------------|-----|\n",
    "| **Task completion** | Did the agent finish the task? | Binary success/fail |\n",
    "| **Accuracy** | Was the answer correct? | Compare to ground truth |\n",
    "| **Efficiency** | How many steps/tool calls? | Count steps |\n",
    "| **Tool selection** | Did it use the right tools? | Compare to optimal trace |\n",
    "| **Error recovery** | Did it handle failures gracefully? | Inject errors, check recovery |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentEvaluator:\n",
    "    \"\"\"Evaluate agent performance on a benchmark.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.results = []\n",
    "    \n",
    "    def evaluate(self, agent, test_cases):\n",
    "        \"\"\"Run agent on test cases and measure performance.\"\"\"\n",
    "        self.results = []\n",
    "        \n",
    "        for test in test_cases:\n",
    "            agent.trace = []\n",
    "            answer = agent.run(test['query'])\n",
    "            \n",
    "            # Measure metrics\n",
    "            trace = agent.trace\n",
    "            n_steps = len([t for t in trace if t['step'] == 'action'])\n",
    "            tools_used = [t['tool'] for t in trace if t['step'] == 'action']\n",
    "            \n",
    "            # Check if expected tool was used\n",
    "            correct_tool = test.get('expected_tool') in tools_used if test.get('expected_tool') else True\n",
    "            \n",
    "            # Check if answer contains expected content\n",
    "            answer_correct = any(\n",
    "                keyword.lower() in answer.lower()\n",
    "                for keyword in test.get('expected_keywords', [])\n",
    "            )\n",
    "            \n",
    "            self.results.append({\n",
    "                'query': test['query'],\n",
    "                'n_steps': n_steps,\n",
    "                'tools_used': tools_used,\n",
    "                'correct_tool': correct_tool,\n",
    "                'answer_correct': answer_correct,\n",
    "                'completed': len(answer) > 10,\n",
    "            })\n",
    "        \n",
    "        return self._compute_metrics()\n",
    "    \n",
    "    def _compute_metrics(self):\n",
    "        n = len(self.results)\n",
    "        return {\n",
    "            'completion_rate': sum(r['completed'] for r in self.results) / n,\n",
    "            'accuracy': sum(r['answer_correct'] for r in self.results) / n,\n",
    "            'tool_accuracy': sum(r['correct_tool'] for r in self.results) / n,\n",
    "            'avg_steps': np.mean([r['n_steps'] for r in self.results]),\n",
    "        }\n",
    "\n",
    "\n",
    "# Evaluation benchmark\n",
    "test_cases = [\n",
    "    {'query': 'Tell me about transformers',\n",
    "     'expected_tool': 'search', 'expected_keywords': ['attention', '2017']},\n",
    "    {'query': 'What is relu?',\n",
    "     'expected_tool': 'lookup', 'expected_keywords': ['max', 'activation']},\n",
    "    {'query': 'How does RLHF work?',\n",
    "     'expected_tool': 'search', 'expected_keywords': ['reward', 'PPO']},\n",
    "    {'query': 'What is backpropagation?',\n",
    "     'expected_tool': 'search', 'expected_keywords': ['gradient', 'chain']},\n",
    "    {'query': 'Tell me about embeddings and semantic similarity',\n",
    "     'expected_tool': 'search', 'expected_keywords': ['vector', 'cosine']},\n",
    "]\n",
    "\n",
    "evaluator = AgentEvaluator()\n",
    "agent = ReActAgent(tools)\n",
    "metrics = evaluator.evaluate(agent, test_cases)\n",
    "\n",
    "print(\"Agent Evaluation Results:\")\n",
    "for metric, value in metrics.items():\n",
    "    print(f\"  {metric}: {value:.2%}\" if 'rate' in metric or 'accuracy' in metric\n",
    "          else f\"  {metric}: {value:.1f}\")\n",
    "\n",
    "# Visualize\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 5))\n",
    "metric_names = list(metrics.keys())\n",
    "metric_values = list(metrics.values())\n",
    "colors = ['#2ecc71', '#3498db', '#f39c12', '#e74c3c']\n",
    "bars = ax.bar(metric_names, metric_values, color=colors, edgecolor='black', alpha=0.8)\n",
    "\n",
    "for bar, val in zip(bars, metric_values):\n",
    "    label = f'{val:.0%}' if val <= 1 else f'{val:.1f}'\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02,\n",
    "            label, ha='center', fontsize=11, fontweight='bold')\n",
    "\n",
    "ax.set_ylabel('Score', fontsize=12)\n",
    "ax.set_title('Agent Performance Metrics', fontsize=13, fontweight='bold')\n",
    "ax.set_xticklabels(metric_names, rotation=15, ha='right')\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Multi-Agent Systems\n",
    "\n",
    "Complex tasks often benefit from **multiple specialized agents** working together:\n",
    "\n",
    "- **Researcher**: Gathers information from search/documents\n",
    "- **Coder**: Writes and executes code\n",
    "- **Reviewer**: Checks work quality\n",
    "- **Orchestrator**: Coordinates the team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpecializedAgent:\n",
    "    \"\"\"A specialized agent with a specific role.\"\"\"\n",
    "    \n",
    "    def __init__(self, name, role, tools):\n",
    "        self.name = name\n",
    "        self.role = role\n",
    "        self.tools = tools\n",
    "    \n",
    "    def process(self, task, context=None):\n",
    "        \"\"\"Process a task given optional context from other agents.\"\"\"\n",
    "        results = []\n",
    "        for tool_name, args in self._decide_actions(task, context):\n",
    "            if tool_name in self.tools:\n",
    "                result = self.tools[tool_name].execute(**args)\n",
    "                results.append({'tool': tool_name, 'result': result})\n",
    "        return {'agent': self.name, 'role': self.role, 'results': results}\n",
    "    \n",
    "    def _decide_actions(self, task, context):\n",
    "        \"\"\"Decide which tools to use (simplified).\"\"\"\n",
    "        actions = []\n",
    "        if self.role == 'researcher':\n",
    "            actions.append(('search', {'query': task}))\n",
    "        elif self.role == 'fact_checker':\n",
    "            # Check key terms from context\n",
    "            if context:\n",
    "                for r in context.get('results', []):\n",
    "                    if 'result' in r and 'results' in r.get('result', {}):\n",
    "                        for item in r['result']['results']:\n",
    "                            key = item.get('title', '').lower()\n",
    "                            actions.append(('lookup', {'term': key}))\n",
    "                            break\n",
    "        return actions\n",
    "\n",
    "\n",
    "class Orchestrator:\n",
    "    \"\"\"Coordinates multiple specialized agents.\"\"\"\n",
    "    \n",
    "    def __init__(self, agents):\n",
    "        self.agents = {a.name: a for a in agents}\n",
    "    \n",
    "    def run_pipeline(self, task):\n",
    "        \"\"\"Run agents in a pipeline.\"\"\"\n",
    "        print(f\"Orchestrator: Task = '{task}'\\n\")\n",
    "        \n",
    "        # Step 1: Research\n",
    "        researcher = self.agents.get('researcher')\n",
    "        if researcher:\n",
    "            research_output = researcher.process(task)\n",
    "            print(f\"  {researcher.name} ({researcher.role}):\")\n",
    "            for r in research_output['results']:\n",
    "                print(f\"    Tool: {r['tool']} -> {json.dumps(r['result'])[:100]}\")\n",
    "        \n",
    "        # Step 2: Fact check\n",
    "        checker = self.agents.get('fact_checker')\n",
    "        if checker:\n",
    "            check_output = checker.process(task, context=research_output)\n",
    "            print(f\"  {checker.name} ({checker.role}):\")\n",
    "            for r in check_output['results']:\n",
    "                print(f\"    Tool: {r['tool']} -> {json.dumps(r['result'])[:100]}\")\n",
    "        \n",
    "        print(f\"\\n  Orchestrator: Pipeline complete.\")\n",
    "        return {'research': research_output, 'fact_check': check_output if checker else None}\n",
    "\n",
    "\n",
    "# Build multi-agent system\n",
    "researcher = SpecializedAgent('researcher', 'researcher', tools)\n",
    "checker = SpecializedAgent('fact_checker', 'fact_checker', tools)\n",
    "\n",
    "orchestrator = Orchestrator([researcher, checker])\n",
    "result = orchestrator.run_pipeline(\"Explain how attention works in transformers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercises\n",
    "\n",
    "### Exercise 1: Weather Agent\n",
    "\n",
    "Create a `WeatherTool` (simulated) and integrate it into the ReAct agent. The tool should accept a city name and return simulated weather data. Test with queries like \"What's the weather in San Francisco?\" and \"Should I bring an umbrella in New York?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: Your code here\n",
    "# Hint: Create a WeatherTool class that extends Tool,\n",
    "# add it to the tools dict, and modify the agent's reasoning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Reflexion Agent\n",
    "\n",
    "Implement a Reflexion agent that: (1) attempts to answer, (2) self-evaluates its answer, (3) reflects on what went wrong, (4) retries with improved approach. Test on a math word problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2: Your code here\n",
    "# Hint: After the agent generates an answer, add a \"self-check\" step\n",
    "# that verifies the answer and triggers a retry if needed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Agent Benchmark Suite\n",
    "\n",
    "Create a benchmark of 10+ test cases with varying difficulty. Compare ReAct vs PlanningAgent on completion rate, accuracy, and efficiency. Which architecture performs better on which types of tasks?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3: Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "- **AI agents** use LLMs as reasoning engines that can take actions through tools\n",
    "- **Tools** are the agent's interface to the world: search, calculate, execute code, call APIs\n",
    "- **ReAct** interleaves reasoning and acting for flexible problem-solving\n",
    "- **Chain-of-thought** reasoning improves tool selection and task decomposition\n",
    "- **Safety guardrails** (rate limits, validation, sandboxing) are essential for production agents\n",
    "- **Multi-agent systems** let specialized agents collaborate on complex tasks\n",
    "- Agent evaluation requires task-specific metrics: completion, accuracy, efficiency\n",
    "\n",
    "### Fundamental Insight\n",
    "\n",
    "Agents transform LLMs from passive text generators into active problem-solvers. The key is not the tools themselves â€” it's the reasoning loop that decides *which* tool to use and *when*. The better the reasoning, the more capable the agent. This is why improvements in base LLM reasoning (from GPT-3 to GPT-4 to Claude) translate directly into more capable agents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "Building agents is one thing â€” knowing if they actually work is another. In **Notebook 23: Evaluating AI Systems**, we'll learn the science of AI evaluation: benchmarks, automated eval frameworks, LLM-as-judge, red teaming, and the metrics that determine whether an AI system is ready for production."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

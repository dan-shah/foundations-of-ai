
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Part 8.1: Retrieval-Augmented Generation (RAG) &#8212; Foundations of AI</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=9c3e77be" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=1ae7504c"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'notebooks/26_rag';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Part 8.2: AI Agents and Tool Use" href="27_ai_agents.html" />
    <link rel="prev" title="Part 7.4: PPO and Modern RL" href="25_ppo_modern_rl.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../intro.html">
  
  
  
  
  
  
    <p class="title logo__title">Foundations of AI</p>
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Part 1: Mathematical Foundations</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="01_linear_algebra.html">Part 1.1: Linear Algebra for Deep Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="02_calculus.html">Part 1.2: Calculus for Deep Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="03_probability_statistics.html">Part 1.3: Probability &amp; Statistics for Deep Learning</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Part 2: Programming Foundations</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="04_python_oop.html">Part 2.1: Python OOP for Deep Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="05_numpy_deep_dive.html">Part 2.2: NumPy Deep Dive</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Part 3: Classical ML &amp; Optimization</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="06_classical_ml.html">Part 3.1: Classical Machine Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="07_optimization_linear_programming.html">Part 3.2: Optimization &amp; Linear Programming</a></li>
<li class="toctree-l1"><a class="reference internal" href="08_optimization_theory.html">Part 3.3: Optimization Theory for Machine Learning</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Part 4: Neural Network Fundamentals</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="09_perceptrons_basic_networks.html">Part 4.1: Perceptrons &amp; Basic Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="10_backpropagation.html">Part 4.2: Backpropagation</a></li>
<li class="toctree-l1"><a class="reference internal" href="11_pytorch_fundamentals.html">Part 4.3: PyTorch Fundamentals</a></li>
<li class="toctree-l1"><a class="reference internal" href="12_training_deep_networks.html">Part 4.4: Training Deep Networks</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Part 5: Neural Network Architectures</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="13_convolutional_neural_networks.html">Part 5.1: Convolutional Neural Networks (CNNs)</a></li>
<li class="toctree-l1"><a class="reference internal" href="14_computer_vision_depth.html">Part 5.2: Computer Vision — Beyond Classification</a></li>
<li class="toctree-l1"><a class="reference internal" href="15_recurrent_neural_networks.html">Part 5.3: Recurrent Neural Networks (RNNs)</a></li>
<li class="toctree-l1"><a class="reference internal" href="16_attention_mechanisms.html">Part 5.4: Attention Mechanisms</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Part 6: Transformers &amp; LLMs</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="17_transformer_architecture.html">Part 6.1: Transformer Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="18_embeddings.html">Part 6.2: Embeddings</a></li>
<li class="toctree-l1"><a class="reference internal" href="19_tokenization_lm_training.html">Part 6.3: Tokenization &amp; Language Model Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="20_language_models.html">Part 6.4: Language Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="21_finetuning_and_peft.html">Part 6.5: Fine-tuning &amp; PEFT</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Part 7: Reinforcement Learning</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="22_rl_fundamentals.html">Part 7.1: Reinforcement Learning Fundamentals</a></li>
<li class="toctree-l1"><a class="reference internal" href="23_q_learning_dqn.html">Part 7.2: Q-Learning and Deep Q-Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="24_policy_gradients.html">Part 7.3: Policy Gradient Methods</a></li>
<li class="toctree-l1"><a class="reference internal" href="25_ppo_modern_rl.html">Part 7.4: PPO and Modern RL</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Part 8: Applied AI Systems</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Part 8.1: Retrieval-Augmented Generation (RAG)</a></li>
<li class="toctree-l1"><a class="reference internal" href="27_ai_agents.html">Part 8.2: AI Agents and Tool Use</a></li>
<li class="toctree-l1"><a class="reference internal" href="28_ai_evals.html">Part 8.3: Evaluating AI Systems</a></li>
<li class="toctree-l1"><a class="reference internal" href="29_production_monitoring.html">Part 8.4: Production AI Systems</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Part 9: Advanced Topics</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="30_inference_optimization.html">Part 9.1: LLM Inference Optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="31_ml_systems.html">Part 9.2: ML Systems &amp; Experiment Tracking</a></li>
<li class="toctree-l1"><a class="reference internal" href="32_multimodal_ai.html">Part 9.3: Multimodal AI</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://colab.research.google.com/github/dan-shah/foundations-of-ai/blob/main/notebooks/26_rag.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch on Colab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img alt="Colab logo" src="../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/dan-shah/foundations-of-ai" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/dan-shah/foundations-of-ai/edit/main/notebooks/26_rag.ipynb" target="_blank"
   class="btn btn-sm btn-source-edit-button dropdown-item"
   title="Suggest edit"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="btn__text-container">Suggest edit</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/dan-shah/foundations-of-ai/issues/new?title=Issue%20on%20page%20%2Fnotebooks/26_rag.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/notebooks/26_rag.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Part 8.1: Retrieval-Augmented Generation (RAG)</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#learning-objectives">Learning Objectives</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#why-rag">1. Why RAG?</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-problem-with-parametric-knowledge">The Problem with Parametric Knowledge</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#rag-vs-fine-tuning">RAG vs. Fine-Tuning</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#intuitive-explanation">Intuitive Explanation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#visualization-the-rag-pipeline">Visualization: The RAG Pipeline</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#document-chunking">2. Document Chunking</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#why-chunk">Why Chunk?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#key-tradeoff">Key Tradeoff</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#visualization-chunking-strategy-comparison">Visualization: Chunking Strategy Comparison</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#embeddings-and-vector-search">3. Embeddings and Vector Search</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#building-a-simple-embedding-model">Building a Simple Embedding Model</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#vector-store">4. Vector Store</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#visualization-embedding-space">Visualization: Embedding Space</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-complete-rag-pipeline">5. The Complete RAG Pipeline</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#reranking-improving-retrieval-quality">6. Reranking: Improving Retrieval Quality</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluating-rag-systems">7. Evaluating RAG Systems</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#retrieval-metrics">Retrieval Metrics</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#generation-metrics">Generation Metrics</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#common-rag-failure-modes">8. Common RAG Failure Modes</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#advanced-rag-patterns">9. Advanced RAG Patterns</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#knowledge-graph-rag">10. Knowledge Graph RAG</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#vector-rag-vs-kg-rag-vs-hybrid">Vector RAG vs. KG-RAG vs. Hybrid</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercises">Exercises</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-1-chunking-strategy-comparison-race-report-optimization">Exercise 1: Chunking Strategy Comparison — Race Report Optimization</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-2-multi-hop-rag-cross-referencing-race-data">Exercise 2: Multi-Hop RAG — Cross-Referencing Race Data</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-3-rag-with-metadata-filtering-circuit-specific-search">Exercise 3: RAG with Metadata Filtering — Circuit-Specific Search</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#summary">Summary</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#key-concepts">Key Concepts</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#fundamental-insight">Fundamental Insight</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#next-steps">Next Steps</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="part-8-1-retrieval-augmented-generation-rag">
<h1>Part 8.1: Retrieval-Augmented Generation (RAG)<a class="headerlink" href="#part-8-1-retrieval-augmented-generation-rag" title="Link to this heading">#</a></h1>
<p>Language models are powerful, but they have a fundamental limitation: their knowledge is frozen at training time. Ask about yesterday’s news, your company’s internal docs, or a recently published paper, and the model can only hallucinate. <strong>Retrieval-Augmented Generation (RAG)</strong> solves this by giving LLMs access to external knowledge at inference time.</p>
<p><strong>F1 analogy:</strong> Think of RAG like a race engineer’s access to the team’s historical database. During a race, the engineer doesn’t rely solely on memory — they query past race data for similar conditions (retrieval), then combine that historical context with live telemetry to make strategy calls (augmented generation). The vector store is the team’s indexed archive of thousands of past races, searchable by situation similarity rather than date or keyword.</p>
<p>RAG is the most widely deployed LLM pattern in production today — it’s how ChatGPT plugins, enterprise search, and AI assistants work with custom data. Understanding RAG means understanding how to build practical AI systems.</p>
<section id="learning-objectives">
<h2>Learning Objectives<a class="headerlink" href="#learning-objectives" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>[ ] Understand why RAG exists and when to use it vs. fine-tuning</p></li>
<li><p>[ ] Implement document chunking strategies and understand their tradeoffs</p></li>
<li><p>[ ] Build a vector store with similarity search from scratch</p></li>
<li><p>[ ] Implement a complete RAG pipeline: chunk → embed → retrieve → generate</p></li>
<li><p>[ ] Understand and implement reranking for improved retrieval quality</p></li>
<li><p>[ ] Evaluate RAG systems with retrieval and generation metrics</p></li>
<li><p>[ ] Recognize common RAG failure modes and how to fix them</p></li>
<li><p>[ ] Understand how knowledge graphs enhance RAG for relational and multi-hop queries</p></li>
<li><p>[ ] Connect RAG to the embedding concepts from Notebook 18</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.patches</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">mpatches</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">collections</span><span class="w"> </span><span class="kn">import</span> <span class="n">defaultdict</span><span class="p">,</span> <span class="n">Counter</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">re</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">hashlib</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn.functional</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">F</span>

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Part 8.1: Retrieval-Augmented Generation (RAG)&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">50</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<hr class="docutils" />
<section id="why-rag">
<h2>1. Why RAG?<a class="headerlink" href="#why-rag" title="Link to this heading">#</a></h2>
<section id="the-problem-with-parametric-knowledge">
<h3>The Problem with Parametric Knowledge<a class="headerlink" href="#the-problem-with-parametric-knowledge" title="Link to this heading">#</a></h3>
<p>LLMs store knowledge in their parameters (weights). This has three major limitations:</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Problem</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Example</p></th>
<th class="head"><p>F1 Parallel</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>Staleness</strong></p></td>
<td><p>Knowledge frozen at training cutoff</p></td>
<td><p>“Who won the 2025 Super Bowl?”</p></td>
<td><p>A strategy model trained on 2023 data doesn’t know about 2024 regulation changes</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Hallucination</strong></p></td>
<td><p>Generates plausible but wrong facts</p></td>
<td><p>Citing non-existent papers</p></td>
<td><p>The model confidently predicting tire life based on data from a track it’s never seen</p></td>
</tr>
<tr class="row-even"><td><p><strong>No private data</strong></p></td>
<td><p>Can’t access your specific documents</p></td>
<td><p>Company policy questions</p></td>
<td><p>Can’t access your team’s proprietary telemetry or confidential race debriefs</p></td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="rag-vs-fine-tuning">
<h3>RAG vs. Fine-Tuning<a class="headerlink" href="#rag-vs-fine-tuning" title="Link to this heading">#</a></h3>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Approach</p></th>
<th class="head"><p>When to Use</p></th>
<th class="head"><p>Pros</p></th>
<th class="head"><p>Cons</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>RAG</strong></p></td>
<td><p>Dynamic knowledge, factual accuracy</p></td>
<td><p>No training needed, always up-to-date, verifiable</p></td>
<td><p>Latency overhead, retrieval errors</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Fine-tuning</strong></p></td>
<td><p>Behavior change, domain style</p></td>
<td><p>Faster inference, no retrieval</p></td>
<td><p>Expensive, knowledge goes stale</p></td>
</tr>
<tr class="row-even"><td><p><strong>RAG + Fine-tuning</strong></p></td>
<td><p>Best of both</p></td>
<td><p>Accurate + well-behaved</p></td>
<td><p>Most complex</p></td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="intuitive-explanation">
<h3>Intuitive Explanation<a class="headerlink" href="#intuitive-explanation" title="Link to this heading">#</a></h3>
<p>Think of RAG like an open-book exam: instead of memorizing everything (fine-tuning), you bring your textbooks (retrieved documents) and look up the answer. The LLM’s job shifts from “know everything” to “read well and synthesize.”</p>
<p><strong>F1 analogy:</strong> Fine-tuning is like training a driver on a simulator until they memorize every corner — great until the track layout changes. RAG is like giving the driver a radio connection to the pit wall, where engineers look up relevant data from past races in real-time and relay it. The driver (LLM) still makes the final call, but with the latest information at hand.</p>
</section>
<section id="visualization-the-rag-pipeline">
<h3>Visualization: The RAG Pipeline<a class="headerlink" href="#visualization-the-rag-pipeline" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">14</span><span class="p">,</span> <span class="mi">7</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">14</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">9</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;The RAG Pipeline&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">)</span>

<span class="c1"># Indexing pipeline (top)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mf">8.5</span><span class="p">,</span> <span class="s1">&#39;Indexing Pipeline (offline)&#39;</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span>
        <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">,</span> <span class="n">style</span><span class="o">=</span><span class="s1">&#39;italic&#39;</span><span class="p">)</span>

<span class="n">index_steps</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;Documents&#39;</span><span class="p">,</span> <span class="s1">&#39;#95a5a6&#39;</span><span class="p">,</span> <span class="s1">&#39;Raw text, PDFs,</span><span class="se">\n</span><span class="s1">web pages&#39;</span><span class="p">),</span>
    <span class="p">(</span><span class="mf">3.5</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;Chunker&#39;</span><span class="p">,</span> <span class="s1">&#39;#3498db&#39;</span><span class="p">,</span> <span class="s1">&#39;Split into</span><span class="se">\n</span><span class="s1">manageable pieces&#39;</span><span class="p">),</span>
    <span class="p">(</span><span class="mf">6.5</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;Embedder&#39;</span><span class="p">,</span> <span class="s1">&#39;#9b59b6&#39;</span><span class="p">,</span> <span class="s1">&#39;Convert chunks</span><span class="se">\n</span><span class="s1">to vectors&#39;</span><span class="p">),</span>
    <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;Vector Store&#39;</span><span class="p">,</span> <span class="s1">&#39;#2ecc71&#39;</span><span class="p">,</span> <span class="s1">&#39;Index vectors</span><span class="se">\n</span><span class="s1">for fast search&#39;</span><span class="p">),</span>
<span class="p">]</span>

<span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">label</span><span class="p">,</span> <span class="n">color</span><span class="p">,</span> <span class="n">desc</span> <span class="ow">in</span> <span class="n">index_steps</span><span class="p">:</span>
    <span class="n">box</span> <span class="o">=</span> <span class="n">mpatches</span><span class="o">.</span><span class="n">FancyBboxPatch</span><span class="p">((</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">),</span> <span class="n">w</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">boxstyle</span><span class="o">=</span><span class="s2">&quot;round,pad=0.2&quot;</span><span class="p">,</span>
                                   <span class="n">facecolor</span><span class="o">=</span><span class="n">color</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">add_patch</span><span class="p">(</span><span class="n">box</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="n">w</span><span class="o">/</span><span class="mi">2</span><span class="p">,</span> <span class="n">y</span> <span class="o">+</span> <span class="n">h</span><span class="o">/</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span>
            <span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="n">w</span><span class="o">/</span><span class="mi">2</span><span class="p">,</span> <span class="n">y</span> <span class="o">-</span> <span class="mf">0.4</span><span class="p">,</span> <span class="n">desc</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">index_steps</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
    <span class="n">x1</span> <span class="o">=</span> <span class="n">index_steps</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">index_steps</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">2</span><span class="p">]</span>
    <span class="n">x2</span> <span class="o">=</span> <span class="n">index_steps</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">xy</span><span class="o">=</span><span class="p">(</span><span class="n">x2</span><span class="p">,</span> <span class="mf">7.5</span><span class="p">),</span> <span class="n">xytext</span><span class="o">=</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="mf">7.5</span><span class="p">),</span>
               <span class="n">arrowprops</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">arrowstyle</span><span class="o">=</span><span class="s1">&#39;-&gt;&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">))</span>

<span class="c1"># Query pipeline (bottom)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="s1">&#39;Query Pipeline (online)&#39;</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span>
        <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">,</span> <span class="n">style</span><span class="o">=</span><span class="s1">&#39;italic&#39;</span><span class="p">)</span>

<span class="n">query_steps</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;User Query&#39;</span><span class="p">,</span> <span class="s1">&#39;#e74c3c&#39;</span><span class="p">,</span> <span class="s1">&#39;&quot;What is...?&quot;&#39;</span><span class="p">),</span>
    <span class="p">(</span><span class="mf">3.5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;Embed Query&#39;</span><span class="p">,</span> <span class="s1">&#39;#9b59b6&#39;</span><span class="p">,</span> <span class="s1">&#39;Same embedder</span><span class="se">\n</span><span class="s1">as indexing&#39;</span><span class="p">),</span>
    <span class="p">(</span><span class="mf">6.5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;Retrieve&#39;</span><span class="p">,</span> <span class="s1">&#39;#2ecc71&#39;</span><span class="p">,</span> <span class="s1">&#39;Find top-k</span><span class="se">\n</span><span class="s1">nearest chunks&#39;</span><span class="p">),</span>
    <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;Generate&#39;</span><span class="p">,</span> <span class="s1">&#39;#f39c12&#39;</span><span class="p">,</span> <span class="s1">&#39;LLM synthesizes</span><span class="se">\n</span><span class="s1">answer + context&#39;</span><span class="p">),</span>
<span class="p">]</span>

<span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">label</span><span class="p">,</span> <span class="n">color</span><span class="p">,</span> <span class="n">desc</span> <span class="ow">in</span> <span class="n">query_steps</span><span class="p">:</span>
    <span class="n">box</span> <span class="o">=</span> <span class="n">mpatches</span><span class="o">.</span><span class="n">FancyBboxPatch</span><span class="p">((</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">),</span> <span class="n">w</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">boxstyle</span><span class="o">=</span><span class="s2">&quot;round,pad=0.2&quot;</span><span class="p">,</span>
                                   <span class="n">facecolor</span><span class="o">=</span><span class="n">color</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">add_patch</span><span class="p">(</span><span class="n">box</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="n">w</span><span class="o">/</span><span class="mi">2</span><span class="p">,</span> <span class="n">y</span> <span class="o">+</span> <span class="n">h</span><span class="o">/</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span>
            <span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="n">w</span><span class="o">/</span><span class="mi">2</span><span class="p">,</span> <span class="n">y</span> <span class="o">-</span> <span class="mf">0.4</span><span class="p">,</span> <span class="n">desc</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">query_steps</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
    <span class="n">x1</span> <span class="o">=</span> <span class="n">query_steps</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">query_steps</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">2</span><span class="p">]</span>
    <span class="n">x2</span> <span class="o">=</span> <span class="n">query_steps</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">xy</span><span class="o">=</span><span class="p">(</span><span class="n">x2</span><span class="p">,</span> <span class="mf">3.5</span><span class="p">),</span> <span class="n">xytext</span><span class="o">=</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="mf">3.5</span><span class="p">),</span>
               <span class="n">arrowprops</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">arrowstyle</span><span class="o">=</span><span class="s1">&#39;-&gt;&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">))</span>

<span class="c1"># Connection from vector store to retrieve</span>
<span class="n">ax</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">xy</span><span class="o">=</span><span class="p">(</span><span class="mf">7.75</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">xytext</span><span class="o">=</span><span class="p">(</span><span class="mf">11.5</span><span class="p">,</span> <span class="mi">7</span><span class="p">),</span>
           <span class="n">arrowprops</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">arrowstyle</span><span class="o">=</span><span class="s1">&#39;-&gt;&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;#2ecc71&#39;</span><span class="p">,</span>
                          <span class="n">connectionstyle</span><span class="o">=</span><span class="s1">&#39;arc3,rad=-0.3&#39;</span><span class="p">))</span>

<span class="c1"># Answer</span>
<span class="n">box</span> <span class="o">=</span> <span class="n">mpatches</span><span class="o">.</span><span class="n">FancyBboxPatch</span><span class="p">((</span><span class="mi">4</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">),</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">boxstyle</span><span class="o">=</span><span class="s2">&quot;round,pad=0.3&quot;</span><span class="p">,</span>
                               <span class="n">facecolor</span><span class="o">=</span><span class="s1">&#39;#2c3e50&#39;</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">add_patch</span><span class="p">(</span><span class="n">box</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;Grounded Answer (with citations)&#39;</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span>
        <span class="n">fontsize</span><span class="o">=</span><span class="mi">11</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">xy</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">),</span> <span class="n">xytext</span><span class="o">=</span><span class="p">(</span><span class="mf">11.5</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
           <span class="n">arrowprops</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">arrowstyle</span><span class="o">=</span><span class="s1">&#39;-&gt;&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;#f39c12&#39;</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<hr class="docutils" />
<section id="document-chunking">
<h2>2. Document Chunking<a class="headerlink" href="#document-chunking" title="Link to this heading">#</a></h2>
<p>Before we can search documents, we need to split them into chunks. Chunking strategy dramatically affects RAG quality.</p>
<section id="why-chunk">
<h3>Why Chunk?<a class="headerlink" href="#why-chunk" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>LLMs have limited context windows</p></li>
<li><p>Embedding models work best on shorter texts</p></li>
<li><p>Retrieval is more precise with smaller, focused chunks</p></li>
</ul>
</section>
<section id="key-tradeoff">
<h3>Key Tradeoff<a class="headerlink" href="#key-tradeoff" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>Too small</strong>: Loses context, retrieves fragments without enough information</p></li>
<li><p><strong>Too large</strong>: Dilutes relevance, wastes context window space</p></li>
</ul>
<p><strong>F1 analogy:</strong> Chunking is like breaking race reports into queryable sections. A full 50-page post-race debrief is too big to search effectively — you need it split into sections: “tire strategy,” “weather conditions,” “overtaking analysis,” “pit stop timing.” Too granular (individual sentences) and you lose context; too coarse (the entire report) and the retrieval becomes imprecise. The art is finding the right granularity, just like choosing how to organize the team’s knowledge base so engineers can find what they need mid-race.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Sample document corpus for our RAG system</span>
<span class="n">DOCUMENTS</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;neural_networks&quot;</span><span class="p">:</span> <span class="s2">&quot;&quot;&quot;Neural networks are computing systems inspired by biological neural networks. </span>
<span class="s2">They consist of layers of interconnected nodes called neurons. Each connection has a weight that </span>
<span class="s2">adjusts during training. The input layer receives data, hidden layers process it through weighted </span>
<span class="s2">connections and activation functions, and the output layer produces predictions.</span>

<span class="s2">Backpropagation is the key algorithm for training neural networks. It computes gradients of the loss </span>
<span class="s2">function with respect to each weight by applying the chain rule. These gradients tell us how to </span>
<span class="s2">adjust weights to minimize the loss. Stochastic gradient descent (SGD) and its variants like Adam </span>
<span class="s2">are commonly used optimizers.</span>

<span class="s2">Deep learning refers to neural networks with many hidden layers. Deep networks can learn hierarchical </span>
<span class="s2">representations — early layers detect simple features like edges, while deeper layers combine them </span>
<span class="s2">into complex patterns like faces or objects. This hierarchical feature learning is what makes deep </span>
<span class="s2">learning so powerful for tasks like image recognition and natural language processing.&quot;&quot;&quot;</span><span class="p">,</span>

    <span class="s2">&quot;transformers&quot;</span><span class="p">:</span> <span class="s2">&quot;&quot;&quot;The Transformer architecture was introduced in the 2017 paper &#39;Attention Is All </span>
<span class="s2">You Need&#39; by Vaswani et al. It replaced recurrent networks with self-attention mechanisms, enabling </span>
<span class="s2">parallel processing of sequences. The key innovation is the attention mechanism, which allows each </span>
<span class="s2">token to attend to all other tokens in the sequence.</span>

<span class="s2">Self-attention computes three matrices: Query (Q), Key (K), and Value (V) from the input. The </span>
<span class="s2">attention score between positions is computed as the dot product of Q and K, scaled by the square </span>
<span class="s2">root of the dimension, then softmaxed to get weights for the V matrix. Multi-head attention runs </span>
<span class="s2">multiple attention operations in parallel, each learning different relationship patterns.</span>

<span class="s2">Transformers use positional encodings since they have no inherent notion of sequence order. The </span>
<span class="s2">original paper used sinusoidal encodings, but modern models often use learned positional embeddings </span>
<span class="s2">or relative position encodings like RoPE. Layer normalization and residual connections are critical </span>
<span class="s2">for training stability in deep transformer models.&quot;&quot;&quot;</span><span class="p">,</span>

    <span class="s2">&quot;rlhf&quot;</span><span class="p">:</span> <span class="s2">&quot;&quot;&quot;Reinforcement Learning from Human Feedback (RLHF) is the technique used to align </span>
<span class="s2">language models with human preferences. The process has three stages: supervised fine-tuning (SFT) </span>
<span class="s2">on human demonstrations, training a reward model on preference comparisons, and optimizing the </span>
<span class="s2">policy with PPO using the reward model.</span>

<span class="s2">The reward model is trained using the Bradley-Terry preference model. Given pairs of responses </span>
<span class="s2">where humans indicated a preference, the model learns to assign higher scores to preferred </span>
<span class="s2">responses. The loss function is the negative log likelihood of the human preferences under </span>
<span class="s2">the model&#39;s scoring.</span>

<span class="s2">PPO optimization with a KL penalty is critical to prevent reward hacking. Without the KL </span>
<span class="s2">constraint, the model finds degenerate solutions that exploit the reward model&#39;s weaknesses. </span>
<span class="s2">The KL penalty keeps the policy close to the SFT reference model, ensuring the model remains </span>
<span class="s2">coherent and fluent while improving on the reward signal. Direct Preference Optimization (DPO) </span>
<span class="s2">is a newer alternative that skips the reward model entirely.&quot;&quot;&quot;</span><span class="p">,</span>

    <span class="s2">&quot;embeddings&quot;</span><span class="p">:</span> <span class="s2">&quot;&quot;&quot;Word embeddings represent words as dense vectors in a continuous space. </span>
<span class="s2">Word2Vec introduced two key approaches: Skip-gram, which predicts context words from a target </span>
<span class="s2">word, and CBOW, which predicts the target from context. These models learn that semantically </span>
<span class="s2">similar words end up close together in the embedding space.</span>

<span class="s2">Modern embedding models like sentence transformers produce embeddings for entire sentences or </span>
<span class="s2">paragraphs. These are crucial for RAG systems because they enable semantic search — finding </span>
<span class="s2">documents by meaning rather than keyword matching. Cosine similarity is the standard metric </span>
<span class="s2">for comparing embeddings.</span>

<span class="s2">Contextual embeddings from models like BERT produce different vectors for the same word </span>
<span class="s2">depending on context. The word &#39;bank&#39; gets different embeddings in &#39;river bank&#39; versus </span>
<span class="s2">&#39;bank account&#39;. This context-sensitivity makes them far more powerful than static embeddings </span>
<span class="s2">for understanding natural language.&quot;&quot;&quot;</span>
<span class="p">}</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Document corpus: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">DOCUMENTS</span><span class="p">)</span><span class="si">}</span><span class="s2"> documents&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">text</span> <span class="ow">in</span> <span class="n">DOCUMENTS</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="n">words</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">text</span><span class="o">.</span><span class="n">split</span><span class="p">())</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">words</span><span class="si">}</span><span class="s2"> words&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">DocumentChunker</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Multiple chunking strategies for RAG.&quot;&quot;&quot;</span>
    
    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">fixed_size</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">chunk_size</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">overlap</span><span class="o">=</span><span class="mi">50</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Split into fixed-size character chunks with overlap.&quot;&quot;&quot;</span>
        <span class="n">chunks</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">start</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">while</span> <span class="n">start</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
            <span class="n">end</span> <span class="o">=</span> <span class="n">start</span> <span class="o">+</span> <span class="n">chunk_size</span>
            <span class="n">chunk</span> <span class="o">=</span> <span class="n">text</span><span class="p">[</span><span class="n">start</span><span class="p">:</span><span class="n">end</span><span class="p">]</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">chunk</span><span class="p">:</span>
                <span class="n">chunks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">chunk</span><span class="p">)</span>
            <span class="n">start</span> <span class="o">+=</span> <span class="n">chunk_size</span> <span class="o">-</span> <span class="n">overlap</span>
        <span class="k">return</span> <span class="n">chunks</span>
    
    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">sentence_based</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">max_sentences</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Split into groups of sentences.&quot;&quot;&quot;</span>
        <span class="n">sentences</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;(?&lt;=[.!?])\s+&#39;</span><span class="p">,</span> <span class="n">text</span><span class="o">.</span><span class="n">strip</span><span class="p">())</span>
        <span class="n">chunks</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">sentences</span><span class="p">),</span> <span class="n">max_sentences</span><span class="p">):</span>
            <span class="n">chunk</span> <span class="o">=</span> <span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">sentences</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span> <span class="o">+</span> <span class="n">max_sentences</span><span class="p">])</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">chunk</span><span class="p">:</span>
                <span class="n">chunks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">chunk</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">chunks</span>
    
    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">paragraph_based</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Split on paragraph boundaries.&quot;&quot;&quot;</span>
        <span class="n">paragraphs</span> <span class="o">=</span> <span class="p">[</span><span class="n">p</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">text</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n\n</span><span class="s1">&#39;</span><span class="p">)</span> <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">strip</span><span class="p">()]</span>
        <span class="k">return</span> <span class="n">paragraphs</span>
    
    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">semantic_window</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">window_size</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Sliding window over sentences with overlap.&quot;&quot;&quot;</span>
        <span class="n">sentences</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;(?&lt;=[.!?])\s+&#39;</span><span class="p">,</span> <span class="n">text</span><span class="o">.</span><span class="n">strip</span><span class="p">())</span>
        <span class="n">chunks</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">sentences</span><span class="p">)):</span>
            <span class="n">window</span> <span class="o">=</span> <span class="n">sentences</span><span class="p">[</span><span class="nb">max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">i</span> <span class="o">-</span> <span class="n">window_size</span> <span class="o">//</span> <span class="mi">2</span><span class="p">):</span><span class="n">i</span> <span class="o">+</span> <span class="n">window_size</span> <span class="o">//</span> <span class="mi">2</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span>
            <span class="n">chunk</span> <span class="o">=</span> <span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">window</span><span class="p">)</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">chunk</span> <span class="ow">and</span> <span class="n">chunk</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">chunks</span><span class="p">:</span>
                <span class="n">chunks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">chunk</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">chunks</span>


<span class="c1"># Demonstrate chunking strategies</span>
<span class="n">sample_text</span> <span class="o">=</span> <span class="n">DOCUMENTS</span><span class="p">[</span><span class="s1">&#39;transformers&#39;</span><span class="p">]</span>
<span class="n">chunker</span> <span class="o">=</span> <span class="n">DocumentChunker</span><span class="p">()</span>

<span class="n">strategies</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;Fixed (200 chars, 50 overlap)&#39;</span><span class="p">:</span> <span class="n">chunker</span><span class="o">.</span><span class="n">fixed_size</span><span class="p">(</span><span class="n">sample_text</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">50</span><span class="p">),</span>
    <span class="s1">&#39;Sentence-based (3 per chunk)&#39;</span><span class="p">:</span> <span class="n">chunker</span><span class="o">.</span><span class="n">sentence_based</span><span class="p">(</span><span class="n">sample_text</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
    <span class="s1">&#39;Paragraph-based&#39;</span><span class="p">:</span> <span class="n">chunker</span><span class="o">.</span><span class="n">paragraph_based</span><span class="p">(</span><span class="n">sample_text</span><span class="p">),</span>
<span class="p">}</span>

<span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">chunks</span> <span class="ow">in</span> <span class="n">strategies</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">chunks</span><span class="p">)</span><span class="si">}</span><span class="s2"> chunks&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">chunks</span><span class="p">[:</span><span class="mi">3</span><span class="p">]):</span>
        <span class="n">preview</span> <span class="o">=</span> <span class="n">chunk</span><span class="p">[:</span><span class="mi">80</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="s1">&#39; &#39;</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="s1">&#39;...&#39;</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">chunk</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">80</span> <span class="k">else</span> <span class="s1">&#39;&#39;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  [</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">] (</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">chunk</span><span class="p">)</span><span class="si">}</span><span class="s2"> chars) </span><span class="si">{</span><span class="n">preview</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="visualization-chunking-strategy-comparison">
<h3>Visualization: Chunking Strategy Comparison<a class="headerlink" href="#visualization-chunking-strategy-comparison" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>

<span class="k">for</span> <span class="n">ax</span><span class="p">,</span> <span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">chunks</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">axes</span><span class="p">,</span> <span class="n">strategies</span><span class="o">.</span><span class="n">items</span><span class="p">()):</span>
    <span class="n">sizes</span> <span class="o">=</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">chunks</span><span class="p">]</span>
    <span class="n">bars</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">sizes</span><span class="p">)),</span> <span class="n">sizes</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;#3498db&#39;</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Chunk index&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">11</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Chunk size (chars)&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">11</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="se">\n</span><span class="s1">(</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">chunks</span><span class="p">)</span><span class="si">}</span><span class="s1"> chunks)&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">11</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="s1">&#39;y&#39;</span><span class="p">)</span>
    
    <span class="c1"># Annotate mean</span>
    <span class="n">mean_size</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">sizes</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">mean_size</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">sizes</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">mean_size</span> <span class="o">+</span> <span class="mi">10</span><span class="p">,</span> <span class="sa">f</span><span class="s1">&#39;μ=</span><span class="si">{</span><span class="n">mean_size</span><span class="si">:</span><span class="s1">.0f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">9</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;Chunk Size Distribution by Strategy&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mf">1.02</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Fixed-size: Uniform chunks but may split mid-sentence&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Sentence-based: Respects sentence boundaries, variable size&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Paragraph-based: Respects semantic boundaries, fewest chunks&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<hr class="docutils" />
<section id="embeddings-and-vector-search">
<h2>3. Embeddings and Vector Search<a class="headerlink" href="#embeddings-and-vector-search" title="Link to this heading">#</a></h2>
<p>Once we have chunks, we convert them to vectors using an embedding model, then store them for similarity search. We covered embeddings in Notebook 18 — now we’ll use them in practice.</p>
<p><strong>F1 analogy:</strong> The vector store is the team’s knowledge base of past races, indexed by situation similarity. Instead of filing race reports by date or circuit name, you encode each report section as a vector that captures its <em>meaning</em>. When the engineer asks “What happened last time we faced tire degradation on a hot street circuit?”, the system finds the most semantically similar past situations — even if they used completely different words in the original report. This is the difference between keyword search (“tire degradation AND street circuit”) and semantic search (“situations like this one”).</p>
<section id="building-a-simple-embedding-model">
<h3>Building a Simple Embedding Model<a class="headerlink" href="#building-a-simple-embedding-model" title="Link to this heading">#</a></h3>
<p>In production, you’d use a pre-trained model (e.g., OpenAI <code class="docutils literal notranslate"><span class="pre">text-embedding-3-small</span></code> or an open-source sentence transformer). Here we’ll build a simplified TF-IDF + learned projection to demonstrate the mechanics.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">SimpleEmbedder</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;TF-IDF based embedding model for demonstration.</span>
<span class="sd">    </span>
<span class="sd">    In production, use sentence-transformers or API-based embeddings.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="o">=</span><span class="mi">64</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embedding_dim</span> <span class="o">=</span> <span class="n">embedding_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vocab</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">idf</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">projection</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># Random projection for dimensionality reduction</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">_tokenize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Simple whitespace + lowercase tokenization.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">re</span><span class="o">.</span><span class="n">findall</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;\b[a-zA-Z]{2,}\b&#39;</span><span class="p">,</span> <span class="n">text</span><span class="o">.</span><span class="n">lower</span><span class="p">())</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">documents</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Build vocabulary and IDF scores from a corpus.&quot;&quot;&quot;</span>
        <span class="n">doc_freq</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">()</span>
        <span class="n">all_tokens</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
        
        <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">documents</span><span class="p">:</span>
            <span class="n">tokens</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_tokenize</span><span class="p">(</span><span class="n">doc</span><span class="p">))</span>
            <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">tokens</span><span class="p">:</span>
                <span class="n">doc_freq</span><span class="p">[</span><span class="n">token</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="n">all_tokens</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>
        
        <span class="c1"># Build vocabulary (top tokens by document frequency)</span>
        <span class="n">sorted_tokens</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">all_tokens</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">doc_freq</span><span class="p">[</span><span class="n">t</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vocab</span> <span class="o">=</span> <span class="p">{</span><span class="n">token</span><span class="p">:</span> <span class="n">idx</span> <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">token</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">sorted_tokens</span><span class="p">)}</span>
        
        <span class="c1"># Compute IDF</span>
        <span class="n">n_docs</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">documents</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">idf</span> <span class="o">=</span> <span class="p">{</span><span class="n">token</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">n_docs</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">doc_freq</span><span class="p">[</span><span class="n">token</span><span class="p">]))</span>
                     <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">vocab</span><span class="p">}</span>
        
        <span class="c1"># Random projection matrix for dimensionality reduction</span>
        <span class="n">vocab_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vocab</span><span class="p">)</span>
        <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">projection</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding_dim</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">embedding_dim</span><span class="p">)</span>
        
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Embedder fitted: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vocab</span><span class="p">)</span><span class="si">}</span><span class="s2"> tokens, </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">embedding_dim</span><span class="si">}</span><span class="s2">d embeddings&quot;</span><span class="p">)</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">embed</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Convert text to a dense embedding vector.&quot;&quot;&quot;</span>
        <span class="n">tokens</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tokenize</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
        
        <span class="c1"># TF-IDF vector</span>
        <span class="n">tf</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>
        <span class="n">tfidf</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vocab</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">token</span><span class="p">,</span> <span class="n">count</span> <span class="ow">in</span> <span class="n">tf</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">token</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">vocab</span><span class="p">:</span>
                <span class="n">idx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">vocab</span><span class="p">[</span><span class="n">token</span><span class="p">]</span>
                <span class="n">tfidf</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">count</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">tokens</span><span class="p">))</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">idf</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">token</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        
        <span class="c1"># Project to lower dimension</span>
        <span class="n">embedding</span> <span class="o">=</span> <span class="n">tfidf</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">projection</span>
        
        <span class="c1"># L2 normalize</span>
        <span class="n">norm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">embedding</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">norm</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">embedding</span> <span class="o">=</span> <span class="n">embedding</span> <span class="o">/</span> <span class="n">norm</span>
        
        <span class="k">return</span> <span class="n">embedding</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">embed_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">texts</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Embed multiple texts.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">embed</span><span class="p">(</span><span class="n">text</span><span class="p">)</span> <span class="k">for</span> <span class="n">text</span> <span class="ow">in</span> <span class="n">texts</span><span class="p">])</span>


<span class="c1"># Build embedder from our corpus</span>
<span class="n">all_text</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">DOCUMENTS</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
<span class="n">embedder</span> <span class="o">=</span> <span class="n">SimpleEmbedder</span><span class="p">(</span><span class="n">embedding_dim</span><span class="o">=</span><span class="mi">64</span><span class="p">)</span>
<span class="n">embedder</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">all_text</span><span class="p">)</span>

<span class="c1"># Test it</span>
<span class="n">test_embedding</span> <span class="o">=</span> <span class="n">embedder</span><span class="o">.</span><span class="n">embed</span><span class="p">(</span><span class="s2">&quot;How does attention work in transformers?&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Query embedding shape: </span><span class="si">{</span><span class="n">test_embedding</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;L2 norm: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">test_embedding</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> (should be ~1.0)&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<hr class="docutils" />
<section id="vector-store">
<h2>4. Vector Store<a class="headerlink" href="#vector-store" title="Link to this heading">#</a></h2>
<p>A vector store indexes embeddings for fast similarity search. The core operation is <strong>nearest neighbor search</strong>: given a query vector, find the <span class="math notranslate nohighlight">\(k\)</span> most similar stored vectors.</p>
<p><strong>F1 analogy:</strong> The vector store is like the team’s race strategy database — thousands of past race situations encoded as vectors. When the race engineer types “We’re on mediums, lap 25 of 55, gap to car ahead is closing,” the vector store finds the three or four most similar historical situations. The cosine similarity score tells you <em>how</em> similar each past situation was. In production F1 teams, this kind of indexed retrieval needs to return results in milliseconds — you can’t wait 10 seconds for an answer when racing at 300 km/h.</p>
<p>In production, you’d use FAISS, Pinecone, Weaviate, or Chroma. Here we build one from scratch to understand the mechanics.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">VectorStore</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Simple vector store with cosine similarity search.&quot;&quot;&quot;</span>
    
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">embedder</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embedder</span> <span class="o">=</span> <span class="n">embedder</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embeddings</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># List of vectors</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">documents</span> <span class="o">=</span> <span class="p">[]</span>   <span class="c1"># Original text chunks</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">metadata</span> <span class="o">=</span> <span class="p">[]</span>    <span class="c1"># Source document info</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">add_documents</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">chunks</span><span class="p">,</span> <span class="n">source_name</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Index a list of text chunks.&quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="n">chunks</span><span class="p">:</span>
            <span class="n">embedding</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedder</span><span class="o">.</span><span class="n">embed</span><span class="p">(</span><span class="n">chunk</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">embeddings</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">embedding</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">documents</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">chunk</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">metadata</span><span class="o">.</span><span class="n">append</span><span class="p">({</span><span class="s1">&#39;source&#39;</span><span class="p">:</span> <span class="n">source_name</span><span class="p">,</span> <span class="s1">&#39;length&#39;</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">chunk</span><span class="p">)})</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">search</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">query</span><span class="p">,</span> <span class="n">top_k</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Find the top-k most similar chunks to a query.&quot;&quot;&quot;</span>
        <span class="n">query_embedding</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedder</span><span class="o">.</span><span class="n">embed</span><span class="p">(</span><span class="n">query</span><span class="p">)</span>
        
        <span class="c1"># Cosine similarity (embeddings are already normalized)</span>
        <span class="n">similarities</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span>
            <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">query_embedding</span><span class="p">,</span> <span class="n">emb</span><span class="p">)</span> <span class="k">for</span> <span class="n">emb</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">embeddings</span>
        <span class="p">])</span>
        
        <span class="c1"># Get top-k indices</span>
        <span class="n">top_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">similarities</span><span class="p">)[::</span><span class="o">-</span><span class="mi">1</span><span class="p">][:</span><span class="n">top_k</span><span class="p">]</span>
        
        <span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">top_indices</span><span class="p">:</span>
            <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
                <span class="s1">&#39;chunk&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">documents</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span>
                <span class="s1">&#39;score&#39;</span><span class="p">:</span> <span class="n">similarities</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span>
                <span class="s1">&#39;metadata&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">metadata</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span>
                <span class="s1">&#39;index&#39;</span><span class="p">:</span> <span class="n">idx</span>
            <span class="p">})</span>
        
        <span class="k">return</span> <span class="n">results</span>
    
    <span class="k">def</span><span class="w"> </span><span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">documents</span><span class="p">)</span>


<span class="c1"># Build the vector store</span>
<span class="n">store</span> <span class="o">=</span> <span class="n">VectorStore</span><span class="p">(</span><span class="n">embedder</span><span class="p">)</span>

<span class="k">for</span> <span class="n">doc_name</span><span class="p">,</span> <span class="n">doc_text</span> <span class="ow">in</span> <span class="n">DOCUMENTS</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="n">chunks</span> <span class="o">=</span> <span class="n">DocumentChunker</span><span class="o">.</span><span class="n">paragraph_based</span><span class="p">(</span><span class="n">doc_text</span><span class="p">)</span>
    <span class="n">store</span><span class="o">.</span><span class="n">add_documents</span><span class="p">(</span><span class="n">chunks</span><span class="p">,</span> <span class="n">source_name</span><span class="o">=</span><span class="n">doc_name</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Vector store: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">store</span><span class="p">)</span><span class="si">}</span><span class="s2"> chunks indexed&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Sources: </span><span class="si">{</span><span class="nb">set</span><span class="p">(</span><span class="n">m</span><span class="p">[</span><span class="s1">&#39;source&#39;</span><span class="p">]</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">m</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">store</span><span class="o">.</span><span class="n">metadata</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Test search</span>
<span class="n">query</span> <span class="o">=</span> <span class="s2">&quot;How does attention work?&quot;</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">store</span><span class="o">.</span><span class="n">search</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">top_k</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Query: &#39;</span><span class="si">{</span><span class="n">query</span><span class="si">}</span><span class="s2">&#39;&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Top-3 results:&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">r</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">results</span><span class="p">):</span>
    <span class="n">preview</span> <span class="o">=</span> <span class="n">r</span><span class="p">[</span><span class="s1">&#39;chunk&#39;</span><span class="p">][:</span><span class="mi">100</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="s1">&#39; &#39;</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;...&#39;</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  [</span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">] Score: </span><span class="si">{</span><span class="n">r</span><span class="p">[</span><span class="s1">&#39;score&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> | Source: </span><span class="si">{</span><span class="n">r</span><span class="p">[</span><span class="s1">&#39;metadata&#39;</span><span class="p">][</span><span class="s1">&#39;source&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;       </span><span class="si">{</span><span class="n">preview</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<section id="visualization-embedding-space">
<h3>Visualization: Embedding Space<a class="headerlink" href="#visualization-embedding-space" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Visualize the embedding space with PCA</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">numpy.linalg</span><span class="w"> </span><span class="kn">import</span> <span class="n">svd</span>

<span class="n">embeddings_matrix</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">store</span><span class="o">.</span><span class="n">embeddings</span><span class="p">)</span>
<span class="c1"># Simple PCA via SVD</span>
<span class="n">mean</span> <span class="o">=</span> <span class="n">embeddings_matrix</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">centered</span> <span class="o">=</span> <span class="n">embeddings_matrix</span> <span class="o">-</span> <span class="n">mean</span>
<span class="n">U</span><span class="p">,</span> <span class="n">S</span><span class="p">,</span> <span class="n">Vt</span> <span class="o">=</span> <span class="n">svd</span><span class="p">(</span><span class="n">centered</span><span class="p">,</span> <span class="n">full_matrices</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">pca_2d</span> <span class="o">=</span> <span class="n">centered</span> <span class="o">@</span> <span class="n">Vt</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">T</span>

<span class="c1"># Color by source document</span>
<span class="n">source_colors</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;neural_networks&#39;</span><span class="p">:</span> <span class="s1">&#39;#3498db&#39;</span><span class="p">,</span> <span class="s1">&#39;transformers&#39;</span><span class="p">:</span> <span class="s1">&#39;#e74c3c&#39;</span><span class="p">,</span>
                 <span class="s1">&#39;rlhf&#39;</span><span class="p">:</span> <span class="s1">&#39;#2ecc71&#39;</span><span class="p">,</span> <span class="s1">&#39;embeddings&#39;</span><span class="p">:</span> <span class="s1">&#39;#f39c12&#39;</span><span class="p">}</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">point</span><span class="p">,</span> <span class="n">meta</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">pca_2d</span><span class="p">,</span> <span class="n">store</span><span class="o">.</span><span class="n">metadata</span><span class="p">)):</span>
    <span class="n">color</span> <span class="o">=</span> <span class="n">source_colors</span><span class="p">[</span><span class="n">meta</span><span class="p">[</span><span class="s1">&#39;source&#39;</span><span class="p">]]</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">point</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">point</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">color</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">zorder</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">meta</span><span class="p">[</span><span class="s1">&#39;source&#39;</span><span class="p">][:</span><span class="mi">5</span><span class="p">]</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="p">(</span><span class="n">point</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">point</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span>
               <span class="n">textcoords</span><span class="o">=</span><span class="s2">&quot;offset points&quot;</span><span class="p">,</span> <span class="n">xytext</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">7</span><span class="p">)</span>

<span class="c1"># Plot query point</span>
<span class="n">query_emb</span> <span class="o">=</span> <span class="n">embedder</span><span class="o">.</span><span class="n">embed</span><span class="p">(</span><span class="n">query</span><span class="p">)</span>
<span class="n">query_pca</span> <span class="o">=</span> <span class="p">(</span><span class="n">query_emb</span> <span class="o">-</span> <span class="n">mean</span><span class="p">)</span> <span class="o">@</span> <span class="n">Vt</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">T</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">query_pca</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">query_pca</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;*&#39;</span><span class="p">,</span> <span class="n">zorder</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Query&#39;</span><span class="p">)</span>

<span class="c1"># Draw lines to top results</span>
<span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">results</span><span class="p">[:</span><span class="mi">3</span><span class="p">]:</span>
    <span class="n">idx</span> <span class="o">=</span> <span class="n">r</span><span class="p">[</span><span class="s1">&#39;index&#39;</span><span class="p">]</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">query_pca</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">pca_2d</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="mi">0</span><span class="p">]],</span> <span class="p">[</span><span class="n">query_pca</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">pca_2d</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="mi">1</span><span class="p">]],</span>
            <span class="s1">&#39;k--&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">1.5</span><span class="p">)</span>

<span class="c1"># Legend</span>
<span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">color</span> <span class="ow">in</span> <span class="n">source_colors</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">([],</span> <span class="p">[],</span> <span class="n">c</span><span class="o">=</span><span class="n">color</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">80</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper left&#39;</span><span class="p">)</span>

<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;PCA Component 1&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;PCA Component 2&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Chunk Embeddings in 2D (PCA)</span><span class="se">\n</span><span class="s1">Dashed lines = retrieved chunks&#39;</span><span class="p">,</span>
             <span class="n">fontsize</span><span class="o">=</span><span class="mi">13</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<hr class="docutils" />
<section id="the-complete-rag-pipeline">
<h2>5. The Complete RAG Pipeline<a class="headerlink" href="#the-complete-rag-pipeline" title="Link to this heading">#</a></h2>
<p>Now let’s put it all together into a complete RAG system.</p>
<p><strong>F1 analogy:</strong> The full RAG pipeline mirrors what happens on the pit wall during a race. The engineer’s question (query) gets embedded and matched against the team’s historical database (retrieval). The top-k most relevant past race situations are pulled together with the current live data (augmented context). Then the strategy model (LLM) synthesizes all of this into a recommendation: “Based on similar situations at Silverstone 2022 and Barcelona 2023, we recommend pitting on lap 32 for hards.” The key insight: the model doesn’t need to <em>remember</em> every past race — it just needs to <em>read</em> the relevant ones and reason well.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">RAGPipeline</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Complete Retrieval-Augmented Generation pipeline.&quot;&quot;&quot;</span>
    
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vector_store</span><span class="p">,</span> <span class="n">top_k</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">store</span> <span class="o">=</span> <span class="n">vector_store</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">top_k</span> <span class="o">=</span> <span class="n">top_k</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">build_prompt</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">query</span><span class="p">,</span> <span class="n">retrieved_chunks</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Build the prompt with retrieved context.&quot;&quot;&quot;</span>
        <span class="n">context</span> <span class="o">=</span> <span class="s2">&quot;</span><span class="se">\n\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span>
            <span class="sa">f</span><span class="s2">&quot;[Source: </span><span class="si">{</span><span class="n">r</span><span class="p">[</span><span class="s1">&#39;metadata&#39;</span><span class="p">][</span><span class="s1">&#39;source&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">] </span><span class="si">{</span><span class="n">r</span><span class="p">[</span><span class="s1">&#39;chunk&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">retrieved_chunks</span>
        <span class="p">])</span>
        
        <span class="n">prompt</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;&quot;&quot;Answer the question based on the provided context. If the context doesn&#39;t </span>
<span class="s2">contain enough information, say so. Cite the source documents.</span>

<span class="s2">Context:</span>
<span class="si">{</span><span class="n">context</span><span class="si">}</span>

<span class="s2">Question: </span><span class="si">{</span><span class="n">query</span><span class="si">}</span>

<span class="s2">Answer:&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">prompt</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">query</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">question</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Full RAG pipeline: retrieve + build prompt.&quot;&quot;&quot;</span>
        <span class="c1"># Step 1: Retrieve relevant chunks</span>
        <span class="n">results</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">store</span><span class="o">.</span><span class="n">search</span><span class="p">(</span><span class="n">question</span><span class="p">,</span> <span class="n">top_k</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">top_k</span><span class="p">)</span>
        
        <span class="c1"># Step 2: Build augmented prompt</span>
        <span class="n">prompt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">build_prompt</span><span class="p">(</span><span class="n">question</span><span class="p">,</span> <span class="n">results</span><span class="p">)</span>
        
        <span class="c1"># Step 3: In production, send to LLM. Here we return the prompt.</span>
        <span class="k">return</span> <span class="p">{</span>
            <span class="s1">&#39;prompt&#39;</span><span class="p">:</span> <span class="n">prompt</span><span class="p">,</span>
            <span class="s1">&#39;retrieved&#39;</span><span class="p">:</span> <span class="n">results</span><span class="p">,</span>
            <span class="s1">&#39;n_chunks&#39;</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">results</span><span class="p">),</span>
            <span class="s1">&#39;total_context_chars&#39;</span><span class="p">:</span> <span class="nb">sum</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">r</span><span class="p">[</span><span class="s1">&#39;chunk&#39;</span><span class="p">])</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">results</span><span class="p">),</span>
        <span class="p">}</span>


<span class="c1"># Build and test the RAG pipeline</span>
<span class="n">rag</span> <span class="o">=</span> <span class="n">RAGPipeline</span><span class="p">(</span><span class="n">store</span><span class="p">,</span> <span class="n">top_k</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

<span class="n">test_queries</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;How does backpropagation work?&quot;</span><span class="p">,</span>
    <span class="s2">&quot;What is the attention mechanism?&quot;</span><span class="p">,</span>
    <span class="s2">&quot;How is RLHF used to train language models?&quot;</span><span class="p">,</span>
    <span class="s2">&quot;What are word embeddings?&quot;</span><span class="p">,</span>
<span class="p">]</span>

<span class="k">for</span> <span class="n">query</span> <span class="ow">in</span> <span class="n">test_queries</span><span class="p">:</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">rag</span><span class="o">.</span><span class="n">query</span><span class="p">(</span><span class="n">query</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Query: &#39;</span><span class="si">{</span><span class="n">query</span><span class="si">}</span><span class="s2">&#39;&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Retrieved </span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="s1">&#39;n_chunks&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2"> chunks (</span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="s1">&#39;total_context_chars&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2"> chars)&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">result</span><span class="p">[</span><span class="s1">&#39;retrieved&#39;</span><span class="p">]:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;    [</span><span class="si">{</span><span class="n">r</span><span class="p">[</span><span class="s1">&#39;score&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">] </span><span class="si">{</span><span class="n">r</span><span class="p">[</span><span class="s1">&#39;metadata&#39;</span><span class="p">][</span><span class="s1">&#39;source&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Show what the LLM would see</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">rag</span><span class="o">.</span><span class="n">query</span><span class="p">(</span><span class="s2">&quot;What is the attention mechanism?&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;PROMPT SENT TO LLM:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">[</span><span class="s1">&#39;prompt&#39;</span><span class="p">][:</span><span class="mi">1000</span><span class="p">])</span>
<span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">result</span><span class="p">[</span><span class="s1">&#39;prompt&#39;</span><span class="p">])</span> <span class="o">&gt;</span> <span class="mi">1000</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">... (</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">result</span><span class="p">[</span><span class="s1">&#39;prompt&#39;</span><span class="p">])</span><span class="si">}</span><span class="s2"> total characters)&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<hr class="docutils" />
<section id="reranking-improving-retrieval-quality">
<h2>6. Reranking: Improving Retrieval Quality<a class="headerlink" href="#reranking-improving-retrieval-quality" title="Link to this heading">#</a></h2>
<p>Embedding-based retrieval is fast but approximate. A <strong>reranker</strong> takes the top-k results and re-scores them using a more powerful (but slower) model. This two-stage approach is the standard in production RAG:</p>
<ol class="arabic simple">
<li><p><strong>Stage 1 (Retriever)</strong>: Fast approximate search over millions of chunks → top-k candidates</p></li>
<li><p><strong>Stage 2 (Reranker)</strong>: Accurate scoring of k candidates → final ranked list</p></li>
</ol>
<p>The reranker sees the query and chunk together (cross-attention), unlike the embedder which encodes them independently.</p>
<p><strong>F1 analogy:</strong> This is exactly how F1 teams filter data during a race. Stage 1 is the quick database scan: “Pull all past situations involving tire degradation on a hot track.” That might return 50 results. Stage 2 is the senior strategist reviewing those 50 and saying, “Actually, only these 5 are truly comparable — the others were wet races or used different tire compounds.” The reranker applies deeper analysis to a smaller candidate set, just like the experienced engineer applying judgment to narrow down the relevant precedents.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">CrossEncoderReranker</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Simplified cross-encoder reranker.</span>
<span class="sd">    </span>
<span class="sd">    In production, use a fine-tuned cross-encoder like ms-marco-MiniLM.</span>
<span class="sd">    Here we simulate with a learned relevance scorer.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">embedder</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embedder</span> <span class="o">=</span> <span class="n">embedder</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">query</span><span class="p">,</span> <span class="n">chunk</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Score query-chunk relevance.</span>
<span class="sd">        </span>
<span class="sd">        Simulates a cross-encoder by computing multiple similarity features</span>
<span class="sd">        and combining them.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">q_emb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedder</span><span class="o">.</span><span class="n">embed</span><span class="p">(</span><span class="n">query</span><span class="p">)</span>
        <span class="n">c_emb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedder</span><span class="o">.</span><span class="n">embed</span><span class="p">(</span><span class="n">chunk</span><span class="p">)</span>
        
        <span class="c1"># Feature 1: Cosine similarity (same as retriever)</span>
        <span class="n">cosine_sim</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">q_emb</span><span class="p">,</span> <span class="n">c_emb</span><span class="p">)</span>
        
        <span class="c1"># Feature 2: Term overlap (keyword matching)</span>
        <span class="n">q_tokens</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">re</span><span class="o">.</span><span class="n">findall</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;\b[a-zA-Z]{2,}\b&#39;</span><span class="p">,</span> <span class="n">query</span><span class="o">.</span><span class="n">lower</span><span class="p">()))</span>
        <span class="n">c_tokens</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">re</span><span class="o">.</span><span class="n">findall</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;\b[a-zA-Z]{2,}\b&#39;</span><span class="p">,</span> <span class="n">chunk</span><span class="o">.</span><span class="n">lower</span><span class="p">()))</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">q_tokens</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">term_overlap</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">q_tokens</span> <span class="o">&amp;</span> <span class="n">c_tokens</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">q_tokens</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">term_overlap</span> <span class="o">=</span> <span class="mi">0</span>
        
        <span class="c1"># Feature 3: Chunk length penalty (prefer focused chunks)</span>
        <span class="n">length_penalty</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">chunk</span><span class="p">)</span> <span class="o">/</span> <span class="mi">1000</span><span class="p">)</span>
        
        <span class="c1"># Combined score (weighted)</span>
        <span class="n">score</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">cosine_sim</span> <span class="o">+</span> <span class="mf">0.35</span> <span class="o">*</span> <span class="n">term_overlap</span> <span class="o">+</span> <span class="mf">0.15</span> <span class="o">*</span> <span class="n">length_penalty</span>
        <span class="k">return</span> <span class="n">score</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">rerank</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">query</span><span class="p">,</span> <span class="n">results</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Rerank a list of retrieval results.&quot;&quot;&quot;</span>
        <span class="n">scored</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">results</span><span class="p">:</span>
            <span class="n">new_score</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">r</span><span class="p">[</span><span class="s1">&#39;chunk&#39;</span><span class="p">])</span>
            <span class="n">scored</span><span class="o">.</span><span class="n">append</span><span class="p">({</span><span class="o">**</span><span class="n">r</span><span class="p">,</span> <span class="s1">&#39;original_score&#39;</span><span class="p">:</span> <span class="n">r</span><span class="p">[</span><span class="s1">&#39;score&#39;</span><span class="p">],</span> <span class="s1">&#39;rerank_score&#39;</span><span class="p">:</span> <span class="n">new_score</span><span class="p">})</span>
        
        <span class="n">scored</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="s1">&#39;rerank_score&#39;</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">scored</span>


<span class="c1"># Demonstrate reranking</span>
<span class="n">reranker</span> <span class="o">=</span> <span class="n">CrossEncoderReranker</span><span class="p">(</span><span class="n">embedder</span><span class="p">)</span>

<span class="n">query</span> <span class="o">=</span> <span class="s2">&quot;How does the reward model work in RLHF?&quot;</span>
<span class="n">initial_results</span> <span class="o">=</span> <span class="n">store</span><span class="o">.</span><span class="n">search</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">top_k</span><span class="o">=</span><span class="mi">6</span><span class="p">)</span>
<span class="n">reranked_results</span> <span class="o">=</span> <span class="n">reranker</span><span class="o">.</span><span class="n">rerank</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">initial_results</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Query: &#39;</span><span class="si">{</span><span class="n">query</span><span class="si">}</span><span class="s2">&#39;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="s1">&#39;Rank&#39;</span><span class="si">:</span><span class="s2">&lt;5</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="s1">&#39;Original&#39;</span><span class="si">:</span><span class="s2">&gt;10</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="s1">&#39;Reranked&#39;</span><span class="si">:</span><span class="s2">&gt;10</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="s1">&#39;Source&#39;</span><span class="si">:</span><span class="s2">&lt;20</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="s1">&#39;Preview&#39;</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">r</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">reranked_results</span><span class="p">):</span>
    <span class="n">preview</span> <span class="o">=</span> <span class="n">r</span><span class="p">[</span><span class="s1">&#39;chunk&#39;</span><span class="p">][:</span><span class="mi">50</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="s1">&#39; &#39;</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;...&#39;</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">:</span><span class="s2">&lt;5</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">r</span><span class="p">[</span><span class="s1">&#39;original_score&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">10.4f</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">r</span><span class="p">[</span><span class="s1">&#39;rerank_score&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">10.4f</span><span class="si">}</span><span class="s2"> &quot;</span>
          <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">r</span><span class="p">[</span><span class="s1">&#39;metadata&#39;</span><span class="p">][</span><span class="s1">&#39;source&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">&lt;20</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">preview</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<hr class="docutils" />
<section id="evaluating-rag-systems">
<h2>7. Evaluating RAG Systems<a class="headerlink" href="#evaluating-rag-systems" title="Link to this heading">#</a></h2>
<p>RAG evaluation has two components:</p>
<section id="retrieval-metrics">
<h3>Retrieval Metrics<a class="headerlink" href="#retrieval-metrics" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>Precision&#64;k</strong>: Of the k retrieved chunks, how many are relevant?</p></li>
<li><p><strong>Recall&#64;k</strong>: Of all relevant chunks, how many were retrieved?</p></li>
<li><p><strong>MRR</strong> (Mean Reciprocal Rank): Where does the first relevant result appear?</p></li>
</ul>
</section>
<section id="generation-metrics">
<h3>Generation Metrics<a class="headerlink" href="#generation-metrics" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>Faithfulness</strong>: Does the answer stick to the retrieved context? (No hallucination)</p></li>
<li><p><strong>Relevance</strong>: Does the answer address the question?</p></li>
<li><p><strong>Groundedness</strong>: Can every claim be traced to a source chunk?</p></li>
</ul>
<p><strong>F1 analogy:</strong> Evaluating a RAG system is like evaluating the pit wall’s information delivery. <strong>Precision&#64;k</strong>: Of the 3 past race reports the system pulled up, how many were actually relevant to the current situation? <strong>Recall&#64;k</strong>: Were there other critical past situations the system missed? <strong>MRR</strong>: Was the most relevant historical race the first one shown, or buried at position 5? On the generation side, <strong>faithfulness</strong> asks: did the strategy recommendation actually follow from the retrieved data, or did the model hallucinate a recommendation not supported by the evidence?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">RAGEvaluator</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Evaluate RAG retrieval quality.&quot;&quot;&quot;</span>
    
    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">precision_at_k</span><span class="p">(</span><span class="n">retrieved_sources</span><span class="p">,</span> <span class="n">relevant_sources</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Fraction of retrieved items that are relevant.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">k</span><span class="p">:</span>
            <span class="n">retrieved_sources</span> <span class="o">=</span> <span class="n">retrieved_sources</span><span class="p">[:</span><span class="n">k</span><span class="p">]</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">retrieved_sources</span><span class="p">:</span>
            <span class="k">return</span> <span class="mf">0.0</span>
        <span class="n">relevant_count</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="mi">1</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">retrieved_sources</span> <span class="k">if</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">relevant_sources</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">relevant_count</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">retrieved_sources</span><span class="p">)</span>
    
    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">recall_at_k</span><span class="p">(</span><span class="n">retrieved_sources</span><span class="p">,</span> <span class="n">relevant_sources</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Fraction of relevant items that were retrieved.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">k</span><span class="p">:</span>
            <span class="n">retrieved_sources</span> <span class="o">=</span> <span class="n">retrieved_sources</span><span class="p">[:</span><span class="n">k</span><span class="p">]</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">relevant_sources</span><span class="p">:</span>
            <span class="k">return</span> <span class="mf">0.0</span>
        <span class="n">relevant_count</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="mi">1</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">retrieved_sources</span> <span class="k">if</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">relevant_sources</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">relevant_count</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">relevant_sources</span><span class="p">)</span>
    
    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">mrr</span><span class="p">(</span><span class="n">retrieved_sources</span><span class="p">,</span> <span class="n">relevant_sources</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Mean Reciprocal Rank: 1/rank of first relevant result.&quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">source</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">retrieved_sources</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">source</span> <span class="ow">in</span> <span class="n">relevant_sources</span><span class="p">:</span>
                <span class="k">return</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="mf">0.0</span>
    
    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">context_relevance</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">chunks</span><span class="p">,</span> <span class="n">embedder</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Average cosine similarity between query and retrieved chunks.&quot;&quot;&quot;</span>
        <span class="n">q_emb</span> <span class="o">=</span> <span class="n">embedder</span><span class="o">.</span><span class="n">embed</span><span class="p">(</span><span class="n">query</span><span class="p">)</span>
        <span class="n">sims</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">q_emb</span><span class="p">,</span> <span class="n">embedder</span><span class="o">.</span><span class="n">embed</span><span class="p">(</span><span class="n">chunk</span><span class="p">))</span> <span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="n">chunks</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">sims</span><span class="p">)</span>


<span class="c1"># Create evaluation dataset (query, expected relevant sources)</span>
<span class="n">eval_dataset</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">(</span><span class="s2">&quot;How does backpropagation work?&quot;</span><span class="p">,</span> <span class="p">{</span><span class="s2">&quot;neural_networks&quot;</span><span class="p">}),</span>
    <span class="p">(</span><span class="s2">&quot;What is self-attention?&quot;</span><span class="p">,</span> <span class="p">{</span><span class="s2">&quot;transformers&quot;</span><span class="p">}),</span>
    <span class="p">(</span><span class="s2">&quot;How is RLHF used?&quot;</span><span class="p">,</span> <span class="p">{</span><span class="s2">&quot;rlhf&quot;</span><span class="p">}),</span>
    <span class="p">(</span><span class="s2">&quot;What are word embeddings?&quot;</span><span class="p">,</span> <span class="p">{</span><span class="s2">&quot;embeddings&quot;</span><span class="p">}),</span>
    <span class="p">(</span><span class="s2">&quot;How does PPO optimize language models?&quot;</span><span class="p">,</span> <span class="p">{</span><span class="s2">&quot;rlhf&quot;</span><span class="p">}),</span>
    <span class="p">(</span><span class="s2">&quot;What is the transformer architecture?&quot;</span><span class="p">,</span> <span class="p">{</span><span class="s2">&quot;transformers&quot;</span><span class="p">}),</span>
    <span class="p">(</span><span class="s2">&quot;How do neural networks learn?&quot;</span><span class="p">,</span> <span class="p">{</span><span class="s2">&quot;neural_networks&quot;</span><span class="p">}),</span>
    <span class="p">(</span><span class="s2">&quot;What is cosine similarity?&quot;</span><span class="p">,</span> <span class="p">{</span><span class="s2">&quot;embeddings&quot;</span><span class="p">}),</span>
<span class="p">]</span>

<span class="n">evaluator</span> <span class="o">=</span> <span class="n">RAGEvaluator</span><span class="p">()</span>

<span class="c1"># Evaluate retrieval</span>
<span class="n">all_p1</span><span class="p">,</span> <span class="n">all_p3</span><span class="p">,</span> <span class="n">all_mrr</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">query</span><span class="p">,</span> <span class="n">relevant</span> <span class="ow">in</span> <span class="n">eval_dataset</span><span class="p">:</span>
    <span class="n">results</span> <span class="o">=</span> <span class="n">store</span><span class="o">.</span><span class="n">search</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">top_k</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
    <span class="n">retrieved</span> <span class="o">=</span> <span class="p">[</span><span class="n">r</span><span class="p">[</span><span class="s1">&#39;metadata&#39;</span><span class="p">][</span><span class="s1">&#39;source&#39;</span><span class="p">]</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">results</span><span class="p">]</span>
    
    <span class="n">p1</span> <span class="o">=</span> <span class="n">evaluator</span><span class="o">.</span><span class="n">precision_at_k</span><span class="p">(</span><span class="n">retrieved</span><span class="p">,</span> <span class="n">relevant</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">p3</span> <span class="o">=</span> <span class="n">evaluator</span><span class="o">.</span><span class="n">precision_at_k</span><span class="p">(</span><span class="n">retrieved</span><span class="p">,</span> <span class="n">relevant</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
    <span class="n">mrr</span> <span class="o">=</span> <span class="n">evaluator</span><span class="o">.</span><span class="n">mrr</span><span class="p">(</span><span class="n">retrieved</span><span class="p">,</span> <span class="n">relevant</span><span class="p">)</span>
    
    <span class="n">all_p1</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">p1</span><span class="p">)</span>
    <span class="n">all_p3</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">p3</span><span class="p">)</span>
    <span class="n">all_mrr</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">mrr</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;RAG Retrieval Evaluation:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Precision@1: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">all_p1</span><span class="p">)</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Precision@3: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">all_p3</span><span class="p">)</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  MRR:         </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">all_mrr</span><span class="p">)</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Visualize per-query retrieval performance</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">14</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>

<span class="c1"># Per-query metrics</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">eval_dataset</span><span class="p">))</span>
<span class="n">width</span> <span class="o">=</span> <span class="mf">0.25</span>
<span class="n">ax</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">width</span><span class="p">,</span> <span class="n">all_p1</span><span class="p">,</span> <span class="n">width</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;P@1&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;#3498db&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">all_p3</span><span class="p">,</span> <span class="n">width</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;P@3&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;#2ecc71&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="n">width</span><span class="p">,</span> <span class="n">all_mrr</span><span class="p">,</span> <span class="n">width</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;MRR&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;#e74c3c&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xticklabels</span><span class="p">([</span><span class="n">q</span><span class="p">[</span><span class="mi">0</span><span class="p">][:</span><span class="mi">20</span><span class="p">]</span> <span class="o">+</span> <span class="s1">&#39;...&#39;</span> <span class="k">for</span> <span class="n">q</span> <span class="ow">in</span> <span class="n">eval_dataset</span><span class="p">],</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">45</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;right&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Score&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Per-Query Retrieval Metrics&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">13</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="s1">&#39;y&#39;</span><span class="p">)</span>

<span class="c1"># Summary metrics</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">metrics</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;P@1&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">all_p1</span><span class="p">),</span> <span class="s1">&#39;P@3&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">all_p3</span><span class="p">),</span> <span class="s1">&#39;MRR&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">all_mrr</span><span class="p">)}</span>
<span class="n">colors</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;#3498db&#39;</span><span class="p">,</span> <span class="s1">&#39;#2ecc71&#39;</span><span class="p">,</span> <span class="s1">&#39;#e74c3c&#39;</span><span class="p">]</span>
<span class="n">bars</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">keys</span><span class="p">(),</span> <span class="n">metrics</span><span class="o">.</span><span class="n">values</span><span class="p">(),</span> <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span>
<span class="k">for</span> <span class="n">bar</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">bars</span><span class="p">,</span> <span class="n">metrics</span><span class="o">.</span><span class="n">values</span><span class="p">()):</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">bar</span><span class="o">.</span><span class="n">get_x</span><span class="p">()</span> <span class="o">+</span> <span class="n">bar</span><span class="o">.</span><span class="n">get_width</span><span class="p">()</span><span class="o">/</span><span class="mi">2</span><span class="p">,</span> <span class="n">bar</span><span class="o">.</span><span class="n">get_height</span><span class="p">()</span> <span class="o">+</span> <span class="mf">0.02</span><span class="p">,</span>
            <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">val</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Score&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Average Retrieval Metrics&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">13</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">1.1</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="s1">&#39;y&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<hr class="docutils" />
<section id="common-rag-failure-modes">
<h2>8. Common RAG Failure Modes<a class="headerlink" href="#common-rag-failure-modes" title="Link to this heading">#</a></h2>
<p>Understanding how RAG fails is as important as understanding how it works.</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Failure Mode</p></th>
<th class="head"><p>Cause</p></th>
<th class="head"><p>Fix</p></th>
<th class="head"><p>F1 Parallel</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>Missing context</strong></p></td>
<td><p>Relevant chunk not retrieved</p></td>
<td><p>Better chunking, more chunks, hybrid search</p></td>
<td><p>The database didn’t have data from a comparable race — need to expand the archive</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Wrong context</strong></p></td>
<td><p>Irrelevant chunks retrieved</p></td>
<td><p>Reranking, better embeddings, metadata filters</p></td>
<td><p>Pulling up a Monaco comparison when the current race is Monza — wrong track type entirely</p></td>
</tr>
<tr class="row-even"><td><p><strong>Lost in the middle</strong></p></td>
<td><p>LLM ignores middle context</p></td>
<td><p>Put important context first/last</p></td>
<td><p>The critical data point was buried in the third report — the strategist only read the first and last</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Hallucination</strong></p></td>
<td><p>LLM generates beyond context</p></td>
<td><p>Stronger prompting, faithfulness checks</p></td>
<td><p>The model recommends a three-stop strategy based on data that only supports two stops</p></td>
</tr>
<tr class="row-even"><td><p><strong>Chunk boundary</strong></p></td>
<td><p>Answer spans two chunks</p></td>
<td><p>Overlapping chunks, larger windows</p></td>
<td><p>Tire degradation data is in one chunk, weather data in another — the full picture requires both</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Embedding mismatch</strong></p></td>
<td><p>Query and doc use different vocabulary</p></td>
<td><p>Query expansion, hypothetical document embeddings</p></td>
<td><p>Engineer asks about “graining” but the report used “front tire surface degradation”</p></td>
</tr>
</tbody>
</table>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Demonstrate the &quot;chunk boundary&quot; problem</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;FAILURE MODE: Chunk Boundary Problem&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">50</span><span class="p">)</span>

<span class="c1"># Information split across chunks</span>
<span class="n">text</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;The transformer uses multi-head attention with 8 heads. Each head has dimension 64.</span>

<span class="s2">The total dimension is therefore 8 * 64 = 512, which is the model&#39;s hidden size.&quot;&quot;&quot;</span>

<span class="n">chunks</span> <span class="o">=</span> <span class="n">DocumentChunker</span><span class="o">.</span><span class="n">paragraph_based</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Original text answers: &#39;What is the total dimension?&#39;&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;But paragraph chunking splits it:&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">chunks</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Chunk </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">: &#39;</span><span class="si">{</span><span class="n">chunk</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="si">}</span><span class="s2">&#39;&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Chunk 0 has the components, Chunk 1 has the answer.&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Retrieving only one chunk misses the complete picture.&quot;</span><span class="p">)</span>

<span class="c1"># Fix: overlapping chunks</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">FIX: Sentence-based chunking with overlap&quot;</span><span class="p">)</span>
<span class="n">chunks_fixed</span> <span class="o">=</span> <span class="n">DocumentChunker</span><span class="o">.</span><span class="n">sentence_based</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">max_sentences</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">chunks_fixed</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Chunk </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">: &#39;</span><span class="si">{</span><span class="n">chunk</span><span class="o">.</span><span class="n">strip</span><span class="p">()[:</span><span class="mi">100</span><span class="p">]</span><span class="si">}</span><span class="s2">&#39;&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Demonstrate hybrid search (keyword + semantic)</span>
<span class="k">class</span><span class="w"> </span><span class="nc">HybridSearch</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Combine keyword (BM25-like) and semantic search.&quot;&quot;&quot;</span>
    
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vector_store</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">store</span> <span class="o">=</span> <span class="n">vector_store</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>  <span class="c1"># Weight for semantic vs keyword</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">keyword_score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">query</span><span class="p">,</span> <span class="n">chunk</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Simple keyword matching score (BM25 approximation).&quot;&quot;&quot;</span>
        <span class="n">q_tokens</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">re</span><span class="o">.</span><span class="n">findall</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;\b[a-zA-Z]{3,}\b&#39;</span><span class="p">,</span> <span class="n">query</span><span class="o">.</span><span class="n">lower</span><span class="p">()))</span>
        <span class="n">c_tokens</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">findall</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;\b[a-zA-Z]{3,}\b&#39;</span><span class="p">,</span> <span class="n">chunk</span><span class="o">.</span><span class="n">lower</span><span class="p">())</span>
        <span class="n">c_set</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">c_tokens</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="ow">not</span> <span class="n">q_tokens</span><span class="p">:</span>
            <span class="k">return</span> <span class="mf">0.0</span>
        
        <span class="c1"># Term frequency component</span>
        <span class="n">tf_score</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">q_tokens</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">c_set</span><span class="p">:</span>
                <span class="n">count</span> <span class="o">=</span> <span class="n">c_tokens</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="n">token</span><span class="p">)</span>
                <span class="n">tf_score</span> <span class="o">+=</span> <span class="n">count</span> <span class="o">/</span> <span class="p">(</span><span class="n">count</span> <span class="o">+</span> <span class="mf">1.0</span><span class="p">)</span>  <span class="c1"># Saturating TF</span>
        
        <span class="k">return</span> <span class="n">tf_score</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">q_tokens</span><span class="p">)</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">search</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">query</span><span class="p">,</span> <span class="n">top_k</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Hybrid search combining semantic and keyword scores.&quot;&quot;&quot;</span>
        <span class="c1"># Get all semantic scores</span>
        <span class="n">q_emb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">store</span><span class="o">.</span><span class="n">embedder</span><span class="o">.</span><span class="n">embed</span><span class="p">(</span><span class="n">query</span><span class="p">)</span>
        
        <span class="n">scored</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">emb</span><span class="p">,</span> <span class="n">doc</span><span class="p">,</span> <span class="n">meta</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">store</span><span class="o">.</span><span class="n">embeddings</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">store</span><span class="o">.</span><span class="n">documents</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">store</span><span class="o">.</span><span class="n">metadata</span>
        <span class="p">)):</span>
            <span class="n">semantic</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">q_emb</span><span class="p">,</span> <span class="n">emb</span><span class="p">)</span>
            <span class="n">keyword</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">keyword_score</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">doc</span><span class="p">)</span>
            <span class="n">combined</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">*</span> <span class="n">semantic</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">)</span> <span class="o">*</span> <span class="n">keyword</span>
            <span class="n">scored</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
                <span class="s1">&#39;chunk&#39;</span><span class="p">:</span> <span class="n">doc</span><span class="p">,</span> <span class="s1">&#39;score&#39;</span><span class="p">:</span> <span class="n">combined</span><span class="p">,</span>
                <span class="s1">&#39;semantic_score&#39;</span><span class="p">:</span> <span class="n">semantic</span><span class="p">,</span> <span class="s1">&#39;keyword_score&#39;</span><span class="p">:</span> <span class="n">keyword</span><span class="p">,</span>
                <span class="s1">&#39;metadata&#39;</span><span class="p">:</span> <span class="n">meta</span><span class="p">,</span> <span class="s1">&#39;index&#39;</span><span class="p">:</span> <span class="n">i</span>
            <span class="p">})</span>
        
        <span class="n">scored</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="s1">&#39;score&#39;</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">scored</span><span class="p">[:</span><span class="n">top_k</span><span class="p">]</span>


<span class="c1"># Compare semantic vs hybrid</span>
<span class="n">hybrid</span> <span class="o">=</span> <span class="n">HybridSearch</span><span class="p">(</span><span class="n">store</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">)</span>

<span class="n">query</span> <span class="o">=</span> <span class="s2">&quot;Bradley-Terry preference model&quot;</span>
<span class="n">semantic_results</span> <span class="o">=</span> <span class="n">store</span><span class="o">.</span><span class="n">search</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">top_k</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">hybrid_results</span> <span class="o">=</span> <span class="n">hybrid</span><span class="o">.</span><span class="n">search</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">top_k</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Query: &#39;</span><span class="si">{</span><span class="n">query</span><span class="si">}</span><span class="s2">&#39;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Semantic search:&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">semantic_results</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  [</span><span class="si">{</span><span class="n">r</span><span class="p">[</span><span class="s1">&#39;score&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">] </span><span class="si">{</span><span class="n">r</span><span class="p">[</span><span class="s1">&#39;metadata&#39;</span><span class="p">][</span><span class="s1">&#39;source&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Hybrid search:&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">hybrid_results</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  [</span><span class="si">{</span><span class="n">r</span><span class="p">[</span><span class="s1">&#39;score&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">] sem=</span><span class="si">{</span><span class="n">r</span><span class="p">[</span><span class="s1">&#39;semantic_score&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2"> kw=</span><span class="si">{</span><span class="n">r</span><span class="p">[</span><span class="s1">&#39;keyword_score&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2"> &quot;</span>
          <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">r</span><span class="p">[</span><span class="s1">&#39;metadata&#39;</span><span class="p">][</span><span class="s1">&#39;source&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<hr class="docutils" />
<section id="advanced-rag-patterns">
<h2>9. Advanced RAG Patterns<a class="headerlink" href="#advanced-rag-patterns" title="Link to this heading">#</a></h2>
<p>Production RAG systems go beyond basic retrieve-and-generate:</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Pattern</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>When to Use</p></th>
<th class="head"><p>F1 Parallel</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>Query expansion</strong></p></td>
<td><p>Rewrite query for better retrieval</p></td>
<td><p>Ambiguous or short queries</p></td>
<td><p>Engineer says “tires” — expand to “tire degradation compound temperature graining blistering”</p></td>
</tr>
<tr class="row-odd"><td><p><strong>HyDE</strong></p></td>
<td><p>Generate hypothetical answer, embed that</p></td>
<td><p>Query-document vocabulary mismatch</p></td>
<td><p>Generate what a good race report <em>would</em> say, then find actual reports like it</p></td>
</tr>
<tr class="row-even"><td><p><strong>Multi-step RAG</strong></p></td>
<td><p>Retrieve → reason → retrieve again</p></td>
<td><p>Complex multi-hop questions</p></td>
<td><p>“Find races with similar weather, then from those find ones with similar tire strategy outcomes”</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Parent-child chunking</strong></p></td>
<td><p>Retrieve small chunks, return parent</p></td>
<td><p>Need precision + context</p></td>
<td><p>Find the exact sentence about tire life, but return the full strategy section for context</p></td>
</tr>
<tr class="row-even"><td><p><strong>Metadata filtering</strong></p></td>
<td><p>Filter by date, source, category</p></td>
<td><p>Large corpora with structure</p></td>
<td><p>Only search races from this season, or only search data from this specific circuit</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Agentic RAG</strong></p></td>
<td><p>Agent decides when/what to retrieve</p></td>
<td><p>Open-ended tasks</p></td>
<td><p>The strategy model decides whether it needs historical data or can answer from current telemetry alone</p></td>
</tr>
<tr class="row-even"><td><p><strong>KG-RAG</strong></p></td>
<td><p>Knowledge graph triples + vector search</p></td>
<td><p>Relational and multi-hop queries</p></td>
<td><p>The team’s wiring diagram: Verstappen → drives for → Red Bull → uses → Honda engine. Vector search finds similar <em>text</em>, the graph follows explicit <em>connections</em></p></td>
</tr>
</tbody>
</table>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Implement HyDE (Hypothetical Document Embeddings)</span>
<span class="k">class</span><span class="w"> </span><span class="nc">HyDE</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Hypothetical Document Embeddings.</span>
<span class="sd">    </span>
<span class="sd">    Instead of embedding the query directly, generate a hypothetical answer</span>
<span class="sd">    and embed THAT. The hypothetical answer will use vocabulary closer to</span>
<span class="sd">    the actual documents.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vector_store</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">store</span> <span class="o">=</span> <span class="n">vector_store</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">generate_hypothetical</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">query</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Simulate generating a hypothetical answer.</span>
<span class="sd">        In production, this would use an LLM.&quot;&quot;&quot;</span>
        <span class="c1"># Simple simulation: expand query with related terms</span>
        <span class="n">expansions</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s1">&#39;attention&#39;</span><span class="p">:</span> <span class="s1">&#39;self-attention computes query key value matrices dot product softmax weights&#39;</span><span class="p">,</span>
            <span class="s1">&#39;backprop&#39;</span><span class="p">:</span> <span class="s1">&#39;backpropagation chain rule gradients loss function weights update&#39;</span><span class="p">,</span>
            <span class="s1">&#39;rlhf&#39;</span><span class="p">:</span> <span class="s1">&#39;reinforcement learning human feedback reward model PPO policy optimization&#39;</span><span class="p">,</span>
            <span class="s1">&#39;embedding&#39;</span><span class="p">:</span> <span class="s1">&#39;word embeddings dense vectors semantic similarity cosine distance&#39;</span><span class="p">,</span>
        <span class="p">}</span>
        
        <span class="n">hypothetical</span> <span class="o">=</span> <span class="n">query</span>
        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">expansion</span> <span class="ow">in</span> <span class="n">expansions</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">query</span><span class="o">.</span><span class="n">lower</span><span class="p">():</span>
                <span class="n">hypothetical</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">query</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">expansion</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="k">break</span>
        
        <span class="k">return</span> <span class="n">hypothetical</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">search</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">query</span><span class="p">,</span> <span class="n">top_k</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Search using hypothetical document embedding.&quot;&quot;&quot;</span>
        <span class="n">hypothetical</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">generate_hypothetical</span><span class="p">(</span><span class="n">query</span><span class="p">)</span>
        
        <span class="c1"># Embed the hypothetical answer instead of the raw query</span>
        <span class="n">query_emb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">store</span><span class="o">.</span><span class="n">embedder</span><span class="o">.</span><span class="n">embed</span><span class="p">(</span><span class="n">hypothetical</span><span class="p">)</span>
        
        <span class="n">similarities</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span>
            <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">query_emb</span><span class="p">,</span> <span class="n">emb</span><span class="p">)</span> <span class="k">for</span> <span class="n">emb</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">store</span><span class="o">.</span><span class="n">embeddings</span>
        <span class="p">])</span>
        
        <span class="n">top_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">similarities</span><span class="p">)[::</span><span class="o">-</span><span class="mi">1</span><span class="p">][:</span><span class="n">top_k</span><span class="p">]</span>
        <span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">top_indices</span><span class="p">:</span>
            <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
                <span class="s1">&#39;chunk&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">store</span><span class="o">.</span><span class="n">documents</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span>
                <span class="s1">&#39;score&#39;</span><span class="p">:</span> <span class="n">similarities</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span>
                <span class="s1">&#39;metadata&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">store</span><span class="o">.</span><span class="n">metadata</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span>
            <span class="p">})</span>
        <span class="k">return</span> <span class="n">results</span>


<span class="n">hyde</span> <span class="o">=</span> <span class="n">HyDE</span><span class="p">(</span><span class="n">store</span><span class="p">)</span>
<span class="n">query</span> <span class="o">=</span> <span class="s2">&quot;How does attention work?&quot;</span>

<span class="n">normal_results</span> <span class="o">=</span> <span class="n">store</span><span class="o">.</span><span class="n">search</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">top_k</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">hyde_results</span> <span class="o">=</span> <span class="n">hyde</span><span class="o">.</span><span class="n">search</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">top_k</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Query: &#39;</span><span class="si">{</span><span class="n">query</span><span class="si">}</span><span class="s2">&#39;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Standard retrieval:&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">normal_results</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  [</span><span class="si">{</span><span class="n">r</span><span class="p">[</span><span class="s1">&#39;score&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">] </span><span class="si">{</span><span class="n">r</span><span class="p">[</span><span class="s1">&#39;metadata&#39;</span><span class="p">][</span><span class="s1">&#39;source&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">HyDE retrieval:&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">hyde_results</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  [</span><span class="si">{</span><span class="n">r</span><span class="p">[</span><span class="s1">&#39;score&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">] </span><span class="si">{</span><span class="n">r</span><span class="p">[</span><span class="s1">&#39;metadata&#39;</span><span class="p">][</span><span class="s1">&#39;source&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<hr class="docutils" />
<section id="knowledge-graph-rag">
<h2>10. Knowledge Graph RAG<a class="headerlink" href="#knowledge-graph-rag" title="Link to this heading">#</a></h2>
<p>Vector search finds documents that are <em>similar</em> to a query, but it can’t follow <em>relationships</em>. Ask “What optimizer trains the model that uses attention?” and vector search will find chunks mentioning optimizers and chunks mentioning attention — but it can’t <em>connect</em> them through the reasoning chain: Transformer → uses → attention, Adam → trains → Transformer.</p>
<p><strong>Knowledge Graph RAG (KG-RAG)</strong> solves this by maintaining a structured graph of entities and their relationships as <strong>(subject, predicate, object) triples</strong> — e.g., <code class="docutils literal notranslate"><span class="pre">(&quot;backpropagation&quot;,</span> <span class="pre">&quot;uses&quot;,</span> <span class="pre">&quot;chain</span> <span class="pre">rule&quot;)</span></code>. At query time, the system extracts entities from the query, traverses the graph to find related entities, and combines graph-sourced context with vector-retrieved chunks.</p>
<p><strong>F1 analogy:</strong> The knowledge graph is the team’s wiring diagram of how everything connects — drivers → teams → engines → circuits → regulations. Vector search finds similar <em>descriptions</em> (e.g., reports that <em>mention</em> Red Bull), but the graph knows that “Verstappen drives for Red Bull which uses a Honda engine” as explicit linked facts. When the engineer asks “What engine does Verstappen’s team use?”, the graph traverses: Verstappen → drives for → Red Bull → uses → Honda. No amount of text similarity search can replicate that structured reasoning.</p>
<section id="vector-rag-vs-kg-rag-vs-hybrid">
<h3>Vector RAG vs. KG-RAG vs. Hybrid<a class="headerlink" href="#vector-rag-vs-kg-rag-vs-hybrid" title="Link to this heading">#</a></h3>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Dimension</p></th>
<th class="head"><p>Vector RAG</p></th>
<th class="head"><p>KG-RAG</p></th>
<th class="head"><p>Hybrid (Vector + KG)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>Strength</strong></p></td>
<td><p>Semantic similarity, fuzzy matching</p></td>
<td><p>Relational reasoning, multi-hop queries</p></td>
<td><p>Best of both</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Weakness</strong></p></td>
<td><p>Can’t follow relationships</p></td>
<td><p>Requires structured graph, brittle entity matching</p></td>
<td><p>More complex to build</p></td>
</tr>
<tr class="row-even"><td><p><strong>Query type</strong></p></td>
<td><p>“Tell me about attention mechanisms”</p></td>
<td><p>“What algorithm uses the chain rule?”</p></td>
<td><p>Both types</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Data structure</strong></p></td>
<td><p>Unstructured text → vectors</p></td>
<td><p>(subject, predicate, object) triples</p></td>
<td><p>Both</p></td>
</tr>
<tr class="row-even"><td><p><strong>F1 example</strong></p></td>
<td><p>“Find races similar to today’s conditions”</p></td>
<td><p>“What engine does Verstappen’s team use?”</p></td>
<td><p>“Find similar races involving Honda-powered teams”</p></td>
</tr>
</tbody>
</table>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">KnowledgeGraph</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A simple knowledge graph storing (subject, predicate, object) triples.</span>
<span class="sd">    </span>
<span class="sd">    In production, you&#39;d use Neo4j, Amazon Neptune, or a similar graph database.</span>
<span class="sd">    Here we build one from scratch to demonstrate KG-RAG mechanics.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">triples</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># List of (subject, predicate, object)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">adjacency</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">list</span><span class="p">)</span>  <span class="c1"># entity -&gt; [(predicate, neighbor)]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">entities</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">add_triple</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">subject</span><span class="p">,</span> <span class="n">predicate</span><span class="p">,</span> <span class="n">obj</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Add a (subject, predicate, object) triple to the graph.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">triples</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">subject</span><span class="p">,</span> <span class="n">predicate</span><span class="p">,</span> <span class="n">obj</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">adjacency</span><span class="p">[</span><span class="n">subject</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">predicate</span><span class="p">,</span> <span class="n">obj</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">adjacency</span><span class="p">[</span><span class="n">obj</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">predicate</span> <span class="o">+</span> <span class="s2">&quot; (inv)&quot;</span><span class="p">,</span> <span class="n">subject</span><span class="p">))</span>  <span class="c1"># Inverse edge</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">entities</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">subject</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">entities</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">obj</span><span class="p">)</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">get_neighbors</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">entity</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get all directly connected entities.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">adjacency</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">entity</span><span class="p">,</span> <span class="p">[])</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">traverse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">entity</span><span class="p">,</span> <span class="n">hops</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;BFS traversal from an entity up to `hops` edges away.</span>
<span class="sd">        </span>
<span class="sd">        Returns all discovered entities and the paths taken.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">visited</span> <span class="o">=</span> <span class="p">{</span><span class="n">entity</span><span class="p">}</span>
        <span class="n">frontier</span> <span class="o">=</span> <span class="p">[(</span><span class="n">entity</span><span class="p">,</span> <span class="p">[])]</span>  <span class="c1"># (current_entity, path_of_triples)</span>
        <span class="n">all_paths</span> <span class="o">=</span> <span class="p">[]</span>
        
        <span class="k">for</span> <span class="n">hop</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">hops</span><span class="p">):</span>
            <span class="n">next_frontier</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">current</span><span class="p">,</span> <span class="n">path</span> <span class="ow">in</span> <span class="n">frontier</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">predicate</span><span class="p">,</span> <span class="n">neighbor</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_neighbors</span><span class="p">(</span><span class="n">current</span><span class="p">):</span>
                    <span class="k">if</span> <span class="n">neighbor</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">visited</span><span class="p">:</span>
                        <span class="n">visited</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">neighbor</span><span class="p">)</span>
                        <span class="n">new_path</span> <span class="o">=</span> <span class="n">path</span> <span class="o">+</span> <span class="p">[(</span><span class="n">current</span><span class="p">,</span> <span class="n">predicate</span><span class="p">,</span> <span class="n">neighbor</span><span class="p">)]</span>
                        <span class="n">all_paths</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">new_path</span><span class="p">)</span>
                        <span class="n">next_frontier</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">neighbor</span><span class="p">,</span> <span class="n">new_path</span><span class="p">))</span>
            <span class="n">frontier</span> <span class="o">=</span> <span class="n">next_frontier</span>
        
        <span class="k">return</span> <span class="n">visited</span><span class="p">,</span> <span class="n">all_paths</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">search</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">query_entities</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Find all triples involving any of the query entities.&quot;&quot;&quot;</span>
        <span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">subj</span><span class="p">,</span> <span class="n">pred</span><span class="p">,</span> <span class="n">obj</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">triples</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">subj</span> <span class="ow">in</span> <span class="n">query_entities</span> <span class="ow">or</span> <span class="n">obj</span> <span class="ow">in</span> <span class="n">query_entities</span><span class="p">:</span>
                <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">subj</span><span class="p">,</span> <span class="n">pred</span><span class="p">,</span> <span class="n">obj</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">results</span>


<span class="c1"># Build a knowledge graph from our document corpus</span>
<span class="n">kg</span> <span class="o">=</span> <span class="n">KnowledgeGraph</span><span class="p">()</span>

<span class="c1"># Extract triples that capture relationships across our documents</span>
<span class="c1"># Neural networks</span>
<span class="n">kg</span><span class="o">.</span><span class="n">add_triple</span><span class="p">(</span><span class="s2">&quot;neural network&quot;</span><span class="p">,</span> <span class="s2">&quot;contains&quot;</span><span class="p">,</span> <span class="s2">&quot;neurons&quot;</span><span class="p">)</span>
<span class="n">kg</span><span class="o">.</span><span class="n">add_triple</span><span class="p">(</span><span class="s2">&quot;neural network&quot;</span><span class="p">,</span> <span class="s2">&quot;trained by&quot;</span><span class="p">,</span> <span class="s2">&quot;backpropagation&quot;</span><span class="p">)</span>
<span class="n">kg</span><span class="o">.</span><span class="n">add_triple</span><span class="p">(</span><span class="s2">&quot;backpropagation&quot;</span><span class="p">,</span> <span class="s2">&quot;uses&quot;</span><span class="p">,</span> <span class="s2">&quot;chain rule&quot;</span><span class="p">)</span>
<span class="n">kg</span><span class="o">.</span><span class="n">add_triple</span><span class="p">(</span><span class="s2">&quot;backpropagation&quot;</span><span class="p">,</span> <span class="s2">&quot;computes&quot;</span><span class="p">,</span> <span class="s2">&quot;gradients&quot;</span><span class="p">)</span>
<span class="n">kg</span><span class="o">.</span><span class="n">add_triple</span><span class="p">(</span><span class="s2">&quot;gradients&quot;</span><span class="p">,</span> <span class="s2">&quot;used by&quot;</span><span class="p">,</span> <span class="s2">&quot;SGD&quot;</span><span class="p">)</span>
<span class="n">kg</span><span class="o">.</span><span class="n">add_triple</span><span class="p">(</span><span class="s2">&quot;gradients&quot;</span><span class="p">,</span> <span class="s2">&quot;used by&quot;</span><span class="p">,</span> <span class="s2">&quot;Adam&quot;</span><span class="p">)</span>
<span class="n">kg</span><span class="o">.</span><span class="n">add_triple</span><span class="p">(</span><span class="s2">&quot;deep learning&quot;</span><span class="p">,</span> <span class="s2">&quot;is a&quot;</span><span class="p">,</span> <span class="s2">&quot;neural network&quot;</span><span class="p">)</span>
<span class="n">kg</span><span class="o">.</span><span class="n">add_triple</span><span class="p">(</span><span class="s2">&quot;deep learning&quot;</span><span class="p">,</span> <span class="s2">&quot;learns&quot;</span><span class="p">,</span> <span class="s2">&quot;hierarchical representations&quot;</span><span class="p">)</span>

<span class="c1"># Transformers</span>
<span class="n">kg</span><span class="o">.</span><span class="n">add_triple</span><span class="p">(</span><span class="s2">&quot;Transformer&quot;</span><span class="p">,</span> <span class="s2">&quot;uses&quot;</span><span class="p">,</span> <span class="s2">&quot;self-attention&quot;</span><span class="p">)</span>
<span class="n">kg</span><span class="o">.</span><span class="n">add_triple</span><span class="p">(</span><span class="s2">&quot;self-attention&quot;</span><span class="p">,</span> <span class="s2">&quot;computes&quot;</span><span class="p">,</span> <span class="s2">&quot;Q K V matrices&quot;</span><span class="p">)</span>
<span class="n">kg</span><span class="o">.</span><span class="n">add_triple</span><span class="p">(</span><span class="s2">&quot;self-attention&quot;</span><span class="p">,</span> <span class="s2">&quot;uses&quot;</span><span class="p">,</span> <span class="s2">&quot;dot product&quot;</span><span class="p">)</span>
<span class="n">kg</span><span class="o">.</span><span class="n">add_triple</span><span class="p">(</span><span class="s2">&quot;self-attention&quot;</span><span class="p">,</span> <span class="s2">&quot;uses&quot;</span><span class="p">,</span> <span class="s2">&quot;softmax&quot;</span><span class="p">)</span>
<span class="n">kg</span><span class="o">.</span><span class="n">add_triple</span><span class="p">(</span><span class="s2">&quot;Transformer&quot;</span><span class="p">,</span> <span class="s2">&quot;uses&quot;</span><span class="p">,</span> <span class="s2">&quot;positional encoding&quot;</span><span class="p">)</span>
<span class="n">kg</span><span class="o">.</span><span class="n">add_triple</span><span class="p">(</span><span class="s2">&quot;Transformer&quot;</span><span class="p">,</span> <span class="s2">&quot;uses&quot;</span><span class="p">,</span> <span class="s2">&quot;layer normalization&quot;</span><span class="p">)</span>
<span class="n">kg</span><span class="o">.</span><span class="n">add_triple</span><span class="p">(</span><span class="s2">&quot;Transformer&quot;</span><span class="p">,</span> <span class="s2">&quot;uses&quot;</span><span class="p">,</span> <span class="s2">&quot;residual connections&quot;</span><span class="p">)</span>
<span class="n">kg</span><span class="o">.</span><span class="n">add_triple</span><span class="p">(</span><span class="s2">&quot;multi-head attention&quot;</span><span class="p">,</span> <span class="s2">&quot;is a&quot;</span><span class="p">,</span> <span class="s2">&quot;self-attention&quot;</span><span class="p">)</span>

<span class="c1"># RLHF</span>
<span class="n">kg</span><span class="o">.</span><span class="n">add_triple</span><span class="p">(</span><span class="s2">&quot;RLHF&quot;</span><span class="p">,</span> <span class="s2">&quot;stage 1&quot;</span><span class="p">,</span> <span class="s2">&quot;SFT&quot;</span><span class="p">)</span>
<span class="n">kg</span><span class="o">.</span><span class="n">add_triple</span><span class="p">(</span><span class="s2">&quot;RLHF&quot;</span><span class="p">,</span> <span class="s2">&quot;stage 2&quot;</span><span class="p">,</span> <span class="s2">&quot;reward model&quot;</span><span class="p">)</span>
<span class="n">kg</span><span class="o">.</span><span class="n">add_triple</span><span class="p">(</span><span class="s2">&quot;RLHF&quot;</span><span class="p">,</span> <span class="s2">&quot;stage 3&quot;</span><span class="p">,</span> <span class="s2">&quot;PPO&quot;</span><span class="p">)</span>
<span class="n">kg</span><span class="o">.</span><span class="n">add_triple</span><span class="p">(</span><span class="s2">&quot;reward model&quot;</span><span class="p">,</span> <span class="s2">&quot;uses&quot;</span><span class="p">,</span> <span class="s2">&quot;Bradley-Terry&quot;</span><span class="p">)</span>
<span class="n">kg</span><span class="o">.</span><span class="n">add_triple</span><span class="p">(</span><span class="s2">&quot;PPO&quot;</span><span class="p">,</span> <span class="s2">&quot;uses&quot;</span><span class="p">,</span> <span class="s2">&quot;KL penalty&quot;</span><span class="p">)</span>
<span class="n">kg</span><span class="o">.</span><span class="n">add_triple</span><span class="p">(</span><span class="s2">&quot;DPO&quot;</span><span class="p">,</span> <span class="s2">&quot;alternative to&quot;</span><span class="p">,</span> <span class="s2">&quot;RLHF&quot;</span><span class="p">)</span>
<span class="n">kg</span><span class="o">.</span><span class="n">add_triple</span><span class="p">(</span><span class="s2">&quot;RLHF&quot;</span><span class="p">,</span> <span class="s2">&quot;aligns&quot;</span><span class="p">,</span> <span class="s2">&quot;language model&quot;</span><span class="p">)</span>

<span class="c1"># Embeddings</span>
<span class="n">kg</span><span class="o">.</span><span class="n">add_triple</span><span class="p">(</span><span class="s2">&quot;Word2Vec&quot;</span><span class="p">,</span> <span class="s2">&quot;method&quot;</span><span class="p">,</span> <span class="s2">&quot;Skip-gram&quot;</span><span class="p">)</span>
<span class="n">kg</span><span class="o">.</span><span class="n">add_triple</span><span class="p">(</span><span class="s2">&quot;Word2Vec&quot;</span><span class="p">,</span> <span class="s2">&quot;method&quot;</span><span class="p">,</span> <span class="s2">&quot;CBOW&quot;</span><span class="p">)</span>
<span class="n">kg</span><span class="o">.</span><span class="n">add_triple</span><span class="p">(</span><span class="s2">&quot;Word2Vec&quot;</span><span class="p">,</span> <span class="s2">&quot;produces&quot;</span><span class="p">,</span> <span class="s2">&quot;word embeddings&quot;</span><span class="p">)</span>
<span class="n">kg</span><span class="o">.</span><span class="n">add_triple</span><span class="p">(</span><span class="s2">&quot;sentence transformer&quot;</span><span class="p">,</span> <span class="s2">&quot;produces&quot;</span><span class="p">,</span> <span class="s2">&quot;sentence embeddings&quot;</span><span class="p">)</span>
<span class="n">kg</span><span class="o">.</span><span class="n">add_triple</span><span class="p">(</span><span class="s2">&quot;embeddings&quot;</span><span class="p">,</span> <span class="s2">&quot;compared by&quot;</span><span class="p">,</span> <span class="s2">&quot;cosine similarity&quot;</span><span class="p">)</span>
<span class="n">kg</span><span class="o">.</span><span class="n">add_triple</span><span class="p">(</span><span class="s2">&quot;BERT&quot;</span><span class="p">,</span> <span class="s2">&quot;produces&quot;</span><span class="p">,</span> <span class="s2">&quot;contextual embeddings&quot;</span><span class="p">)</span>
<span class="n">kg</span><span class="o">.</span><span class="n">add_triple</span><span class="p">(</span><span class="s2">&quot;embeddings&quot;</span><span class="p">,</span> <span class="s2">&quot;enables&quot;</span><span class="p">,</span> <span class="s2">&quot;semantic search&quot;</span><span class="p">)</span>

<span class="c1"># Cross-document connections (this is where KG shines!)</span>
<span class="n">kg</span><span class="o">.</span><span class="n">add_triple</span><span class="p">(</span><span class="s2">&quot;Transformer&quot;</span><span class="p">,</span> <span class="s2">&quot;trained by&quot;</span><span class="p">,</span> <span class="s2">&quot;backpropagation&quot;</span><span class="p">)</span>
<span class="n">kg</span><span class="o">.</span><span class="n">add_triple</span><span class="p">(</span><span class="s2">&quot;language model&quot;</span><span class="p">,</span> <span class="s2">&quot;is a&quot;</span><span class="p">,</span> <span class="s2">&quot;Transformer&quot;</span><span class="p">)</span>
<span class="n">kg</span><span class="o">.</span><span class="n">add_triple</span><span class="p">(</span><span class="s2">&quot;BERT&quot;</span><span class="p">,</span> <span class="s2">&quot;is a&quot;</span><span class="p">,</span> <span class="s2">&quot;Transformer&quot;</span><span class="p">)</span>
<span class="n">kg</span><span class="o">.</span><span class="n">add_triple</span><span class="p">(</span><span class="s2">&quot;sentence transformer&quot;</span><span class="p">,</span> <span class="s2">&quot;fine-tuned from&quot;</span><span class="p">,</span> <span class="s2">&quot;Transformer&quot;</span><span class="p">)</span>
<span class="n">kg</span><span class="o">.</span><span class="n">add_triple</span><span class="p">(</span><span class="s2">&quot;RAG&quot;</span><span class="p">,</span> <span class="s2">&quot;uses&quot;</span><span class="p">,</span> <span class="s2">&quot;embeddings&quot;</span><span class="p">)</span>
<span class="n">kg</span><span class="o">.</span><span class="n">add_triple</span><span class="p">(</span><span class="s2">&quot;RAG&quot;</span><span class="p">,</span> <span class="s2">&quot;uses&quot;</span><span class="p">,</span> <span class="s2">&quot;semantic search&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Knowledge Graph built:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Entities: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">kg</span><span class="o">.</span><span class="n">entities</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Triples:  </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">kg</span><span class="o">.</span><span class="n">triples</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Sample entities: </span><span class="si">{</span><span class="nb">sorted</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">kg</span><span class="o">.</span><span class="n">entities</span><span class="p">))[:</span><span class="mi">10</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Show neighbors for a sample entity</span>
<span class="n">entity</span> <span class="o">=</span> <span class="s2">&quot;backpropagation&quot;</span>
<span class="n">neighbors</span> <span class="o">=</span> <span class="n">kg</span><span class="o">.</span><span class="n">get_neighbors</span><span class="p">(</span><span class="n">entity</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Neighbors of &#39;</span><span class="si">{</span><span class="n">entity</span><span class="si">}</span><span class="s2">&#39;:&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">pred</span><span class="p">,</span> <span class="n">neighbor</span> <span class="ow">in</span> <span class="n">neighbors</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  --[</span><span class="si">{</span><span class="n">pred</span><span class="si">}</span><span class="s2">]--&gt; </span><span class="si">{</span><span class="n">neighbor</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">KGRAGPipeline</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Combines knowledge graph traversal with vector retrieval.</span>
<span class="sd">    </span>
<span class="sd">    The pipeline:</span>
<span class="sd">    1. Extract known entities from the query</span>
<span class="sd">    2. Traverse the graph to find related entities (1-2 hops)</span>
<span class="sd">    3. Use graph context to expand the vector search</span>
<span class="sd">    4. Combine graph-sourced triples with vector-retrieved chunks</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">knowledge_graph</span><span class="p">,</span> <span class="n">vector_store</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">kg</span> <span class="o">=</span> <span class="n">knowledge_graph</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">store</span> <span class="o">=</span> <span class="n">vector_store</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">extract_entities</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">query</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Find known graph entities mentioned in the query.&quot;&quot;&quot;</span>
        <span class="n">query_lower</span> <span class="o">=</span> <span class="n">query</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
        <span class="n">found</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">entity</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">kg</span><span class="o">.</span><span class="n">entities</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">entity</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="ow">in</span> <span class="n">query_lower</span><span class="p">:</span>
                <span class="n">found</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">entity</span><span class="p">)</span>
        <span class="c1"># Sort by length descending to prefer longer (more specific) matches</span>
        <span class="n">found</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">key</span><span class="o">=</span><span class="nb">len</span><span class="p">,</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">found</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">query</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">question</span><span class="p">,</span> <span class="n">hops</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">vector_top_k</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Full KG-RAG pipeline: graph traversal + vector retrieval.&quot;&quot;&quot;</span>
        <span class="c1"># Step 1: Extract entities from the query</span>
        <span class="n">entities</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">extract_entities</span><span class="p">(</span><span class="n">question</span><span class="p">)</span>
        
        <span class="c1"># Step 2: Traverse the graph from each entity</span>
        <span class="n">graph_context</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">all_related_entities</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
        <span class="n">all_paths</span> <span class="o">=</span> <span class="p">[]</span>
        
        <span class="k">for</span> <span class="n">entity</span> <span class="ow">in</span> <span class="n">entities</span><span class="p">:</span>
            <span class="n">visited</span><span class="p">,</span> <span class="n">paths</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">kg</span><span class="o">.</span><span class="n">traverse</span><span class="p">(</span><span class="n">entity</span><span class="p">,</span> <span class="n">hops</span><span class="o">=</span><span class="n">hops</span><span class="p">)</span>
            <span class="n">all_related_entities</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">visited</span><span class="p">)</span>
            <span class="n">all_paths</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">paths</span><span class="p">)</span>
            
            <span class="c1"># Collect direct triples as context</span>
            <span class="k">for</span> <span class="n">pred</span><span class="p">,</span> <span class="n">neighbor</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">kg</span><span class="o">.</span><span class="n">get_neighbors</span><span class="p">(</span><span class="n">entity</span><span class="p">):</span>
                <span class="n">graph_context</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">entity</span><span class="si">}</span><span class="s2"> --[</span><span class="si">{</span><span class="n">pred</span><span class="si">}</span><span class="s2">]--&gt; </span><span class="si">{</span><span class="n">neighbor</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        
        <span class="c1"># Step 3: Expand query with related entities for vector search</span>
        <span class="n">expanded_query</span> <span class="o">=</span> <span class="n">question</span> <span class="o">+</span> <span class="s2">&quot; &quot;</span> <span class="o">+</span> <span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">all_related_entities</span><span class="p">)</span>
        <span class="n">vector_results</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">store</span><span class="o">.</span><span class="n">search</span><span class="p">(</span><span class="n">expanded_query</span><span class="p">,</span> <span class="n">top_k</span><span class="o">=</span><span class="n">vector_top_k</span><span class="p">)</span>
        
        <span class="c1"># Step 4: Also get standard (unexpanded) vector results for comparison</span>
        <span class="n">standard_results</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">store</span><span class="o">.</span><span class="n">search</span><span class="p">(</span><span class="n">question</span><span class="p">,</span> <span class="n">top_k</span><span class="o">=</span><span class="n">vector_top_k</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="p">{</span>
            <span class="s1">&#39;query_entities&#39;</span><span class="p">:</span> <span class="n">entities</span><span class="p">,</span>
            <span class="s1">&#39;related_entities&#39;</span><span class="p">:</span> <span class="n">all_related_entities</span><span class="p">,</span>
            <span class="s1">&#39;graph_context&#39;</span><span class="p">:</span> <span class="n">graph_context</span><span class="p">,</span>
            <span class="s1">&#39;graph_paths&#39;</span><span class="p">:</span> <span class="n">all_paths</span><span class="p">,</span>
            <span class="s1">&#39;kg_vector_results&#39;</span><span class="p">:</span> <span class="n">vector_results</span><span class="p">,</span>      <span class="c1"># Graph-expanded retrieval</span>
            <span class="s1">&#39;standard_vector_results&#39;</span><span class="p">:</span> <span class="n">standard_results</span><span class="p">,</span>  <span class="c1"># Standard retrieval</span>
        <span class="p">}</span>


<span class="c1"># Build the KG-RAG pipeline</span>
<span class="n">kg_rag</span> <span class="o">=</span> <span class="n">KGRAGPipeline</span><span class="p">(</span><span class="n">kg</span><span class="p">,</span> <span class="n">store</span><span class="p">)</span>

<span class="c1"># Demo: A relational query that requires following connections</span>
<span class="n">query</span> <span class="o">=</span> <span class="s2">&quot;What training algorithm uses the chain rule?&quot;</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Query: &#39;</span><span class="si">{</span><span class="n">query</span><span class="si">}</span><span class="s2">&#39;&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">kg_rag</span><span class="o">.</span><span class="n">query</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">hops</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">1. Entities found in query: </span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="s1">&#39;query_entities&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">2. Graph traversal discovered </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">result</span><span class="p">[</span><span class="s1">&#39;related_entities&#39;</span><span class="p">])</span><span class="si">}</span><span class="s2"> related entities:&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">entity</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">result</span><span class="p">[</span><span class="s1">&#39;related_entities&#39;</span><span class="p">]):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;     </span><span class="si">{</span><span class="n">entity</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">3. Graph context (direct relationships):&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">ctx</span> <span class="ow">in</span> <span class="n">result</span><span class="p">[</span><span class="s1">&#39;graph_context&#39;</span><span class="p">]:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;     </span><span class="si">{</span><span class="n">ctx</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">4. Graph paths (multi-hop reasoning):&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">path</span> <span class="ow">in</span> <span class="n">result</span><span class="p">[</span><span class="s1">&#39;graph_paths&#39;</span><span class="p">][:</span><span class="mi">5</span><span class="p">]:</span>
    <span class="n">chain</span> <span class="o">=</span> <span class="s2">&quot; -&gt; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">s</span><span class="si">}</span><span class="s2"> --[</span><span class="si">{</span><span class="n">p</span><span class="si">}</span><span class="s2">]--&gt; </span><span class="si">{</span><span class="n">o</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">s</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">o</span> <span class="ow">in</span> <span class="n">path</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;     </span><span class="si">{</span><span class="n">chain</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">5. Standard vector search (no graph):&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">result</span><span class="p">[</span><span class="s1">&#39;standard_vector_results&#39;</span><span class="p">]:</span>
    <span class="n">preview</span> <span class="o">=</span> <span class="n">r</span><span class="p">[</span><span class="s1">&#39;chunk&#39;</span><span class="p">][:</span><span class="mi">60</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="s1">&#39; &#39;</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;...&#39;</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;     [</span><span class="si">{</span><span class="n">r</span><span class="p">[</span><span class="s1">&#39;score&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">] </span><span class="si">{</span><span class="n">r</span><span class="p">[</span><span class="s1">&#39;metadata&#39;</span><span class="p">][</span><span class="s1">&#39;source&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">preview</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">6. KG-expanded vector search:&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">result</span><span class="p">[</span><span class="s1">&#39;kg_vector_results&#39;</span><span class="p">]:</span>
    <span class="n">preview</span> <span class="o">=</span> <span class="n">r</span><span class="p">[</span><span class="s1">&#39;chunk&#39;</span><span class="p">][:</span><span class="mi">60</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="s1">&#39; &#39;</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;...&#39;</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;     [</span><span class="si">{</span><span class="n">r</span><span class="p">[</span><span class="s1">&#39;score&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">] </span><span class="si">{</span><span class="n">r</span><span class="p">[</span><span class="s1">&#39;metadata&#39;</span><span class="p">][</span><span class="s1">&#39;source&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">preview</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">The graph directly tells us: chain rule &lt;-- backpropagation --&gt; gradients&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Vector search alone may not make this connection explicit.&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Visualize the knowledge graph</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">networkx</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nx</span>

<span class="n">G</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">DiGraph</span><span class="p">()</span>

<span class="c1"># Add edges from triples</span>
<span class="k">for</span> <span class="n">subj</span><span class="p">,</span> <span class="n">pred</span><span class="p">,</span> <span class="n">obj</span> <span class="ow">in</span> <span class="n">kg</span><span class="o">.</span><span class="n">triples</span><span class="p">:</span>
    <span class="n">G</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="n">subj</span><span class="p">,</span> <span class="n">obj</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">pred</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>

<span class="c1"># Left: Full knowledge graph</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">pos</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">spring_layout</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mf">2.5</span><span class="p">)</span>

<span class="c1"># Color nodes by topic</span>
<span class="n">topic_colors</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">nn_entities</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;neural network&quot;</span><span class="p">,</span> <span class="s2">&quot;neurons&quot;</span><span class="p">,</span> <span class="s2">&quot;backpropagation&quot;</span><span class="p">,</span> <span class="s2">&quot;chain rule&quot;</span><span class="p">,</span> 
               <span class="s2">&quot;gradients&quot;</span><span class="p">,</span> <span class="s2">&quot;SGD&quot;</span><span class="p">,</span> <span class="s2">&quot;Adam&quot;</span><span class="p">,</span> <span class="s2">&quot;deep learning&quot;</span><span class="p">,</span> <span class="s2">&quot;hierarchical representations&quot;</span><span class="p">}</span>
<span class="n">tf_entities</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;Transformer&quot;</span><span class="p">,</span> <span class="s2">&quot;self-attention&quot;</span><span class="p">,</span> <span class="s2">&quot;Q K V matrices&quot;</span><span class="p">,</span> <span class="s2">&quot;dot product&quot;</span><span class="p">,</span>
               <span class="s2">&quot;softmax&quot;</span><span class="p">,</span> <span class="s2">&quot;positional encoding&quot;</span><span class="p">,</span> <span class="s2">&quot;layer normalization&quot;</span><span class="p">,</span> 
               <span class="s2">&quot;residual connections&quot;</span><span class="p">,</span> <span class="s2">&quot;multi-head attention&quot;</span><span class="p">}</span>
<span class="n">rlhf_entities</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;RLHF&quot;</span><span class="p">,</span> <span class="s2">&quot;SFT&quot;</span><span class="p">,</span> <span class="s2">&quot;reward model&quot;</span><span class="p">,</span> <span class="s2">&quot;PPO&quot;</span><span class="p">,</span> <span class="s2">&quot;Bradley-Terry&quot;</span><span class="p">,</span>
                  <span class="s2">&quot;KL penalty&quot;</span><span class="p">,</span> <span class="s2">&quot;DPO&quot;</span><span class="p">,</span> <span class="s2">&quot;language model&quot;</span><span class="p">}</span>
<span class="n">emb_entities</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;Word2Vec&quot;</span><span class="p">,</span> <span class="s2">&quot;Skip-gram&quot;</span><span class="p">,</span> <span class="s2">&quot;CBOW&quot;</span><span class="p">,</span> <span class="s2">&quot;word embeddings&quot;</span><span class="p">,</span>
                <span class="s2">&quot;sentence transformer&quot;</span><span class="p">,</span> <span class="s2">&quot;sentence embeddings&quot;</span><span class="p">,</span> <span class="s2">&quot;embeddings&quot;</span><span class="p">,</span>
                <span class="s2">&quot;cosine similarity&quot;</span><span class="p">,</span> <span class="s2">&quot;BERT&quot;</span><span class="p">,</span> <span class="s2">&quot;contextual embeddings&quot;</span><span class="p">,</span> <span class="s2">&quot;semantic search&quot;</span><span class="p">,</span> <span class="s2">&quot;RAG&quot;</span><span class="p">}</span>

<span class="n">node_colors</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">G</span><span class="o">.</span><span class="n">nodes</span><span class="p">():</span>
    <span class="k">if</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">nn_entities</span><span class="p">:</span>
        <span class="n">node_colors</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">&#39;#3498db&#39;</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">tf_entities</span><span class="p">:</span>
        <span class="n">node_colors</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">&#39;#e74c3c&#39;</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">rlhf_entities</span><span class="p">:</span>
        <span class="n">node_colors</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">&#39;#2ecc71&#39;</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">emb_entities</span><span class="p">:</span>
        <span class="n">node_colors</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">&#39;#f39c12&#39;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">node_colors</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">&#39;#95a5a6&#39;</span><span class="p">)</span>

<span class="n">nx</span><span class="o">.</span><span class="n">draw_networkx_nodes</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">pos</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">node_color</span><span class="o">=</span><span class="n">node_colors</span><span class="p">,</span> 
                       <span class="n">node_size</span><span class="o">=</span><span class="mi">600</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="mf">1.5</span><span class="p">)</span>
<span class="n">nx</span><span class="o">.</span><span class="n">draw_networkx_labels</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">pos</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">font_size</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">font_weight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">)</span>
<span class="n">nx</span><span class="o">.</span><span class="n">draw_networkx_edges</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">pos</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">edge_color</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> 
                       <span class="n">arrows</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">arrowsize</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">connectionstyle</span><span class="o">=</span><span class="s1">&#39;arc3,rad=0.1&#39;</span><span class="p">)</span>

<span class="c1"># Legend</span>
<span class="k">for</span> <span class="n">label</span><span class="p">,</span> <span class="n">color</span> <span class="ow">in</span> <span class="p">[(</span><span class="s1">&#39;Neural Networks&#39;</span><span class="p">,</span> <span class="s1">&#39;#3498db&#39;</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;Transformers&#39;</span><span class="p">,</span> <span class="s1">&#39;#e74c3c&#39;</span><span class="p">),</span>
                     <span class="p">(</span><span class="s1">&#39;RLHF&#39;</span><span class="p">,</span> <span class="s1">&#39;#2ecc71&#39;</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;Embeddings&#39;</span><span class="p">,</span> <span class="s1">&#39;#f39c12&#39;</span><span class="p">)]:</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">([],</span> <span class="p">[],</span> <span class="n">c</span><span class="o">=</span><span class="n">color</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">label</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">9</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper left&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Full Knowledge Graph</span><span class="se">\n</span><span class="s1">(entities as nodes, relationships as edges)&#39;</span><span class="p">,</span>
             <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>

<span class="c1"># Right: Highlight a query traversal path</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

<span class="c1"># Traverse from &quot;chain rule&quot; to show what KG-RAG finds</span>
<span class="n">start_entity</span> <span class="o">=</span> <span class="s2">&quot;chain rule&quot;</span>
<span class="n">visited</span><span class="p">,</span> <span class="n">paths</span> <span class="o">=</span> <span class="n">kg</span><span class="o">.</span><span class="n">traverse</span><span class="p">(</span><span class="n">start_entity</span><span class="p">,</span> <span class="n">hops</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="c1"># Draw full graph faded</span>
<span class="n">nx</span><span class="o">.</span><span class="n">draw_networkx_nodes</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">pos</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">node_color</span><span class="o">=</span><span class="s1">&#39;#ecf0f1&#39;</span><span class="p">,</span> 
                       <span class="n">node_size</span><span class="o">=</span><span class="mi">400</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
<span class="n">nx</span><span class="o">.</span><span class="n">draw_networkx_edges</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">pos</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">edge_color</span><span class="o">=</span><span class="s1">&#39;#ecf0f1&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
                       <span class="n">arrows</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">arrowsize</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">connectionstyle</span><span class="o">=</span><span class="s1">&#39;arc3,rad=0.1&#39;</span><span class="p">)</span>

<span class="c1"># Highlight visited nodes</span>
<span class="n">visited_nodes</span> <span class="o">=</span> <span class="p">[</span><span class="n">n</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">G</span><span class="o">.</span><span class="n">nodes</span><span class="p">()</span> <span class="k">if</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">visited</span><span class="p">]</span>
<span class="n">other_nodes</span> <span class="o">=</span> <span class="p">[</span><span class="n">n</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">G</span><span class="o">.</span><span class="n">nodes</span><span class="p">()</span> <span class="k">if</span> <span class="n">n</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">visited</span><span class="p">]</span>

<span class="n">nx</span><span class="o">.</span><span class="n">draw_networkx_nodes</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">pos</span><span class="p">,</span> <span class="n">nodelist</span><span class="o">=</span><span class="n">visited_nodes</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span>
                       <span class="n">node_color</span><span class="o">=</span><span class="s1">&#39;#e74c3c&#39;</span><span class="p">,</span> <span class="n">node_size</span><span class="o">=</span><span class="mi">800</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span>
                       <span class="n">edgecolors</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">nx</span><span class="o">.</span><span class="n">draw_networkx_labels</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">pos</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="p">{</span><span class="n">n</span><span class="p">:</span> <span class="n">n</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">visited_nodes</span><span class="p">},</span>
                        <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">font_size</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> <span class="n">font_weight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">)</span>

<span class="c1"># Highlight traversal edges</span>
<span class="n">traversal_edges</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
<span class="k">for</span> <span class="n">path</span> <span class="ow">in</span> <span class="n">paths</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">s</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">o</span> <span class="ow">in</span> <span class="n">path</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">G</span><span class="o">.</span><span class="n">has_edge</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">o</span><span class="p">):</span>
            <span class="n">traversal_edges</span><span class="o">.</span><span class="n">add</span><span class="p">((</span><span class="n">s</span><span class="p">,</span> <span class="n">o</span><span class="p">))</span>
        <span class="k">elif</span> <span class="n">G</span><span class="o">.</span><span class="n">has_edge</span><span class="p">(</span><span class="n">o</span><span class="p">,</span> <span class="n">s</span><span class="p">):</span>
            <span class="n">traversal_edges</span><span class="o">.</span><span class="n">add</span><span class="p">((</span><span class="n">o</span><span class="p">,</span> <span class="n">s</span><span class="p">))</span>

<span class="k">if</span> <span class="n">traversal_edges</span><span class="p">:</span>
    <span class="n">nx</span><span class="o">.</span><span class="n">draw_networkx_edges</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">pos</span><span class="p">,</span> <span class="n">edgelist</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">traversal_edges</span><span class="p">),</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span>
                           <span class="n">edge_color</span><span class="o">=</span><span class="s1">&#39;#e74c3c&#39;</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span>
                           <span class="n">arrows</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">arrowsize</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">connectionstyle</span><span class="o">=</span><span class="s1">&#39;arc3,rad=0.1&#39;</span><span class="p">)</span>

<span class="c1"># Mark start node</span>
<span class="k">if</span> <span class="n">start_entity</span> <span class="ow">in</span> <span class="n">pos</span><span class="p">:</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">([</span><span class="n">pos</span><span class="p">[</span><span class="n">start_entity</span><span class="p">][</span><span class="mi">0</span><span class="p">]],</span> <span class="p">[</span><span class="n">pos</span><span class="p">[</span><span class="n">start_entity</span><span class="p">][</span><span class="mi">1</span><span class="p">]],</span> 
               <span class="n">s</span><span class="o">=</span><span class="mi">1200</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;none&#39;</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s1">&#39;#e74c3c&#39;</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">zorder</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Graph Traversal from &quot;</span><span class="si">{</span><span class="n">start_entity</span><span class="si">}</span><span class="s1">&quot; (2 hops)</span><span class="se">\n</span><span class="s1">&#39;</span>
             <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">visited</span><span class="p">)</span><span class="si">}</span><span class="s1"> entities discovered via relationship following&#39;</span><span class="p">,</span>
             <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;Knowledge Graph: Structure &amp; Traversal&#39;</span><span class="p">,</span>
             <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mf">1.02</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;From &#39;</span><span class="si">{</span><span class="n">start_entity</span><span class="si">}</span><span class="s2">&#39;, 2-hop traversal discovers: </span><span class="si">{</span><span class="nb">sorted</span><span class="p">(</span><span class="n">visited</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;This is the structural reasoning that vector search cannot replicate.&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<hr class="docutils" />
<section id="exercises">
<h2>Exercises<a class="headerlink" href="#exercises" title="Link to this heading">#</a></h2>
<section id="exercise-1-chunking-strategy-comparison-race-report-optimization">
<h3>Exercise 1: Chunking Strategy Comparison — Race Report Optimization<a class="headerlink" href="#exercise-1-chunking-strategy-comparison-race-report-optimization" title="Link to this heading">#</a></h3>
<p>Imagine you’re building a RAG system for an F1 team’s race report archive. Run the full RAG evaluation with each chunking strategy (fixed, sentence, paragraph). Which strategy gives the best retrieval precision? Think about how this applies to chunking race reports: would you split by fixed character count (potentially cutting mid-sentence about tire compounds), by sentence (natural boundaries), or by paragraph (one topic per chunk, like “pit stop analysis” or “weather impact”)? Does the best chunking strategy depend on the query type?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Exercise 1: Your code here</span>
<span class="c1"># Hint: Build separate vector stores for each chunking strategy,</span>
<span class="c1"># run the same eval queries, and compare P@1, P@3, MRR</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="exercise-2-multi-hop-rag-cross-referencing-race-data">
<h3>Exercise 2: Multi-Hop RAG — Cross-Referencing Race Data<a class="headerlink" href="#exercise-2-multi-hop-rag-cross-referencing-race-data" title="Link to this heading">#</a></h3>
<p>Implement a two-step RAG system where the first retrieval provides context that helps reformulate the query for a second retrieval. This mirrors how an F1 strategist might first look up “races with similar tire degradation patterns” and then use those results to refine their search to “what pit stop strategies worked in those specific races?” Test with the question: “What algorithm from NB20 uses the mechanism from NB12?”</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Exercise 2: Your code here</span>
<span class="c1"># Hint: Retrieve once, extract key terms from results,</span>
<span class="c1"># reformulate query, retrieve again</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="exercise-3-rag-with-metadata-filtering-circuit-specific-search">
<h3>Exercise 3: RAG with Metadata Filtering — Circuit-Specific Search<a class="headerlink" href="#exercise-3-rag-with-metadata-filtering-circuit-specific-search" title="Link to this heading">#</a></h3>
<p>Extend the VectorStore to support metadata filtering (e.g., only search within <code class="docutils literal notranslate"><span class="pre">source='transformers'</span></code>). In F1 terms, this is like filtering your race database to only search within a specific circuit or season — “only show me data from Silverstone” or “only recent regulation era.” Show how filtering improves precision when the user specifies a topic.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Exercise 3: Your code here</span>
<span class="c1"># Hint: Add a filter parameter to VectorStore.search()</span>
<span class="c1"># that skips chunks not matching the filter criteria</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<hr class="docutils" />
<section id="summary">
<h2>Summary<a class="headerlink" href="#summary" title="Link to this heading">#</a></h2>
<section id="key-concepts">
<h3>Key Concepts<a class="headerlink" href="#key-concepts" title="Link to this heading">#</a></h3>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Concept</p></th>
<th class="head"><p>Definition</p></th>
<th class="head"><p>F1 Parallel</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>RAG</strong></p></td>
<td><p>Augments LLMs with external knowledge at inference time — no retraining needed</p></td>
<td><p>Race engineer querying the team’s historical database mid-race instead of relying on memory</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Chunking strategy</strong></p></td>
<td><p>Splitting documents into searchable pieces — too small loses context, too large dilutes relevance</p></td>
<td><p>Breaking race reports into sections: tire strategy, weather, pit stops — right granularity matters</p></td>
</tr>
<tr class="row-even"><td><p><strong>Vector stores</strong></p></td>
<td><p>Index embeddings for fast similarity search using cosine similarity</p></td>
<td><p>The team’s knowledge base indexed by situation similarity, not just date or circuit name</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Reranking</strong></p></td>
<td><p>Rescoring candidates with a cross-encoder for improved precision</p></td>
<td><p>Senior strategist reviewing the initial search results and filtering to the truly relevant ones</p></td>
</tr>
<tr class="row-even"><td><p><strong>Hybrid search</strong></p></td>
<td><p>Combining semantic + keyword search outperforms either alone</p></td>
<td><p>Matching both by meaning (“similar conditions”) and keywords (“medium compound, lap 25”)</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Retrieval metrics</strong></p></td>
<td><p>P&#64;k, Recall&#64;k, MRR quantify how well the right chunks are found</p></td>
<td><p>Measuring if the pit wall is pulling up the right historical data when it matters</p></td>
</tr>
<tr class="row-even"><td><p><strong>KG-RAG</strong></p></td>
<td><p>Knowledge graph triples enable relational reasoning and multi-hop queries that vector search can’t handle</p></td>
<td><p>The team’s wiring diagram: following explicit connections like Verstappen → Red Bull → Honda, not just finding similar text</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Advanced patterns</strong></p></td>
<td><p>HyDE, multi-hop RAG, and agentic RAG handle complex queries</p></td>
<td><p>Multi-step data lookups: find similar weather, then find strategies that worked in that weather</p></td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="fundamental-insight">
<h3>Fundamental Insight<a class="headerlink" href="#fundamental-insight" title="Link to this heading">#</a></h3>
<p>RAG transforms LLMs from closed-book test-takers into open-book researchers. By separating knowledge storage (vector store) from reasoning (LLM), RAG systems stay current, reduce hallucination, and work with private data — making them the most practical pattern for production AI systems. In F1 terms, you’re giving the strategy model access to the full team archive instead of asking it to memorize everything from training. The model’s job is to <em>reason</em> over the retrieved data, not to <em>store</em> all the data in its weights.</p>
</section>
</section>
<hr class="docutils" />
<section id="next-steps">
<h2>Next Steps<a class="headerlink" href="#next-steps" title="Link to this heading">#</a></h2>
<p>RAG retrieves knowledge, but sometimes an AI system needs to <strong>take actions</strong> — search the web, call APIs, write code, or interact with tools. In <strong>Notebook 27: AI Agents &amp; Tool Use</strong>, we’ll build agents that reason about <em>what to do</em> and <em>when to do it</em>, using the ReAct pattern and multi-step planning. In F1 terms, we’re moving from the strategist who <em>looks up data</em> to the race engineer who <em>makes decisions and executes them</em> — querying the weather API, running the tire model, adjusting the fuel calculator, and radioing the driver with the call.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./notebooks"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="25_ppo_modern_rl.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Part 7.4: PPO and Modern RL</p>
      </div>
    </a>
    <a class="right-next"
       href="27_ai_agents.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Part 8.2: AI Agents and Tool Use</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#learning-objectives">Learning Objectives</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#why-rag">1. Why RAG?</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-problem-with-parametric-knowledge">The Problem with Parametric Knowledge</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#rag-vs-fine-tuning">RAG vs. Fine-Tuning</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#intuitive-explanation">Intuitive Explanation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#visualization-the-rag-pipeline">Visualization: The RAG Pipeline</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#document-chunking">2. Document Chunking</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#why-chunk">Why Chunk?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#key-tradeoff">Key Tradeoff</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#visualization-chunking-strategy-comparison">Visualization: Chunking Strategy Comparison</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#embeddings-and-vector-search">3. Embeddings and Vector Search</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#building-a-simple-embedding-model">Building a Simple Embedding Model</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#vector-store">4. Vector Store</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#visualization-embedding-space">Visualization: Embedding Space</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-complete-rag-pipeline">5. The Complete RAG Pipeline</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#reranking-improving-retrieval-quality">6. Reranking: Improving Retrieval Quality</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluating-rag-systems">7. Evaluating RAG Systems</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#retrieval-metrics">Retrieval Metrics</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#generation-metrics">Generation Metrics</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#common-rag-failure-modes">8. Common RAG Failure Modes</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#advanced-rag-patterns">9. Advanced RAG Patterns</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#knowledge-graph-rag">10. Knowledge Graph RAG</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#vector-rag-vs-kg-rag-vs-hybrid">Vector RAG vs. KG-RAG vs. Hybrid</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercises">Exercises</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-1-chunking-strategy-comparison-race-report-optimization">Exercise 1: Chunking Strategy Comparison — Race Report Optimization</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-2-multi-hop-rag-cross-referencing-race-data">Exercise 2: Multi-Hop RAG — Cross-Referencing Race Data</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-3-rag-with-metadata-filtering-circuit-specific-search">Exercise 3: RAG with Metadata Filtering — Circuit-Specific Search</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#summary">Summary</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#key-concepts">Key Concepts</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#fundamental-insight">Fundamental Insight</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#next-steps">Next Steps</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Dan Shah
</p>

  </div>
  
  <div class="footer-item">
    

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>
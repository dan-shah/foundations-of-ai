{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Part 2.1: Python OOP for Deep Learning — The Formula 1 Edition\n\nObject-Oriented Programming is essential for deep learning because:\n- PyTorch models are classes (`nn.Module`)\n- Datasets are classes (`torch.utils.data.Dataset`)\n- Training loops use objects with state\n- Clean, reusable code requires good OOP design\n\n**F1 analogy:** An F1 team is a masterclass in object-oriented thinking. A `Car` is a class — it defines what every car *has* (engine, tires, aero package) and what every car *does* (accelerate, brake, turn). But each physical car on the grid is an *instance* — Verstappen's car and his teammate's car follow the same blueprint but carry different settings, different wear, different telemetry data. The team itself is a composition of objects: drivers, engineers, pit crew, strategy software. Inheritance is everywhere: a `SafetyCar` is a kind of `Vehicle`, but with different rules. And the FIA's technical regulations? Those are like type hints and decorators — constraints that validate and wrap behavior without changing the core engineering.\n\n## Learning Objectives\n- [ ] Design clean class hierarchies\n- [ ] Use magic methods to create Pythonic APIs\n- [ ] Write and use decorators\n- [ ] Add type hints for better code documentation\n\n---"
  },
  {
   "cell_type": "code",
   "source": "# Setup - run this cell first\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nplt.style.use('seaborn-v0_8-whitegrid')\nnp.random.seed(42)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### What this means:\n\n**Classes** are like blueprints for building things. Think of a class as an F1 car design specification — it defines the aerodynamics, engine layout, and suspension geometry, but each physical car built from that spec is a separate object with its own wear, setup, and telemetry history.\n\n**F1 analogy:** The `RB20` class is the blueprint. When Red Bull builds chassis #1 for Verstappen and chassis #2 for Perez, those are two *instances*. They share the same design (class), but each accumulates its own mileage, crash damage, and component life. Changing Verstappen's front wing angle doesn't change Perez's.\n\nIn deep learning:\n- The `nn.Module` class is the car design spec for all neural networks\n- When you write `model = MyNetwork()`, you're building one specific car from that spec\n- Each model you create has its own weights, even though they follow the same blueprint",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 1. Classes and Objects\n\nA **class** is a blueprint for creating objects. An **object** is an instance of a class.\n\n### Why Classes Matter in Deep Learning\n\n| PyTorch Concept | Implemented As | F1 Parallel |\n|-----------------|----------------|-------------|\n| Neural network | Class extending `nn.Module` | Car design spec (aero, engine, suspension) |\n| Dataset | Class extending `Dataset` | Season's race calendar with track data |\n| Optimizer | Class with `step()` and `zero_grad()` | Race strategist adjusting setup each lap |\n| Loss function | Class with `forward()` method | Gap to leader — the number you want to minimize |\n| Data loader | Class with `__iter__()` method | Pit crew feeding tires and fuel in batches |\n\n### The F1 Connection\n\nEvery F1 car on the grid is an *instance* of a design class. The constructor (`__init__`) is the factory build — it sets the initial engine mode, tire compound, fuel load, and driver assignment. Methods like `accelerate()`, `brake()`, and `change_tires()` define what the car can *do*. This is exactly how PyTorch models work: `__init__` builds the layers, and `forward()` defines the computation."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Basic class structure — F1 telemetry point\nclass TelemetryPoint:\n    \"\"\"A single telemetry reading from an F1 car's sensors.\"\"\"\n    \n    def __init__(self, n_sensors):\n        \"\"\"Initialize telemetry with random sensor calibrations.\n        \n        Args:\n            n_sensors: Number of sensor channels (speed, throttle, brake, g-force, etc.)\n        \"\"\"\n        import numpy as np\n        self.weights = np.random.randn(n_sensors)  # sensor calibration weights\n        self.bias = 0.0  # baseline offset\n        \n    def forward(self, x):\n        \"\"\"Compute weighted telemetry reading (same math as a neuron!).\"\"\"\n        import numpy as np\n        z = np.dot(self.weights, x) + self.bias\n        return 1 / (1 + np.exp(-z))  # Sigmoid: normalizes to 0-1 range\n\n# Create an instance (object)\ntelemetry = TelemetryPoint(n_sensors=3)\nprint(f\"Sensor weights: {telemetry.weights}\")\nprint(f\"Baseline offset: {telemetry.bias}\")\n\n# Read a telemetry snapshot: [speed_ratio, throttle_position, brake_pressure]\nimport numpy as np\nsensor_reading = np.array([1.0, 2.0, 3.0])\noutput = telemetry.forward(sensor_reading)\nprint(f\"Output for sensor reading {sensor_reading}: {output:.4f}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Deep Dive: Understanding `self`\n\n`self` refers to the specific instance of the class. It's how the object accesses its own data.\n\n**F1 analogy:** When a race engineer says \"check your tire temps,\" the word \"your\" is `self` — it refers to *this specific car*. Verstappen's engineer is talking to Verstappen's car, not Perez's.\n\n```python\ncar1 = TelemetryPoint(3)  # self = car1 inside methods\ncar2 = TelemetryPoint(3)  # self = car2 inside methods\n```\n\nEach object has its own `weights` and `bias` — they don't share! Just like each car has its own telemetry data.\n\n| Term | Meaning | F1 Parallel |\n|------|--------|-------------|\n| `self.weights` | Instance attribute (each object has its own) | This car's sensor calibration |\n| `self.forward(x)` | Instance method (operates on this object's data) | This car's telemetry computation |\n| `TelemetryPoint.forward` | The method definition in the class | The spec for how any car computes telemetry |"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Demonstrating that each instance has its own state\nnp.random.seed(42)\ncar1 = TelemetryPoint(3)  # Verstappen's car\ncar2 = TelemetryPoint(3)  # Perez's car\n\nprint(\"car1 (Verstappen) sensor weights:\", car1.weights)\nprint(\"car2 (Perez) sensor weights:\", car2.weights)\nprint(\"\\nThey're different! Each car has its own sensor calibration.\")\n\n# Modify one, the other is unaffected — just like adjusting one car's setup\ncar1.bias = 1.0\nprint(f\"\\ncar1.bias = {car1.bias}  (adjusted Verstappen's baseline)\")\nprint(f\"car2.bias = {car2.bias}  (Perez's unchanged)\")"
  },
  {
   "cell_type": "code",
   "source": "# Visualization: Object Memory Layout — F1 Cars in the Garage\nfig, axes = plt.subplots(1, 2, figsize=(12, 5))\n\n# Left: Two separate car objects\nax = axes[0]\nax.set_xlim(0, 10)\nax.set_ylim(0, 10)\nax.axis('off')\nax.set_title('Two F1 Car Objects in Memory', fontsize=12, fontweight='bold')\n\n# Object 1 box\nrect1 = plt.Rectangle((0.5, 5), 4, 4.5, fill=True, facecolor='lightblue', \n                        edgecolor='black', linewidth=2)\nax.add_patch(rect1)\nax.text(2.5, 9, 'car1 (VER)', ha='center', va='center', fontsize=11, fontweight='bold')\nax.text(2.5, 8.2, 'weights: [0.49, -0.13, 0.64]', ha='center', fontsize=9)\nax.text(2.5, 7.4, 'bias: 1.0', ha='center', fontsize=9)\nax.text(2.5, 6.5, 'forward: <method>', ha='center', fontsize=9, style='italic')\nax.text(2.5, 5.4, 'id: 0x7f...a1b0', ha='center', fontsize=8, color='gray')\n\n# Object 2 box\nrect2 = plt.Rectangle((5.5, 5), 4, 4.5, fill=True, facecolor='lightgreen', \n                        edgecolor='black', linewidth=2)\nax.add_patch(rect2)\nax.text(7.5, 9, 'car2 (PER)', ha='center', va='center', fontsize=11, fontweight='bold')\nax.text(7.5, 8.2, 'weights: [1.52, -0.23, 0.54]', ha='center', fontsize=9)\nax.text(7.5, 7.4, 'bias: 0.0', ha='center', fontsize=9)\nax.text(7.5, 6.5, 'forward: <method>', ha='center', fontsize=9, style='italic')\nax.text(7.5, 5.4, 'id: 0x7f...c2d0', ha='center', fontsize=8, color='gray')\n\nax.text(5, 3.5, 'Each car has its own copy\\nof instance attributes!', \n        ha='center', fontsize=10, style='italic')\n\n# Right: Class vs Instance attributes — Team regulations vs car setup\nax = axes[1]\nax.set_xlim(0, 10)\nax.set_ylim(0, 10)\nax.axis('off')\nax.set_title('Team Spec (Class) vs Car Setup (Instance)', fontsize=12, fontweight='bold')\n\n# Class (shared) — like FIA regulations or team design spec\nrect_class = plt.Rectangle((2, 6.5), 6, 2.5, fill=True, facecolor='lightyellow', \n                             edgecolor='black', linewidth=2)\nax.add_patch(rect_class)\nax.text(5, 8.5, 'Team (class)', ha='center', fontweight='bold', fontsize=11)\nax.text(5, 7.5, 'car_count = 3  (shared by all)', ha='center', fontsize=10)\n\n# Instances — individual cars\nfor i, (x, color, name) in enumerate([(1.5, 'lightblue', 'car_FP1'), \n                                        (5, 'lightgreen', 'car_FP2'),\n                                        (8.5, 'lightcoral', 'car_Race')]):\n    rect = plt.Rectangle((x-1.2, 2), 2.4, 3, fill=True, facecolor=color, \n                          edgecolor='black', linewidth=1.5)\n    ax.add_patch(rect)\n    ax.text(x, 4.5, name, ha='center', fontweight='bold', fontsize=10)\n    ax.text(x, 3.8, f'id = {i}', ha='center', fontsize=9)\n    ax.text(x, 3.1, f'downforce = {[350, 450, 400][i]}kg', ha='center', fontsize=8)\n    # Arrow to class\n    ax.annotate('', xy=(x, 6.5), xytext=(x, 5),\n                arrowprops=dict(arrowstyle='->', color='gray', lw=1.5))\n\nax.text(5, 1, 'Instance attributes (setup) are unique;\\nclass attributes (team spec) are shared', \n        ha='center', fontsize=10, style='italic')\n\nplt.tight_layout()\nplt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Class Attributes vs Instance Attributes\n\n| Type | Defined | Shared? | Use Case | F1 Parallel |\n|------|---------|---------|----------|-------------|\n| Class attribute | In class body | Yes, by all instances | Constants, counters | FIA regulations (same for all cars) |\n| Instance attribute | In `__init__` with `self.` | No, each instance has own | Object-specific data | Car setup (unique per chassis) |"
  },
  {
   "cell_type": "markdown",
   "source": "### What this means:\n\n**Inheritance** is like the FIA vehicle classification system. Every car on the grid is a `Vehicle`, but an `F1Car` inherits from `Vehicle` and adds open-wheel aero, DRS, and hybrid power units. A `SafetyCar` also inherits from `Vehicle` but has flashing lights and speed limiters instead. Both get basic vehicle behavior (steering, braking) for free — they only define what's unique.\n\n**F1 analogy:** Think of tire compounds. There's a base `Tire` class that defines grip, degradation, and temperature behavior. `SoftTire`, `MediumTire`, and `HardTire` all inherit from `Tire` but override the specific grip and durability characteristics. You don't rewrite the entire tire physics for each compound — you inherit the common behavior and customize the differences.\n\nIn deep learning:\n- `nn.Module` is the \"parent\" that knows how to track parameters, move to GPU, save/load, etc.\n- Your custom model is the \"child\" that inherits all those abilities\n- You only need to write what's unique (your architecture), not reinvent parameter tracking!",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Visualization: Class Hierarchy Diagram — F1 Vehicle Inheritance\nfig, ax = plt.subplots(figsize=(10, 6))\nax.set_xlim(0, 10)\nax.set_ylim(0, 8)\nax.axis('off')\nax.set_title('Class Hierarchy: Inheritance in F1 and Deep Learning', fontsize=14, fontweight='bold')\n\n# Draw boxes\ndef draw_box(ax, x, y, text, color='lightblue'):\n    box = plt.Rectangle((x-0.8, y-0.3), 1.6, 0.6, fill=True, \n                         facecolor=color, edgecolor='black', linewidth=2)\n    ax.add_patch(box)\n    ax.text(x, y, text, ha='center', va='center', fontsize=10, fontweight='bold')\n\n# Parent class\ndraw_box(ax, 5, 7, 'Vehicle', 'lightyellow')\n\n# Child classes (level 1) — different vehicle types\ndraw_box(ax, 2, 5, 'F1Car', 'lightblue')\ndraw_box(ax, 5, 5, 'SafetyCar', 'lightblue')\ndraw_box(ax, 8, 5, 'MedicalCar', 'lightblue')\n\n# Specific cars (level 2) — instances/further specialization\ndraw_box(ax, 2, 3, 'RedBullRB20', 'lightgreen')\ndraw_box(ax, 5, 3, 'Mercedes AMG', 'lightgreen')\ndraw_box(ax, 8, 3, 'Aston Martin', 'lightgreen')\n\n# Draw inheritance arrows\nfor x in [2, 5, 8]:\n    ax.annotate('', xy=(x, 6.7), xytext=(x, 5.3),\n                arrowprops=dict(arrowstyle='->', color='black', lw=2))\n    ax.annotate('', xy=(x, 4.7), xytext=(x, 3.3),\n                arrowprops=dict(arrowstyle='->', color='black', lw=2))\n\n# Legend\nax.text(5, 1.5, 'Arrows show \"inherits from\" relationship', ha='center', fontsize=10, style='italic')\nax.text(5, 1, 'Yellow = Base Vehicle | Blue = Vehicle types | Green = Specific implementations', \n        ha='center', fontsize=9)\n\nplt.tight_layout()\nplt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Class attributes vs instance attributes — F1 Team example\nclass Team:\n    \"\"\"An F1 constructor team.\"\"\"\n    \n    # Class attribute - shared by all teams (like FIA rules)\n    total_teams = 0\n    \n    def __init__(self, n_staff):\n        # Instance attributes - unique to each team\n        self.n_staff = n_staff\n        self.team_id = Team.total_teams\n        Team.total_teams += 1  # Increment the shared counter\n\n# Create teams\nred_bull = Team(800)\nmercedes = Team(900)\nferrari = Team(850)\n\nprint(f\"Red Bull: id={red_bull.team_id}, staff={red_bull.n_staff}\")\nprint(f\"Mercedes: id={mercedes.team_id}, staff={mercedes.n_staff}\")\nprint(f\"Ferrari:  id={ferrari.team_id}, staff={ferrari.n_staff}\")\nprint(f\"\\nTotal teams on the grid: {Team.total_teams}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## 2. Inheritance\n\n**Inheritance** lets you create a new class based on an existing class. The new class \"inherits\" all the methods and attributes of the parent.\n\n### Why Inheritance Matters in Deep Learning\n\n```python\nclass MyModel(nn.Module):      # Inherit from nn.Module\nclass MyDataset(Dataset):       # Inherit from Dataset\nclass MyOptimizer(Optimizer):   # Inherit from Optimizer\n```\n\nYou get all the PyTorch machinery for free, then customize what you need!\n\n### The F1 Connection\n\nInheritance in F1 works exactly the same way. Every tire compound inherits from a base `Tire` class — they all have grip, degradation curves, and temperature windows. But a `SoftTire` overrides the grip coefficient to be higher and the durability to be lower. You don't rewrite the tire physics from scratch for each compound. In PyTorch, when you write `class MyModel(nn.Module)`, you inherit GPU support, parameter tracking, serialization, and gradient computation — then you only define your specific `forward()` method."
  },
  {
   "cell_type": "markdown",
   "source": "### What this means:\n\n**Magic methods** are special methods that Python calls automatically when you use operators or built-in functions. The double underscores (\"dunders\") tell Python \"this is special.\"\n\n**F1 analogy:** Magic methods are like the standardized interfaces on an F1 car. The steering wheel *must* have specific paddle positions, the fuel connector *must* fit the refueling rig, the data port *must* speak the FIA telemetry protocol. You don't call these interfaces manually — they activate automatically when the right situation occurs (pit stop, data download, safety car deployment). Similarly:\n- When you write `len(race_results)`, Python secretly calls `race_results.__len__()`\n- When you write `car(telemetry)`, Python secretly calls `car.__call__(telemetry)`\n- You're teaching Python how to treat YOUR objects like built-in types!",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Base class — like a base Tire compound\nclass Tire:\n    \"\"\"Base class for F1 tire compounds (also demonstrates activation function pattern).\"\"\"\n    \n    def __init__(self, name):\n        self.name = name\n        \n    def grip_curve(self, x):\n        \"\"\"Compute grip response — must be implemented by subclass.\"\"\"\n        raise NotImplementedError(\"Subclasses must implement grip_curve()\")\n    \n    def __repr__(self):\n        return f\"{self.__class__.__name__}()\"\n\n\n# Child classes — specific tire compounds inherit from Tire\nclass SoftTire(Tire):\n    \"\"\"Soft compound: high grip, fast degradation (like ReLU — aggressive response).\"\"\"\n    \n    def __init__(self):\n        super().__init__(\"Soft (C5)\")  # Call parent's __init__\n        \n    def grip_curve(self, x):\n        return np.maximum(0, x)  # ReLU: aggressive, linear response\n\n\nclass MediumTire(Tire):\n    \"\"\"Medium compound: balanced grip (like Sigmoid — smooth, bounded response).\"\"\"\n    \n    def __init__(self):\n        super().__init__(\"Medium (C3)\")\n        \n    def grip_curve(self, x):\n        return 1 / (1 + np.exp(-x))  # Sigmoid: smooth transition\n\n\nclass HardTire(Tire):\n    \"\"\"Hard compound: conservative, durable (like Tanh — symmetric, conservative).\"\"\"\n    \n    def __init__(self):\n        super().__init__(\"Hard (C1)\")\n        \n    def grip_curve(self, x):\n        return np.tanh(x)  # Tanh: conservative, symmetric\n\n\n# Use them — these are also activation functions!\ntire_compounds = [SoftTire(), MediumTire(), HardTire()]\nx = np.linspace(-3, 3, 100)\n\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(10, 4))\ncolors = ['red', 'gold', 'white']\nfor tire, color in zip(tire_compounds, colors):\n    edgecolor = 'black' if color == 'white' else color\n    plt.plot(x, tire.grip_curve(x), label=tire.name, linewidth=2, color=edgecolor)\nplt.xlabel('Input (throttle demand / neural activation)')\nplt.ylabel('Response (grip level / activation output)')\nplt.title('Tire Compound Response Curves = Activation Functions (via inheritance)')\nplt.legend()\nplt.grid(True, alpha=0.3)\nplt.show()\n\n# All share the same interface!\nprint(\"All tire compounds share the same interface:\")\nfor tire in tire_compounds:\n    print(f\"  {tire} -> grip_curve(0) = {tire.grip_curve(np.array([0]))[0]:.4f}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Deep Dive: `super()` and Method Resolution Order\n\n`super()` calls the parent class's method. This is essential when you want to extend (not replace) the parent's behavior.\n\n**F1 analogy:** When a new tire compound is developed, it doesn't start from scratch. The engineers call `super().__init__()` — they initialize the base rubber chemistry, the internal structure, and the temperature model from the parent `Tire` class. *Then* they add compound-specific modifications like softer rubber polymers or harder carcass construction.\n\n```python\nclass SoftTire(Tire):\n    def __init__(self):\n        super().__init__(\"Soft\")  # Initialize base tire first!\n        self.grip_multiplier = 1.3  # Then add soft-specific stuff\n```\n\n**In PyTorch, you MUST call `super().__init__()`** in your model's `__init__`!"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Simulating PyTorch's nn.Module pattern — like an F1 car's ECU (Electronic Control Unit)\nclass Module:\n    \"\"\"Simplified version of nn.Module — think of it as the car's ECU base system.\"\"\"\n    \n    def __init__(self):\n        self._parameters = {}\n        self._modules = {}\n        \n    def register_parameter(self, name, value):\n        self._parameters[name] = value\n        \n    def parameters(self):\n        \"\"\"Return all parameters — like listing all tunable settings in the ECU.\"\"\"\n        params = list(self._parameters.values())\n        for module in self._modules.values():\n            params.extend(module.parameters())\n        return params\n    \n    def __call__(self, x):\n        return self.forward(x)\n\n\nclass Linear(Module):\n    \"\"\"Linear layer: y = xW + b — a single processing stage in the car's data pipeline.\"\"\"\n    \n    def __init__(self, in_features, out_features):\n        super().__init__()  # MUST call parent's __init__!\n        \n        # Initialize weights — like calibrating sensor mappings\n        self.weight = np.random.randn(in_features, out_features) * 0.01\n        self.bias = np.zeros(out_features)\n        \n        # Register as parameters\n        self.register_parameter('weight', self.weight)\n        self.register_parameter('bias', self.bias)\n        \n    def forward(self, x):\n        return x @ self.weight + self.bias\n\n\n# Use it — process a batch of telemetry readings\nlayer = Linear(10, 5)\nx = np.random.randn(3, 10)  # 3 laps, 10 sensor channels each\noutput = layer(x)  # Calls __call__ -> forward\n\nprint(f\"Input shape (laps x sensors): {x.shape}\")\nprint(f\"Output shape (laps x features): {output.shape}\")\nprint(f\"Number of parameter sets: {len(layer.parameters())}\")\nprint(f\"Weight shape: {layer.weight.shape}\")\nprint(f\"Bias shape: {layer.bias.shape}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## 3. Magic Methods (Dunder Methods)\n\n**Magic methods** (also called \"dunder\" methods for \"double underscore\") let you define how your objects behave with Python's built-in operations.\n\n### Why Magic Methods Matter in Deep Learning\n\n| Magic Method | Enables | PyTorch Example | F1 Parallel |\n|--------------|---------|----------------|-------------|\n| `__init__` | Creating objects | `model = MyModel()` | Building a car in the factory |\n| `__call__` | Calling like function | `output = model(input)` | Sending the car out on track |\n| `__len__` | `len()` function | `len(dataset)` | Number of laps in a stint |\n| `__getitem__` | Indexing with `[]` | `dataset[0]` | Looking up lap 17's telemetry |\n| `__iter__` | For loops | `for batch in dataloader:` | Iterating through race laps |\n| `__repr__` | Nice printing | `print(model)` | Pit wall display showing car status |\n| `__add__` | The `+` operator | `tensor1 + tensor2` | Combining stint times: S1 + S2 = total |\n| `__lt__` | The `<` operator | `result1 < result2` | Championship standings comparison |"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# A RaceResult class demonstrating magic methods — like a lap time or stint record\nclass RaceResult:\n    \"\"\"A race result / stint time demonstrating magic methods (same math as a Tensor).\"\"\"\n    \n    def __init__(self, data):\n        \"\"\"Called when you do: r = RaceResult(data)\"\"\"\n        self.data = np.array(data)\n        \n    def __repr__(self):\n        \"\"\"Called when you do: print(r) — like the pit wall display\"\"\"\n        return f\"RaceResult({self.data.tolist()})\"\n    \n    def __len__(self):\n        \"\"\"Called when you do: len(r) — how many laps/sectors in this result\"\"\"\n        return len(self.data)\n    \n    def __getitem__(self, idx):\n        \"\"\"Called when you do: r[idx] — look up a specific lap\"\"\"\n        return RaceResult(self.data[idx])\n    \n    def __add__(self, other):\n        \"\"\"Called when you do: r1 + r2 — combine stint times\"\"\"\n        if isinstance(other, RaceResult):\n            return RaceResult(self.data + other.data)\n        return RaceResult(self.data + other)\n    \n    def __mul__(self, other):\n        \"\"\"Called when you do: r1 * r2 — scale times (e.g., fuel correction)\"\"\"\n        if isinstance(other, RaceResult):\n            return RaceResult(self.data * other.data)\n        return RaceResult(self.data * other)\n    \n    def __matmul__(self, other):\n        \"\"\"Called when you do: r1 @ r2 — dot product (setup-track alignment)\"\"\"\n        return RaceResult(self.data @ other.data)\n    \n    def __lt__(self, other):\n        \"\"\"Called when you do: r1 < r2 — championship standings comparison\"\"\"\n        if isinstance(other, RaceResult):\n            return np.sum(self.data) < np.sum(other.data)\n        return np.sum(self.data) < other\n    \n    @property\n    def shape(self):\n        \"\"\"Access like r.shape (not r.shape()) — just like numpy\"\"\"\n        return self.data.shape\n\n\n# Demonstrate magic methods with race data\nstint1 = RaceResult([91.2, 90.8, 91.5])  # Lap times for stint 1\nstint2 = RaceResult([92.1, 91.5, 92.0])  # Lap times for stint 2\n\nprint(\"__repr__ (pit wall display):\", stint1)\nprint(\"__len__ (laps in stint):\", len(stint1))\nprint(\"__getitem__ (lap 1 time):\", stint1[0])\nprint(\"__add__ (combine stints):\", stint1 + stint2)\nprint(\"__mul__ (fuel-corrected):\", stint1 * 0.98)\nprint(\"__lt__ (faster stint?):\", stint1 < stint2, \"(lower total = faster)\")\nprint(\"scalar add (penalty +5s):\", stint1 + 5)\nprint(\"shape property:\", stint1.shape)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### `__call__`: Making Objects Callable\n\nThis is **THE** most important magic method for deep learning. It lets you call an object like a function:\n\n```python\nmodel = MyModel()    # __init__\noutput = model(x)    # __call__ -> forward\n```\n\n**F1 analogy:** `__call__` is the green light at the end of pit lane. When you \"call\" the car (send it onto the track), the car doesn't just drive — it runs a whole sequence: warm up tires, engage DRS detection, start telemetry logging, *then* execute the actual lap (`forward()`), then collect post-lap data. PyTorch's `nn.Module.__call__` works the same way:\n1. Calls hooks (if any) — pre-lap checks\n2. Calls your `forward()` method — the actual lap\n3. Calls more hooks — post-lap data collection\n4. Returns the result"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# An F1 car's telemetry processing pipeline — demonstrating __call__\nclass TelemetryPipeline:\n    \"\"\"Neural network that processes F1 telemetry data, demonstrating __call__.\"\"\"\n    \n    def __init__(self, layer_sizes):\n        self.layers = []\n        for i in range(len(layer_sizes) - 1):\n            self.layers.append(Linear(layer_sizes[i], layer_sizes[i+1]))\n        self.activation = SoftTire()  # Using our ReLU-equivalent tire compound!\n            \n    def forward(self, x):\n        \"\"\"Forward pass — process telemetry through all layers.\"\"\"\n        for i, layer in enumerate(self.layers):\n            x = layer(x)\n            # Apply activation to all but last layer\n            if i < len(self.layers) - 1:\n                x = self.activation.grip_curve(x)\n        return x\n    \n    def __call__(self, x):\n        \"\"\"Makes the pipeline callable — like sending the car out on track.\"\"\"\n        return self.forward(x)\n    \n    def __repr__(self):\n        \"\"\"Pit wall display — shows pipeline architecture.\"\"\"\n        layers_str = \"\\n  \".join([f\"Linear({l.weight.shape[0]} -> {l.weight.shape[1]})\" \n                                   for l in self.layers])\n        return f\"TelemetryPipeline(\\n  {layers_str}\\n)\"\n\n\n# Create and use the pipeline\npipeline = TelemetryPipeline([784, 128, 64, 10])\nprint(pipeline)\n\n# Forward pass — note we call pipeline(x), not pipeline.forward(x)\nx = np.random.randn(32, 784)  # Batch of 32 telemetry snapshots (784 sensor channels)\noutput = pipeline(x)  # This calls __call__ -> forward\n\nprint(f\"\\nInput shape (snapshots x sensors): {x.shape}\")\nprint(f\"Output shape (snapshots x predictions): {output.shape}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### `__getitem__` and `__len__`: Building a Dataset\n\nThese methods let you create custom datasets that work with PyTorch's DataLoader.\n\n**F1 analogy:** Think of a season's worth of race data. `__len__` tells you how many races are in the calendar (e.g., 24). `__getitem__` lets you pull up the data for any specific race by index — `season[5]` gets you the Monaco Grand Prix telemetry. This is exactly how PyTorch datasets work."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "class Dataset:\n    \"\"\"Base dataset class (like torch.utils.data.Dataset).\"\"\"\n    \n    def __len__(self):\n        raise NotImplementedError\n        \n    def __getitem__(self, idx):\n        raise NotImplementedError\n\n\nclass SeasonTelemetryDataset(Dataset):\n    \"\"\"A season's worth of F1 telemetry data for demonstration.\"\"\"\n    \n    def __init__(self, n_laps, n_sensors, n_tire_compounds):\n        # Each lap has sensor readings (features) and tire compound used (label)\n        self.X = np.random.randn(n_laps, n_sensors)  # Telemetry readings\n        self.y = np.random.randint(0, n_tire_compounds, n_laps)  # Tire compound: 0=soft, 1=medium, 2=hard\n        \n    def __len__(self):\n        \"\"\"Return number of laps in dataset.\"\"\"\n        return len(self.X)\n    \n    def __getitem__(self, idx):\n        \"\"\"Return (telemetry, tire_compound) for given lap index.\"\"\"\n        return self.X[idx], self.y[idx]\n\n\n# Create dataset — a season of telemetry\nseason_data = SeasonTelemetryDataset(n_laps=1000, n_sensors=10, n_tire_compounds=3)\n\n# Now we can use len() and indexing!\nprint(f\"Total laps in dataset: {len(season_data)}\")\nprint(f\"Lap 0: telemetry={season_data[0][0][:3]}..., tire_compound={season_data[0][1]}\")\nprint(f\"Last lap: telemetry={season_data[-1][0][:3]}..., tire_compound={season_data[-1][1]}\")\n\n# We can iterate through laps!\ncompound_names = {0: 'Soft', 1: 'Medium', 2: 'Hard'}\nprint(\"\\nFirst 3 laps:\")\nfor i in range(3):\n    telemetry, compound = season_data[i]\n    print(f\"  Lap {i}: tire compound = {compound_names[compound]}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Complete Magic Methods Reference\n\n| Method | Triggered By | Example | F1 Parallel |\n|--------|--------------|--------|-------------|\n| `__init__(self, ...)` | `obj = Class(...)` | Constructor | Building the car at the factory |\n| `__repr__(self)` | `print(obj)`, `repr(obj)` | String representation | Pit wall display |\n| `__str__(self)` | `str(obj)` | Human-readable string | TV broadcast graphic |\n| `__len__(self)` | `len(obj)` | Length | Number of laps in a stint |\n| `__getitem__(self, key)` | `obj[key]` | Indexing | Pull up lap 17's data |\n| `__setitem__(self, key, val)` | `obj[key] = val` | Index assignment | Override a lap's data |\n| `__call__(self, ...)` | `obj(...)` | Call like function | Send the car onto track |\n| `__iter__(self)` | `for x in obj:` | Iteration | Loop through each race |\n| `__next__(self)` | `next(obj)` | Next item | Next lap on the calendar |\n| `__add__(self, other)` | `obj + other` | Addition | Combine stint times |\n| `__sub__(self, other)` | `obj - other` | Subtraction | Gap to leader |\n| `__mul__(self, other)` | `obj * other` | Multiplication | Fuel correction factor |\n| `__matmul__(self, other)` | `obj @ other` | Matrix multiplication | Setup-track alignment score |\n| `__eq__(self, other)` | `obj == other` | Equality | Same finishing position? |\n| `__lt__(self, other)` | `obj < other` | Less than | Championship standings |\n| `__enter__(self)` | `with obj:` | Context manager enter | Green flag — session starts |\n| `__exit__(self, ...)` | End of `with` block | Context manager exit | Checkered flag — session ends |"
  },
  {
   "cell_type": "markdown",
   "source": "### What this means:\n\n**Decorators** are like FIA technical regulations wrapped around your car's design — they add validation, timing, and monitoring without changing the core engineering.\n\n**F1 analogy:** Every F1 lap is automatically timed by the official timing system. The driver doesn't need to start and stop a stopwatch — the timing loops embedded in the track surface *decorate* every lap with precise sector times. Similarly, the FIA fuel flow sensor wraps every engine with a validator that checks compliance without the engine needing to know about it. That's what decorators do:\n- `@timed` wraps your function to measure how long it takes (timing loops)\n- `@validated` wraps your function to check inputs meet regulations (scrutineering)\n- `@torch.no_grad()` wraps your function to disable gradient tracking (like switching off data logging to go faster during qualifying sims)",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## 4. Decorators\n\nA **decorator** modifies or enhances a function without changing its code. It's a function that takes a function and returns a new function.\n\n### Why Decorators Matter in Deep Learning\n\n| Decorator | Use | F1 Parallel |\n|-----------|-----|-------------|\n| `@property` | Access method like attribute (`model.device`) | `car.tire_wear` computed from laps driven |\n| `@staticmethod` | Method that doesn't need `self` | Utility: convert km/h to mph |\n| `@classmethod` | Method that operates on class, not instance | `Car.from_telemetry_file(path)` factory method |\n| `@torch.no_grad()` | Disable gradient computation (inference) | Race mode: no data logging overhead |\n| `@torch.jit.script` | JIT compile for speed | Turbo mode: pre-compiled strategy model |\n| Custom `@timed` decorator | Profile your code | Lap timing system (automatic) |\n| Custom `@validated` decorator | Check inputs | FIA scrutineering (technical regulation checks) |"
  },
  {
   "cell_type": "code",
   "source": "# Visualization: Decorator Flow Diagram — Lap Timing System\nfig, ax = plt.subplots(figsize=(12, 6))\nax.set_xlim(0, 12)\nax.set_ylim(0, 8)\nax.axis('off')\nax.set_title('How Decorators Work: @timed (Like F1 Timing Loops)', fontsize=14, fontweight='bold')\n\n# Helper function to draw boxes\ndef draw_flow_box(ax, x, y, w, h, text, color='lightblue', fontsize=10):\n    rect = plt.Rectangle((x, y), w, h, fill=True, facecolor=color, \n                          edgecolor='black', linewidth=2, alpha=0.8)\n    ax.add_patch(rect)\n    ax.text(x + w/2, y + h/2, text, ha='center', va='center', fontsize=fontsize)\n\n# Step 1: Original function (the raw lap)\ndraw_flow_box(ax, 0.5, 5.5, 2.5, 1.5, 'drive_lap()', 'lightyellow', 11)\nax.text(1.75, 7.3, '1. Original\\nfunction', ha='center', fontsize=9)\n\n# Arrow\nax.annotate('', xy=(3.3, 6.25), xytext=(3, 6.25),\n            arrowprops=dict(arrowstyle='->', color='black', lw=2))\n\n# Step 2: @timed decorator (timing loops on track)\ndraw_flow_box(ax, 3.5, 5, 3, 2.5, '@timed\\ndef drive_lap():\\n    ...', 'lightcoral', 10)\nax.text(5, 7.8, '2. Apply\\ndecorator', ha='center', fontsize=9)\n\n# Arrow\nax.annotate('', xy=(6.8, 6.25), xytext=(6.5, 6.25),\n            arrowprops=dict(arrowstyle='->', color='black', lw=2))\n\n# Step 3: Wrapper function (the full timing system)\ndraw_flow_box(ax, 7, 4.5, 4.5, 3.5, 'timed_lap():\\n  cross timing line\\n  result = drive_lap()\\n  record sector time\\n  return result', \n              'lightgreen', 9)\nax.text(9.25, 8.3, '3. Returns wrapped\\nfunction', ha='center', fontsize=9)\n\n# What happens when you call\nax.text(6, 2.5, 'When you call drive_lap():', fontsize=11, fontweight='bold')\nax.text(6, 1.8, 'Python actually calls timed_lap() which:', fontsize=10)\nax.text(6, 1.2, '1. Starts sector timer  2. Drives the actual lap  3. Records lap time', fontsize=9)\n\n# Code example box\ncode_box = plt.Rectangle((0.5, 0.3, ), 5, 1.5, fill=True, facecolor='#f0f0f0', \n                          edgecolor='gray', linewidth=1)\nax.add_patch(code_box)\nax.text(3, 1.35, '@timed', fontsize=10, fontfamily='monospace')\nax.text(3, 0.85, 'def qualify(): ...', fontsize=10, fontfamily='monospace')\nax.text(3, 0.5, '# Same as: qualify = timed(qualify)', fontsize=9, fontfamily='monospace', color='gray')\n\nplt.tight_layout()\nplt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import time\nfrom functools import wraps\n\n# @timed decorator — like the F1 timing loops embedded in the track\ndef timed(func):\n    \"\"\"Decorator that times function execution — like sector timing loops.\"\"\"\n    @wraps(func)  # Preserves function name and docstring\n    def wrapper(*args, **kwargs):\n        start = time.time()\n        result = func(*args, **kwargs)\n        end = time.time()\n        print(f\"{func.__name__} lap time: {end - start:.4f} seconds\")\n        return result\n    return wrapper\n\n\n@timed\ndef slow_pit_stop():\n    \"\"\"A slow pit stop for demonstration.\"\"\"\n    time.sleep(0.1)\n    return \"tires changed\"\n\n\n@timed\ndef compute_telemetry_matrix(n_laps):\n    \"\"\"Process a telemetry matrix — like crunching race data on the pit wall.\"\"\"\n    A = np.random.randn(n_laps, n_laps)\n    B = np.random.randn(n_laps, n_laps)\n    return A @ B\n\n\n# Use the decorated functions — timing is automatic!\nresult1 = slow_pit_stop()\nresult2 = compute_telemetry_matrix(1000)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# More useful decorators — F1 engineering tools\n\ndef debug(func):\n    \"\"\"Print function arguments and return value — like telemetry logging.\"\"\"\n    @wraps(func)\n    def wrapper(*args, **kwargs):\n        args_str = \", \".join([repr(a) for a in args])\n        kwargs_str = \", \".join([f\"{k}={v!r}\" for k, v in kwargs.items()])\n        all_args = \", \".join(filter(None, [args_str, kwargs_str]))\n        print(f\"Calling {func.__name__}({all_args})\")\n        result = func(*args, **kwargs)\n        print(f\"  -> {result!r}\")\n        return result\n    return wrapper\n\n\ndef validated(max_attempts=3):\n    \"\"\"Retry a function if it raises an exception — like re-scrutineering after a failure.\"\"\"\n    def decorator(func):\n        @wraps(func)\n        def wrapper(*args, **kwargs):\n            for attempt in range(max_attempts):\n                try:\n                    return func(*args, **kwargs)\n                except Exception as e:\n                    print(f\"Scrutineering attempt {attempt + 1} failed: {e}\")\n                    if attempt == max_attempts - 1:\n                        raise\n        return wrapper\n    return decorator\n\n\n@debug\ndef calculate_gap(leader_time, chaser_time):\n    \"\"\"Calculate gap between two drivers.\"\"\"\n    return chaser_time - leader_time\n\ngap = calculate_gap(91.2, 91.8)\ngap = calculate_gap(91.2, chaser_time=92.1)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Built-in Decorators: `@property`, `@staticmethod`, `@classmethod`\n\n**F1 analogy:** `@property` is perfect for values that are *computed* from the car's state — like `tire_wear` (depends on laps driven) or `fuel_load` (decreases each lap). You access them like attributes (`car.tire_wear`), but they're recalculated each time. `@staticmethod` is a utility that doesn't need a specific car instance — like a unit converter. `@classmethod` operates on the team/class level — like counting total cars built."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "class F1Car:\n    \"\"\"An F1 car demonstrating @property, @staticmethod, @classmethod.\"\"\"\n    \n    _car_count = 0\n    MAX_FUEL_KG = 110  # FIA regulation: max 110kg fuel\n    \n    def __init__(self, driver_name, initial_fuel_kg=110):\n        self.driver_name = driver_name\n        self._fuel_kg = initial_fuel_kg\n        self._laps_driven = 0\n        self._tire_compound = \"Medium\"\n        F1Car._car_count += 1\n        \n    @property\n    def tire_wear(self):\n        \"\"\"Computed from laps driven — access like an attribute, not a method call.\"\"\"\n        # Tire wear increases ~1.5% per lap (simplified model)\n        wear_pct = min(100, self._laps_driven * 1.5)\n        return wear_pct\n    \n    @property\n    def fuel_load(self):\n        \"\"\"Fuel decreases ~1.7kg per lap — computed on the fly.\"\"\"\n        return max(0, self._fuel_kg - self._laps_driven * 1.7)\n    \n    @property\n    def car_status(self):\n        \"\"\"Summary string for pit wall display.\"\"\"\n        return f\"{self.driver_name}: fuel={self.fuel_load:.1f}kg, tire_wear={self.tire_wear:.1f}%\"\n    \n    def complete_lap(self):\n        \"\"\"Drive one more lap.\"\"\"\n        self._laps_driven += 1\n    \n    @staticmethod\n    def kmh_to_mph(kmh):\n        \"\"\"Static method — doesn't need self, just a utility conversion.\"\"\"\n        return kmh * 0.621371\n    \n    @classmethod\n    def get_car_count(cls):\n        \"\"\"Class method — operates on the class, not instance.\"\"\"\n        return cls._car_count\n    \n    @classmethod\n    def from_config(cls, config):\n        \"\"\"Alternative constructor from a config dict.\"\"\"\n        return cls(driver_name=config['driver'], initial_fuel_kg=config.get('fuel', 110))\n\n\n# Using @property — note NO parentheses!\ncar = F1Car(\"Verstappen\", initial_fuel_kg=105)\nprint(f\"Initial status: {car.car_status}\")\n\n# Drive some laps and watch properties update automatically\nfor lap in range(10):\n    car.complete_lap()\nprint(f\"After 10 laps: {car.car_status}\")\nprint(f\"Tire wear: {car.tire_wear:.1f}%\")  # Not tire_wear()!\nprint(f\"Fuel remaining: {car.fuel_load:.1f}kg\")\n\n# Using @staticmethod — can call on class or instance\nprint(f\"\\n350 km/h = {F1Car.kmh_to_mph(350):.1f} mph\")\n\n# Using @classmethod\ncar2 = F1Car(\"Perez\")\nprint(f\"\\nTotal cars on grid: {F1Car.get_car_count()}\")\n\n# Alternative constructor — build car from a setup sheet\nsetup_sheet = {'driver': 'Norris', 'fuel': 100}\ncar3 = F1Car.from_config(setup_sheet)\nprint(f\"Created from config: {car3.driver_name}, fuel={car3.fuel_load:.1f}kg\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## 5. Context Managers\n\nContext managers handle setup and cleanup automatically using the `with` statement.\n\n### Why Context Managers Matter in Deep Learning\n\n```python\n# Disable gradients during inference\nwith torch.no_grad():\n    predictions = model(test_data)\n\n# Automatic mixed precision training\nwith torch.cuda.amp.autocast():\n    output = model(input)\n\n# Timer context\nwith Timer(\"Training\"):\n    train_one_epoch()\n```\n\n### The F1 Connection\n\n**F1 analogy:** A context manager is like a race session. When you enter `with RaceSession(\"Qualifying\"):`, the system automatically: starts the clock, enables telemetry recording, sets the pit lane speed limit, and opens the track. When the session ends (you exit the `with` block), it automatically: waves the checkered flag, stops telemetry, closes the pit lane, and saves all data. You don't have to remember to do any of this cleanup manually — it happens automatically, even if something goes wrong (like a red flag)."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Context manager for timing — like an F1 session timer\nclass SessionTimer:\n    \"\"\"Context manager for timing code blocks — like an F1 session clock.\"\"\"\n    \n    def __init__(self, session_name=\"Session\"):\n        self.session_name = session_name\n        \n    def __enter__(self):\n        \"\"\"Called when entering the 'with' block — green flag!\"\"\"\n        self.start = time.time()\n        return self  # This is what 'as' binds to\n    \n    def __exit__(self, exc_type, exc_val, exc_tb):\n        \"\"\"Called when exiting the 'with' block — checkered flag!\"\"\"\n        self.elapsed = time.time() - self.start\n        print(f\"{self.session_name} session time: {self.elapsed:.4f} seconds\")\n        return False  # Don't suppress exceptions\n\n\n# Use it — like running different F1 sessions\nwith SessionTimer(\"Telemetry Processing\"):\n    A = np.random.randn(500, 500)\n    B = np.random.randn(500, 500)\n    C = A @ B\n    \nwith SessionTimer(\"Strategy Simulation\"):\n    total = 0\n    for i in range(100000):\n        total += i"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Simulating torch.no_grad() — like switching to \"race mode\" (no data logging overhead)\nclass RaceMode:\n    \"\"\"Context manager to disable telemetry logging (like torch.no_grad()).\"\"\"\n    \n    # Class variable to track global state\n    logging_enabled = True\n    \n    def __enter__(self):\n        self.prev_state = RaceMode.logging_enabled\n        RaceMode.logging_enabled = False\n        print(\"Telemetry logging disabled (race mode — maximum speed)\")\n        return self\n    \n    def __exit__(self, *args):\n        RaceMode.logging_enabled = self.prev_state\n        print(\"Telemetry logging restored\")\n        return False\n\n\ndef process_lap_data():\n    \"\"\"Function that checks whether we're logging telemetry.\"\"\"\n    if RaceMode.logging_enabled:\n        print(\"  Processing with full telemetry logging (training mode)\")\n    else:\n        print(\"  Processing WITHOUT logging — faster! (inference/race mode)\")\n\n\nprint(\"Practice session (training mode):\")\nprocess_lap_data()\n\nprint(\"\\nQualifying hot lap (race mode — no logging overhead):\")\nwith RaceMode():\n    process_lap_data()\n\nprint(\"\\nBack to practice (training mode):\")\nprocess_lap_data()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## 6. Type Hints\n\nType hints document what types your functions expect and return. They don't enforce types at runtime but help with:\n- Documentation\n- IDE autocomplete\n- Static analysis tools (mypy)\n\n**F1 analogy:** F1 is a safety-critical system. The FIA mandates precise specifications: fuel flow must be a `float` in kg/s, tire pressure must be a `float` in PSI, pit speed limit is an `int` in km/h. Type hints in code serve the same purpose — they're the technical regulations for your data. In a real-time telemetry system, sending a `str` where a `float` is expected could mean the difference between a perfect pit stop and a catastrophic failure. Type hints are how you catch those bugs before they hit the track.\n\n### Basic Type Hints"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from typing import List, Dict, Tuple, Optional, Union, Callable\nimport numpy as np\n\n# Basic types — strict like FIA technical regulations\ndef format_driver_name(name: str) -> str:\n    return f\"Driver: {name}\"\n\ndef calculate_gap(leader_time: float, chaser_time: float) -> float:\n    return chaser_time - leader_time\n\n# Collections — telemetry is full of typed collections\ndef total_stint_time(lap_times: List[float]) -> float:\n    return sum(lap_times)\n\ndef get_sensor_shapes(telemetry: Dict[str, np.ndarray]) -> List[Tuple[int, ...]]:\n    return [v.shape for v in telemetry.values()]\n\n# Optional (can be None) — like optional DRS activation\ndef get_tire_response(compound: Optional[str] = None) -> Callable:\n    if compound is None or compound == 'soft':\n        return lambda x: np.maximum(0, x)  # ReLU (aggressive)\n    elif compound == 'medium':\n        return lambda x: 1 / (1 + np.exp(-x))  # Sigmoid (balanced)\n    else:\n        raise ValueError(f\"Unknown compound: {compound}\")\n\n# Union (can be multiple types) — sensor data arrives in different formats\ndef normalize_telemetry(data: Union[List[float], np.ndarray]) -> np.ndarray:\n    arr = np.array(data)\n    return (arr - arr.mean()) / arr.std()\n\n\n# Examples\nprint(format_driver_name(\"Verstappen\"))\nprint(f\"Gap: {calculate_gap(91.2, 91.8):.3f}s\")\nprint(f\"Total stint: {total_stint_time([91.2, 90.8, 91.5])}s\")\nprint(f\"Normalized: {normalize_telemetry([320, 315, 322, 318, 325])}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Type hints in classes — F1 race configuration (like a setup sheet)\nfrom dataclasses import dataclass\nfrom typing import List, Optional\n\n\n@dataclass\nclass RaceStrategyConfig:\n    \"\"\"Configuration for a race strategy — like a pre-race setup sheet.\n    \n    In ML, this pattern is used for TrainingConfig (learning_rate, batch_size, etc.).\n    In F1, this is your race engineer's strategy briefing.\"\"\"\n    fuel_load_kg: float = 105.0\n    tire_compound: str = \"Medium\"\n    pit_stops: int = 1\n    stint_lengths: List[int] = None\n    drs_offset: Optional[float] = None\n    \n    def __post_init__(self):\n        if self.stint_lengths is None:\n            self.stint_lengths = [25, 32]  # Default: 2-stop strategy\n\n\n# @dataclass automatically generates __init__, __repr__, etc.\nstrategy = RaceStrategyConfig(fuel_load_kg=100.0, pit_stops=2)\nprint(strategy)\n\n# Access fields — just like a training config\nprint(f\"\\nFuel load: {strategy.fuel_load_kg}kg\")\nprint(f\"Stint lengths: {strategy.stint_lengths} laps\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## 7. Putting It All Together: A Mini Deep Learning Framework\n\nLet's build a minimal neural network framework using everything we've learned — with F1 naming throughout.\n\n**F1 analogy:** This is like building a complete car from components. We need a base `Module` (the chassis), `Linear` layers (processing stages in the ECU), activation functions (tire compound response curves), and a `Sequential` container (the full car assembly). Every part uses the OOP concepts we've covered: inheritance, magic methods, properties, and type hints."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from typing import List, Callable, Optional\nfrom abc import ABC, abstractmethod\nimport numpy as np\n\n\nclass Module(ABC):\n    \"\"\"Base class for all neural network modules — the chassis of our F1 car.\"\"\"\n    \n    def __init__(self):\n        self._parameters: Dict[str, np.ndarray] = {}\n        self._modules: Dict[str, 'Module'] = {}\n        self.training: bool = True  # True = practice session, False = race mode\n        \n    @abstractmethod\n    def forward(self, x: np.ndarray) -> np.ndarray:\n        \"\"\"Forward pass — must be implemented by subclasses (like each team's aero design).\"\"\"\n        pass\n    \n    def __call__(self, x: np.ndarray) -> np.ndarray:\n        \"\"\"Make module callable — send the car onto the track.\"\"\"\n        return self.forward(x)\n    \n    def parameters(self) -> List[np.ndarray]:\n        \"\"\"Return all tunable parameters — like all the adjustable settings in the ECU.\"\"\"\n        params = list(self._parameters.values())\n        for module in self._modules.values():\n            params.extend(module.parameters())\n        return params\n    \n    def train(self, mode: bool = True):\n        \"\"\"Set training mode — practice session with full telemetry.\"\"\"\n        self.training = mode\n        for module in self._modules.values():\n            module.train(mode)\n        return self\n    \n    def eval(self):\n        \"\"\"Set evaluation mode — race mode, no logging overhead.\"\"\"\n        return self.train(False)\n\n\nclass Linear(Module):\n    \"\"\"Fully connected layer — a single processing stage in the car's ECU.\"\"\"\n    \n    def __init__(self, in_features: int, out_features: int):\n        super().__init__()\n        # Xavier initialization — like calibrating sensor mappings\n        scale = np.sqrt(2.0 / (in_features + out_features))\n        self._parameters['weight'] = np.random.randn(in_features, out_features) * scale\n        self._parameters['bias'] = np.zeros(out_features)\n        \n    def forward(self, x: np.ndarray) -> np.ndarray:\n        return x @ self._parameters['weight'] + self._parameters['bias']\n    \n    def __repr__(self):\n        w = self._parameters['weight']\n        return f\"Linear({w.shape[0]}, {w.shape[1]})\"\n\n\nclass ReLU(Module):\n    \"\"\"ReLU activation — the Soft tire response: aggressive, all-or-nothing.\"\"\"\n    \n    def forward(self, x: np.ndarray) -> np.ndarray:\n        return np.maximum(0, x)\n    \n    def __repr__(self):\n        return \"ReLU()\"\n\n\nclass Sequential(Module):\n    \"\"\"Sequential container — the full car assembly, processing data through each stage.\"\"\"\n    \n    def __init__(self, *modules: Module):\n        super().__init__()\n        for i, module in enumerate(modules):\n            self._modules[str(i)] = module\n            \n    def forward(self, x: np.ndarray) -> np.ndarray:\n        for module in self._modules.values():\n            x = module(x)\n        return x\n    \n    def __repr__(self):\n        \"\"\"Pit wall display — shows the full car architecture.\"\"\"\n        lines = [\"Sequential(\"]\n        for name, module in self._modules.items():\n            lines.append(f\"  ({name}): {module}\")\n        lines.append(\")\")\n        return \"\\n\".join(lines)\n\n\n# Build a telemetry processing model — like assembling an F1 car!\nmodel = Sequential(\n    Linear(784, 256),   # Sensor intake: 784 raw channels -> 256 processed\n    ReLU(),             # Soft tire response (aggressive activation)\n    Linear(256, 128),   # Feature extraction: 256 -> 128\n    ReLU(),\n    Linear(128, 10)     # Final prediction: 128 -> 10 output classes\n)\n\nprint(model)\nprint(f\"\\nNumber of parameter arrays: {len(model.parameters())}\")\nprint(f\"Total parameters: {sum(p.size for p in model.parameters()):,}\")\n\n# Forward pass — process a batch of telemetry snapshots\nx = np.random.randn(32, 784)  # 32 telemetry snapshots, 784 sensors each\noutput = model(x)\nprint(f\"\\nInput shape (snapshots x sensors): {x.shape}\")\nprint(f\"Output shape (snapshots x predictions): {output.shape}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## Exercises\n\n### Exercise 1: Build a DRS (Drag Reduction System) Layer\n\nIn F1, DRS opens a flap on the rear wing to reduce drag on straights — but only when you're within 1 second of the car ahead, and only in designated DRS zones.\n\nIn neural networks, **Dropout** works similarly: it randomly \"opens\" (zeros out) neurons during training to prevent over-reliance on any single pathway. During the race (evaluation), DRS rules are off — all neurons are active.\n\nImplement a dropout layer that:\n- During training: randomly zeros elements with probability `p` (like randomly disabling DRS for some cars)\n- During evaluation: does nothing (but scales output to compensate)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "class DRSLayer(Module):\n    \"\"\"Dropout layer — like the DRS system randomly enabling/disabling aero elements.\"\"\"\n    \n    def __init__(self, p: float = 0.5):\n        super().__init__()\n        self.p = p  # Probability of dropping a neuron (closing DRS)\n        \n    def forward(self, x: np.ndarray) -> np.ndarray:\n        # TODO: Implement dropout\n        # Hint: \n        # - During training (self.training == True): create mask, apply it, scale by 1/(1-p)\n        # - During eval (race day): just return x — all systems active\n        \n        if self.training:\n            # Like randomly activating DRS for (1-p) fraction of the field\n            mask = np.random.binomial(1, 1 - self.p, x.shape)\n            return x * mask / (1 - self.p)  # Scale to keep expected value the same\n        return x\n    \n    def __repr__(self):\n        return f\"DRSLayer(p={self.p})\"\n\n\n# Test the DRS layer\ndrs = DRSLayer(p=0.5)\nx = np.ones((2, 10))  # 2 cars, 10 sensor readings each\n\nprint(\"Practice session (training mode — DRS randomly applied):\")\ndrs.train()\nprint(drs(x))\n\nprint(\"\\nRace day (eval mode — all systems active):\")\ndrs.eval()\nprint(drs(x))"
  },
  {
   "cell_type": "markdown",
   "source": "### Interactive Example: How DRS / Dropout Rate Affects Performance\n\nTry changing the dropout rate to see how it affects the network's activations — like adjusting how aggressively the DRS zones are enforced.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Interactive: Visualizing dropout at different rates — like DRS activation zones\n# Try changing dropout_rate to see the effect!\n\ndef visualize_drs_effect(dropout_rates=[0.0, 0.25, 0.5, 0.75]):\n    \"\"\"Visualize how different dropout rates affect sensor activations.\"\"\"\n    np.random.seed(42)\n    \n    # Create input (simulating sensor readings from a hidden layer)\n    x = np.abs(np.random.randn(1, 100))  # 100 sensor channels, positive values\n    \n    fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n    axes = axes.flatten()\n    \n    for ax, p in zip(axes, dropout_rates):\n        # Apply dropout (DRS-style random masking)\n        if p > 0:\n            mask = np.random.binomial(1, 1 - p, x.shape)\n            output = x * mask / (1 - p)  # Inverted dropout scaling\n        else:\n            output = x.copy()\n            mask = np.ones_like(x)\n        \n        # Visualize — green = active sensor, red = dropped\n        colors = ['green' if m else 'red' for m in mask.flatten()]\n        ax.bar(range(100), output.flatten(), color=colors, alpha=0.7, width=1.0)\n        ax.axhline(y=x.mean(), color='blue', linestyle='--', \n                   label=f'Original mean: {x.mean():.2f}', linewidth=2)\n        ax.axhline(y=output.mean(), color='orange', linestyle='-', \n                   label=f'After DRS/dropout: {output.mean():.2f}', linewidth=2)\n        \n        n_dropped = int(p * 100)\n        ax.set_title(f'DRS Rate p={p}\\n({n_dropped} sensors dropped, {100-n_dropped} active)', \n                     fontsize=11, fontweight='bold')\n        ax.set_xlabel('Sensor channel')\n        ax.set_ylabel('Activation value')\n        ax.legend(loc='upper right', fontsize=8)\n        ax.set_xlim(-1, 101)\n    \n    plt.suptitle('Effect of Dropout/DRS Rate on Sensor Activations\\n(Green = active, Red = dropped)', \n                 fontsize=13, fontweight='bold', y=1.02)\n    plt.tight_layout()\n    plt.show()\n    \n    print(\"Key insight: Notice how the mean stays roughly the same!\")\n    print(\"This is because we scale by 1/(1-p) during training.\")\n    print(\"In F1 terms: the team compensates for DRS by adjusting other aero elements.\")\n    print(\"\\nTry different rates:\")\n    print(\"  - p=0.0: No dropout (all sensors active — like a dry race)\")\n    print(\"  - p=0.5: Typical dropout (50% dropped — balanced regulation)\")\n    print(\"  - p=0.75: Aggressive dropout (may hurt — like heavy rain)\")\n\n# Run the visualization\nvisualize_drs_effect()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Exercise 2: Create a Race Data Loader\n\nIn F1, telemetry data streams in continuously. But the pit wall processes it in batches — chunks of laps at a time, not one sample at a time.\n\nBuild a DataLoader (like a pit wall data feed) that:\n- Takes a dataset and batch_size\n- Is iterable (use `__iter__` and `__next__` — iterate through batches of laps)\n- Optionally shuffles data (like randomizing which laps to analyze first)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "class PitWallDataLoader:\n    \"\"\"DataLoader — like the pit wall data feed that processes telemetry in batches.\"\"\"\n    \n    def __init__(self, dataset, batch_size: int = 32, shuffle: bool = False):\n        self.dataset = dataset\n        self.batch_size = batch_size\n        self.shuffle = shuffle\n        \n    def __len__(self):\n        \"\"\"Number of batches — how many chunks of data to process.\"\"\"\n        return (len(self.dataset) + self.batch_size - 1) // self.batch_size\n    \n    def __iter__(self):\n        \"\"\"Return iterator — start a new pass through the data.\"\"\"\n        # TODO: Create indices, optionally shuffle, reset position\n        self.indices = np.arange(len(self.dataset))\n        if self.shuffle:\n            np.random.shuffle(self.indices)  # Randomize lap order for training\n        self.pos = 0\n        return self\n    \n    def __next__(self):\n        \"\"\"Get next batch of laps — like the pit wall requesting the next chunk.\"\"\"\n        # TODO: Return next batch or raise StopIteration (checkered flag!)\n        if self.pos >= len(self.dataset):\n            raise StopIteration  # Checkered flag — no more data\n            \n        batch_indices = self.indices[self.pos:self.pos + self.batch_size]\n        self.pos += self.batch_size\n        \n        # Collect batch of telemetry and labels\n        batch_telemetry = []\n        batch_compounds = []\n        for idx in batch_indices:\n            telemetry, compound = self.dataset[idx]\n            batch_telemetry.append(telemetry)\n            batch_compounds.append(compound)\n            \n        return np.array(batch_telemetry), np.array(batch_compounds)\n\n\n# Test with our season telemetry dataset\nseason_data = SeasonTelemetryDataset(100, 10, 3)\npit_wall_feed = PitWallDataLoader(season_data, batch_size=32, shuffle=True)\n\nprint(f\"Total laps in dataset: {len(season_data)}\")\nprint(f\"Number of batches: {len(pit_wall_feed)}\")\n\nprint(\"\\nPit wall processing batches:\")\nfor i, (telemetry, compounds) in enumerate(pit_wall_feed):\n    print(f\"  Batch {i}: telemetry.shape={telemetry.shape}, compounds.shape={compounds.shape}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## Summary\n\n### Key Concepts\n\n| Concept | What It Does | PyTorch Example | F1 Parallel |\n|---------|--------------|------------------|-------------|\n| Classes | Bundle data and methods | `nn.Module`, `Dataset` | Car design spec (aero, engine, suspension) |\n| Inheritance | Extend existing classes | `class MyModel(nn.Module)` | SoftTire/MediumTire/HardTire extend base Tire |\n| `__init__` | Initialize object | Setup layers and parameters | Factory build: install engine, tires, aero |\n| `__call__` | Make callable | `model(input)` | Send the car onto the track |\n| `__len__` | Enable `len()` | `len(dataset)` | Number of laps in a stint |\n| `__getitem__` | Enable indexing | `dataset[0]` | Pull up lap 17's telemetry |\n| `__repr__` | Nice printing | `print(model)` | Pit wall display |\n| `__lt__` | Comparison | `result1 < result2` | Championship standings |\n| `__add__` | Addition | `tensor1 + tensor2` | Combining stint times |\n| `@property` | Computed attributes | `model.device` | `car.tire_wear` (computed from laps) |\n| `@timed` | Custom decorator | Profiling | Sector timing loops |\n| Decorators | Modify functions | `@torch.no_grad()` | FIA scrutineering (validate without changing) |\n| Context managers | Setup/cleanup | `with torch.no_grad():` | Race session (green flag to checkered flag) |\n| Type hints | Document types | `def forward(self, x: Tensor) -> Tensor:` | FIA technical regulations (strict specs) |\n\n### Checklist\n- [ ] I can create classes with `__init__` and methods\n- [ ] I understand inheritance and `super()` (base Tire -> SoftTire, MediumTire, HardTire)\n- [ ] I can use magic methods (`__call__`, `__len__`, `__getitem__`, `__lt__`, `__add__`)\n- [ ] I can write and use decorators (`@timed`, `@validated`)\n- [ ] I can create context managers (session timers, race mode)\n- [ ] I can add type hints to functions and classes (safety-critical specs)"
  },
  {
   "cell_type": "markdown",
   "source": "### Connection to Deep Learning\n\n| Concept | PyTorch Example | Why It Matters | F1 Parallel |\n|---------|-----------------|----------------|-------------|\n| **Classes & `__init__`** | `class MyModel(nn.Module): def __init__(self): ...` | Every neural network is a class; `__init__` sets up layers and registers parameters | Every F1 car is an instance; the factory build installs engine, aero, and suspension |\n| **Inheritance** | `class MyModel(nn.Module)` | You inherit GPU support, parameter tracking, save/load, and gradient computation for free | A SoftTire inherits base rubber chemistry and only overrides grip characteristics |\n| **`__call__` & `forward`** | `output = model(x)` calls `forward()` | PyTorch adds hooks and gradient tracking when you call the model, so always use `model(x)` not `model.forward(x)` | Sending the car onto track triggers pre-checks, the lap, and post-lap data — not just driving |\n| **`__len__` & `__getitem__`** | `class MyDataset(Dataset)` | DataLoader uses these to batch and shuffle your data automatically | The pit wall uses these to pull any lap's telemetry by index and process in batches |\n| **`@property`** | `model.device`, `tensor.shape` | Access computed values cleanly without parentheses | `car.tire_wear` and `car.fuel_load` — always current, always computed from state |\n| **`@torch.no_grad()`** | `with torch.no_grad(): pred = model(x)` | Disables gradient tracking during inference for speed and memory savings | Race mode: disable telemetry logging overhead for maximum performance |\n| **Context managers** | `with autocast(): ...` | Mixed precision training, gradient scaling, and resource management | Race sessions: automatic setup (green flag) and cleanup (checkered flag) |\n| **Type hints** | `def forward(self, x: Tensor) -> Tensor` | IDE autocomplete, better documentation, catch bugs early | FIA technical regulations: strict type specs prevent safety-critical errors |",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## Next Steps\n\nContinue to **Part 2.2: NumPy Deep Dive** where we'll cover:\n- Advanced array operations (processing multi-channel telemetry data)\n- Broadcasting in depth (applying fuel corrections across all laps simultaneously)\n- Vectorization for performance (why the pit wall processes matrices, not loops)"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
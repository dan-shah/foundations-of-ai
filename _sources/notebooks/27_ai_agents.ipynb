{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Part 8.2: AI Agents and Tool Use\n\nAn LLM that can only generate text is like a brilliant advisor locked in a room â€” full of knowledge but unable to *do* anything. **AI agents** break out of this limitation by giving LLMs the ability to take actions: search the web, execute code, call APIs, and interact with the world through **tools**.\n\n**F1 analogy:** A pure LLM is like a race strategist who can talk about strategy all day but can't actually check the weather radar, query the tire degradation model, or radio the driver. An AI *agent* is the full race engineer â€” someone who **reasons** (\"the tires are degrading faster than expected\"), **decides** (\"we should pit early\"), and **acts** (calls the tire model API, checks the pit window calculator, radios the driver \"box box box\"). The power isn't just in knowing what to do â€” it's in being able to *do* it.\n\nAgent architectures are behind the most capable AI systems today â€” from coding assistants that edit files and run tests, to research agents that browse the web and synthesize findings. Understanding agents means understanding how AI goes from \"answering questions\" to \"completing tasks.\"\n\n## Learning Objectives\n\n- [ ] Understand the agent paradigm: observe, reason, act, repeat\n- [ ] Implement tool definitions and a tool execution framework\n- [ ] Build a ReAct (Reasoning + Acting) agent from scratch\n- [ ] Understand chain-of-thought reasoning and why it improves agent performance\n- [ ] Implement multi-step planning and execution\n- [ ] Build a simple code-execution agent\n- [ ] Understand agent failure modes and safety considerations\n- [ ] Compare single-turn vs. multi-turn agent architectures"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import json\n",
    "import re\n",
    "import math\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Part 8.2: AI Agents and Tool Use\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## 1. What is an AI Agent?\n\nAn **agent** is a system that uses an LLM as its reasoning engine to:\n1. **Observe** the current state (user request, tool outputs, environment)\n2. **Reason** about what to do next (chain-of-thought)\n3. **Act** by calling tools or generating responses\n4. **Repeat** until the task is complete\n\n**F1 analogy:** This is the race engineer's loop during every single lap:\n1. **Observe**: Read the live telemetry â€” tire temps, gap to car ahead, weather radar, fuel load\n2. **Reason**: \"Tires are degrading 0.3s/lap faster than expected, rain probability just jumped to 60%, and the car ahead is on older tires\"\n3. **Act**: Query the tire model for remaining life, check the weather API, calculate optimal pit window\n4. **Repeat**: Every lap, the cycle runs again with updated information\n\n### Agent vs. Chatbot\n\n| Feature | Chatbot | Agent | F1 Parallel |\n|---------|---------|-------|-------------|\n| **Interaction** | Single response per turn | Multi-step execution | Answering a fan's question vs. managing a full race strategy |\n| **Tools** | None (text only) | Can call APIs, run code, search | Can only talk vs. can query weather, tire model, fuel calc |\n| **Planning** | React to each message | Plan ahead, decompose tasks | Responding to radio calls vs. planning a multi-stop strategy |\n| **State** | Conversation history | + tool outputs, environment state | Just the conversation vs. full race state with telemetry |\n| **Autonomy** | User drives every step | Agent decides what to do next | Driver asks every question vs. engineer proactively calls \"box box box\" |"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization: The Agent Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n",
    "ax.set_xlim(0, 12)\n",
    "ax.set_ylim(0, 10)\n",
    "ax.axis('off')\n",
    "ax.set_title('The AI Agent Loop', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Central LLM\n",
    "circle = plt.Circle((6, 5), 1.5, color='#3498db', alpha=0.9, zorder=5)\n",
    "ax.add_patch(circle)\n",
    "ax.text(6, 5.2, 'LLM', ha='center', va='center', fontsize=16,\n",
    "        fontweight='bold', color='white')\n",
    "ax.text(6, 4.6, '(Reasoning\\nEngine)', ha='center', va='center', fontsize=9, color='white')\n",
    "\n",
    "# Surrounding components\n",
    "components = [\n",
    "    (2, 8, '1. Observe', '#2ecc71', 'Read user request\\n+ tool outputs'),\n",
    "    (10, 8, '2. Reason', '#9b59b6', 'Chain-of-thought\\nplanning'),\n",
    "    (10, 2, '3. Act', '#e74c3c', 'Call tools or\\ngenerate response'),\n",
    "    (2, 2, '4. Update', '#f39c12', 'Add result to\\ncontext'),\n",
    "]\n",
    "\n",
    "for x, y, label, color, desc in components:\n",
    "    box = mpatches.FancyBboxPatch((x - 1.2, y - 0.5), 2.4, 1, boxstyle=\"round,pad=0.2\",\n",
    "                                   facecolor=color, edgecolor='black', linewidth=2, alpha=0.9)\n",
    "    ax.add_patch(box)\n",
    "    ax.text(x, y, label, ha='center', va='center', fontsize=10,\n",
    "            fontweight='bold', color='white')\n",
    "    ax.text(x, y - 0.9, desc, ha='center', va='center', fontsize=8, color='gray')\n",
    "\n",
    "# Arrows forming a cycle\n",
    "arrow_pairs = [(3.2, 8, 8.8, 8), (10, 7.5, 10, 2.5),\n",
    "               (8.8, 2, 3.2, 2), (2, 2.5, 2, 7.5)]\n",
    "for x1, y1, x2, y2 in arrow_pairs:\n",
    "    ax.annotate('', xy=(x2, y2), xytext=(x1, y1),\n",
    "               arrowprops=dict(arrowstyle='->', lw=2.5, color='gray'))\n",
    "\n",
    "# Tools\n",
    "tools = ['Search', 'Calculator', 'Code Exec', 'API Call']\n",
    "for i, tool in enumerate(tools):\n",
    "    x = 5 + i * 1.8\n",
    "    ax.text(x, 0.5, f'ðŸ”§ {tool}', ha='center', fontsize=9,\n",
    "            bbox=dict(boxstyle='round', facecolor='#ecf0f1', edgecolor='gray'))\n",
    "\n",
    "ax.text(7.8, 1.2, 'Available Tools', ha='center', fontsize=10,\n",
    "        fontweight='bold', color='gray')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## 2. Tool Definitions\n\nTools are the agent's interface to the world. Each tool has:\n- A **name** and **description** (so the LLM knows when to use it)\n- **Parameters** with types and descriptions\n- An **execute** function that runs the tool\n\nThis is the same format used by OpenAI function calling, Anthropic tool use, and most agent frameworks.\n\n**F1 analogy:** The race engineer's tools are the pit wall systems: the **weather API** (current conditions + radar forecast), the **tire degradation model** (predicted remaining life given current temps and load), the **fuel calculator** (remaining fuel vs. laps to go), the **gap calculator** (will we come out ahead or behind after a pit stop?), and the **radio** (communicate the decision to the driver). Each tool has a clear purpose, defined inputs, and a specific output â€” the agent's job is knowing *which* tool to call and *when*."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tool:\n",
    "    \"\"\"Base class for agent tools.\"\"\"\n",
    "    \n",
    "    def __init__(self, name, description, parameters):\n",
    "        self.name = name\n",
    "        self.description = description\n",
    "        self.parameters = parameters  # Dict of {param_name: {type, description}}\n",
    "    \n",
    "    def execute(self, **kwargs):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def schema(self):\n",
    "        \"\"\"Return tool schema (like OpenAI function calling format).\"\"\"\n",
    "        return {\n",
    "            'name': self.name,\n",
    "            'description': self.description,\n",
    "            'parameters': self.parameters\n",
    "        }\n",
    "\n",
    "\n",
    "class CalculatorTool(Tool):\n",
    "    \"\"\"Evaluate mathematical expressions safely.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            name='calculator',\n",
    "            description='Evaluate a mathematical expression. Supports +, -, *, /, **, sqrt, sin, cos, log.',\n",
    "            parameters={'expression': {'type': 'string', 'description': 'Math expression to evaluate'}}\n",
    "        )\n",
    "    \n",
    "    def execute(self, expression):\n",
    "        \"\"\"Safely evaluate a math expression.\"\"\"\n",
    "        # Whitelist of safe operations\n",
    "        allowed = {'sqrt': math.sqrt, 'sin': math.sin, 'cos': math.cos,\n",
    "                   'log': math.log, 'pi': math.pi, 'e': math.e,\n",
    "                   'abs': abs, 'round': round, 'pow': pow}\n",
    "        try:\n",
    "            result = eval(expression, {\"__builtins__\": {}}, allowed)\n",
    "            return {'status': 'success', 'result': result}\n",
    "        except Exception as e:\n",
    "            return {'status': 'error', 'error': str(e)}\n",
    "\n",
    "\n",
    "class SearchTool(Tool):\n",
    "    \"\"\"Simulated web search tool.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            name='search',\n",
    "            description='Search for information on a topic. Returns relevant snippets.',\n",
    "            parameters={'query': {'type': 'string', 'description': 'Search query'}}\n",
    "        )\n",
    "        # Simulated search index\n",
    "        self.knowledge = {\n",
    "            'transformer': 'The Transformer was introduced in 2017 by Vaswani et al. in \"Attention Is All You Need\". It uses self-attention instead of recurrence.',\n",
    "            'attention': 'Self-attention computes Query, Key, Value matrices. Attention(Q,K,V) = softmax(QK^T/sqrt(d_k))V.',\n",
    "            'rlhf': 'RLHF uses three stages: SFT on demonstrations, reward model training on preferences, and PPO optimization.',\n",
    "            'backpropagation': 'Backpropagation computes gradients using the chain rule, propagating error backwards through the network.',\n",
    "            'gpt': 'GPT models are decoder-only transformers trained with autoregressive language modeling. GPT-4 was released in March 2023.',\n",
    "            'embedding': 'Embeddings map discrete tokens to dense vectors. Modern sentence embeddings capture semantic meaning.',\n",
    "            'python': 'Python is a high-level programming language known for its readability. It is widely used in AI/ML.',\n",
    "            'pytorch': 'PyTorch is an open-source deep learning framework developed by Meta. It uses dynamic computation graphs.',\n",
    "        }\n",
    "    \n",
    "    def execute(self, query):\n",
    "        \"\"\"Simulate searching for information.\"\"\"\n",
    "        query_lower = query.lower()\n",
    "        results = []\n",
    "        for key, value in self.knowledge.items():\n",
    "            if key in query_lower or any(word in query_lower for word in key.split()):\n",
    "                results.append({'title': key.title(), 'snippet': value})\n",
    "        \n",
    "        if not results:\n",
    "            return {'status': 'success', 'results': [], 'message': 'No results found.'}\n",
    "        return {'status': 'success', 'results': results[:3]}\n",
    "\n",
    "\n",
    "class LookupTool(Tool):\n",
    "    \"\"\"Look up a specific fact from a knowledge base.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            name='lookup',\n",
    "            description='Look up a specific fact or definition.',\n",
    "            parameters={'term': {'type': 'string', 'description': 'Term to look up'}}\n",
    "        )\n",
    "        self.facts = {\n",
    "            'relu': 'ReLU(x) = max(0, x). Most common activation function in deep learning.',\n",
    "            'softmax': 'softmax(x_i) = exp(x_i) / sum(exp(x_j)). Converts logits to probabilities.',\n",
    "            'adam': 'Adam optimizer combines momentum and RMSprop. Default lr=0.001, betas=(0.9, 0.999).',\n",
    "            'cross entropy': 'Cross-entropy loss: L = -sum(y_i * log(p_i)). Standard for classification.',\n",
    "            'batch normalization': 'Normalizes layer inputs to zero mean, unit variance. Speeds up training.',\n",
    "            'dropout': 'Randomly zeros elements with probability p during training. Regularization technique.',\n",
    "        }\n",
    "    \n",
    "    def execute(self, term):\n",
    "        term_lower = term.lower().strip()\n",
    "        if term_lower in self.facts:\n",
    "            return {'status': 'success', 'definition': self.facts[term_lower]}\n",
    "        # Fuzzy match\n",
    "        for key, value in self.facts.items():\n",
    "            if term_lower in key or key in term_lower:\n",
    "                return {'status': 'success', 'definition': value}\n",
    "        return {'status': 'not_found', 'message': f'No definition found for \"{term}\"'}\n",
    "\n",
    "\n",
    "# Create our tool registry\n",
    "tools = {\n",
    "    'calculator': CalculatorTool(),\n",
    "    'search': SearchTool(),\n",
    "    'lookup': LookupTool(),\n",
    "}\n",
    "\n",
    "print(\"Available tools:\")\n",
    "for name, tool in tools.items():\n",
    "    print(f\"  {name}: {tool.description}\")\n",
    "\n",
    "# Test tools\n",
    "print(\"\\nTool tests:\")\n",
    "print(f\"  calculator('2**10'): {tools['calculator'].execute(expression='2**10')}\")\n",
    "print(f\"  search('transformer'): {tools['search'].execute(query='transformer architecture')}\")\n",
    "print(f\"  lookup('relu'): {tools['lookup'].execute(term='relu')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## 3. The ReAct Pattern\n\n**ReAct** (Reasoning + Acting) interleaves chain-of-thought reasoning with tool use:\n\n```\nThought: I need to find out when the Transformer was introduced.\nAction: search(\"transformer architecture origin\")\nObservation: The Transformer was introduced in 2017...\nThought: Now I know it was 2017. Let me calculate how many years ago that was.\nAction: calculator(\"2026 - 2017\")\nObservation: 9\nThought: I have all the information I need.\nAnswer: The Transformer was introduced 9 years ago, in 2017.\n```\n\nThe key insight: by verbalizing its reasoning, the agent makes better decisions about *which* tool to use and *when*.\n\n**F1 analogy:** ReAct is exactly how a race engineer thinks during a race:\n\n```\nThought: Tires are degrading â€” lap times dropped 0.8s in the last 3 laps.\nAction: query_tire_model(compound=\"medium\", laps_done=22, tire_temp=108)\nObservation: Estimated remaining life: 5-7 laps before cliff.\nThought: We need to pit soon. But will we come out in traffic? Let me check the gap.\nAction: calculate_pit_window(current_pos=4, gap_behind=3.2s, pit_loss=22s)\nObservation: We'll rejoin in P6 behind Alonso, 1.8s gap.\nThought: That's tight but acceptable. Box this lap.\nAction: radio_driver(\"Box box box, pit this lap for hards.\")\n```\n\nThe reasoning step before each action is what makes the agent effective â€” without it, the engineer might pit at the wrong time or call the wrong compound."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReActAgent:\n",
    "    \"\"\"ReAct agent: Reasoning + Acting with tool use.\n",
    "    \n",
    "    Uses a simulated LLM (rule-based) to demonstrate the pattern.\n",
    "    In production, this would be an actual LLM like Claude or GPT-4.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, tools, max_steps=5):\n",
    "        self.tools = tools\n",
    "        self.max_steps = max_steps\n",
    "        self.trace = []  # Full execution trace\n",
    "    \n",
    "    def _simulate_reasoning(self, query, observations):\n",
    "        \"\"\"Simulate LLM reasoning to decide next action.\n",
    "        \n",
    "        In production, this is where you'd call the LLM API.\n",
    "        Here we use heuristics to demonstrate the pattern.\n",
    "        \"\"\"\n",
    "        query_lower = query.lower()\n",
    "        \n",
    "        # If we already have observations, try to answer\n",
    "        if len(observations) >= 2:\n",
    "            return {'type': 'answer', 'content': self._synthesize(query, observations)}\n",
    "        \n",
    "        # Decide which tool to use based on query\n",
    "        if any(word in query_lower for word in ['calculate', 'compute', 'how many', 'what is', 'evaluate'])\\\n",
    "           and any(c in query for c in '0123456789+-*/^'):\n",
    "            # Extract math expression\n",
    "            expr = re.findall(r'[\\d\\+\\-\\*/\\(\\)\\. \\*\\*]+', query)\n",
    "            if expr:\n",
    "                expression = expr[0].strip()\n",
    "                return {\n",
    "                    'type': 'action',\n",
    "                    'thought': f'I need to calculate {expression}.',\n",
    "                    'tool': 'calculator',\n",
    "                    'args': {'expression': expression}\n",
    "                }\n",
    "        \n",
    "        if any(word in query_lower for word in ['what is', 'define', 'explain']):\n",
    "            # Try lookup first\n",
    "            terms = re.findall(r'what is (\\w+(?:\\s+\\w+)?)', query_lower)\n",
    "            if terms and not observations:\n",
    "                return {\n",
    "                    'type': 'action',\n",
    "                    'thought': f'Let me look up the definition of \"{terms[0]}\".',\n",
    "                    'tool': 'lookup',\n",
    "                    'args': {'term': terms[0]}\n",
    "                }\n",
    "        \n",
    "        # Default: search\n",
    "        if not observations:\n",
    "            return {\n",
    "                'type': 'action',\n",
    "                'thought': f'I need to search for information about this topic.',\n",
    "                'tool': 'search',\n",
    "                'args': {'query': query}\n",
    "            }\n",
    "        \n",
    "        return {'type': 'answer', 'content': self._synthesize(query, observations)}\n",
    "    \n",
    "    def _synthesize(self, query, observations):\n",
    "        \"\"\"Synthesize a final answer from observations.\"\"\"\n",
    "        parts = []\n",
    "        for obs in observations:\n",
    "            if isinstance(obs.get('result'), dict):\n",
    "                if 'results' in obs['result']:\n",
    "                    for r in obs['result']['results']:\n",
    "                        parts.append(r.get('snippet', ''))\n",
    "                elif 'definition' in obs['result']:\n",
    "                    parts.append(obs['result']['definition'])\n",
    "                elif 'result' in obs['result']:\n",
    "                    parts.append(f\"Calculation result: {obs['result']['result']}\")\n",
    "        \n",
    "        return ' '.join(parts) if parts else 'I could not find enough information to answer.'\n",
    "    \n",
    "    def run(self, query):\n",
    "        \"\"\"Execute the ReAct loop.\"\"\"\n",
    "        self.trace = []\n",
    "        observations = []\n",
    "        \n",
    "        self.trace.append({'step': 'query', 'content': query})\n",
    "        \n",
    "        for step in range(self.max_steps):\n",
    "            # Reason about what to do\n",
    "            decision = self._simulate_reasoning(query, observations)\n",
    "            \n",
    "            if decision['type'] == 'answer':\n",
    "                self.trace.append({\n",
    "                    'step': 'answer',\n",
    "                    'thought': 'I have enough information to answer.',\n",
    "                    'content': decision['content']\n",
    "                })\n",
    "                return decision['content']\n",
    "            \n",
    "            # Execute tool\n",
    "            tool_name = decision['tool']\n",
    "            tool_args = decision['args']\n",
    "            \n",
    "            self.trace.append({\n",
    "                'step': 'thought',\n",
    "                'content': decision.get('thought', '')\n",
    "            })\n",
    "            self.trace.append({\n",
    "                'step': 'action',\n",
    "                'tool': tool_name,\n",
    "                'args': tool_args\n",
    "            })\n",
    "            \n",
    "            result = self.tools[tool_name].execute(**tool_args)\n",
    "            \n",
    "            self.trace.append({\n",
    "                'step': 'observation',\n",
    "                'result': result\n",
    "            })\n",
    "            \n",
    "            observations.append({'tool': tool_name, 'args': tool_args, 'result': result})\n",
    "        \n",
    "        return self._synthesize(query, observations)\n",
    "    \n",
    "    def show_trace(self):\n",
    "        \"\"\"Display the execution trace.\"\"\"\n",
    "        colors = {'query': '\\033[94m', 'thought': '\\033[93m',\n",
    "                  'action': '\\033[91m', 'observation': '\\033[92m',\n",
    "                  'answer': '\\033[95m'}\n",
    "        reset = '\\033[0m'\n",
    "        \n",
    "        for entry in self.trace:\n",
    "            step = entry['step']\n",
    "            if step == 'query':\n",
    "                print(f\"Query: {entry['content']}\")\n",
    "            elif step == 'thought':\n",
    "                print(f\"  Thought: {entry['content']}\")\n",
    "            elif step == 'action':\n",
    "                args_str = ', '.join(f'{k}=\"{v}\"' for k, v in entry['args'].items())\n",
    "                print(f\"  Action: {entry['tool']}({args_str})\")\n",
    "            elif step == 'observation':\n",
    "                result = entry['result']\n",
    "                result_str = json.dumps(result, indent=None)[:120]\n",
    "                print(f\"  Observation: {result_str}\")\n",
    "            elif step == 'answer':\n",
    "                print(f\"  Thought: {entry.get('thought', '')}\")\n",
    "                print(f\"  Answer: {entry['content'][:200]}\")\n",
    "\n",
    "\n",
    "# Test the ReAct agent\n",
    "agent = ReActAgent(tools)\n",
    "\n",
    "queries = [\n",
    "    \"Tell me about the transformer architecture\",\n",
    "    \"What is relu?\",\n",
    "    \"Tell me about RLHF and how it works\",\n",
    "]\n",
    "\n",
    "for query in queries:\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    answer = agent.run(query)\n",
    "    agent.show_trace()\n",
    "    print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization: ReAct Execution Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a ReAct trace\n",
    "fig, ax = plt.subplots(1, 1, figsize=(14, 6))\n",
    "ax.set_xlim(0, 14)\n",
    "ax.set_ylim(0, 7)\n",
    "ax.axis('off')\n",
    "ax.set_title('ReAct Execution Trace', fontsize=14, fontweight='bold')\n",
    "\n",
    "steps = [\n",
    "    (1, 5.5, 'Query', '#95a5a6', '\"Tell me about\\ntransformers\"'),\n",
    "    (3.5, 5.5, 'Thought', '#f39c12', '\"I need to search\\nfor this topic\"'),\n",
    "    (6, 5.5, 'Action', '#e74c3c', 'search(\"transformer\\narchitecture\")'),\n",
    "    (8.5, 5.5, 'Observation', '#2ecc71', '\"Introduced in 2017\\nby Vaswani et al...\"'),\n",
    "    (11, 5.5, 'Thought', '#f39c12', '\"I have enough\\ninfo to answer\"'),\n",
    "]\n",
    "\n",
    "steps2 = [\n",
    "    (3.5, 2.5, 'Answer', '#9b59b6', '\"The Transformer was\\nintroduced in 2017...\"'),\n",
    "]\n",
    "\n",
    "for x, y, label, color, text in steps + steps2:\n",
    "    box = mpatches.FancyBboxPatch((x - 1, y - 0.6), 2, 1.2, boxstyle=\"round,pad=0.15\",\n",
    "                                   facecolor=color, edgecolor='black', linewidth=1.5, alpha=0.9)\n",
    "    ax.add_patch(box)\n",
    "    ax.text(x, y + 0.2, label, ha='center', va='center', fontsize=9,\n",
    "            fontweight='bold', color='white')\n",
    "    ax.text(x, y - 0.25, text, ha='center', va='center', fontsize=7, color='white')\n",
    "\n",
    "# Arrows\n",
    "for i in range(len(steps) - 1):\n",
    "    ax.annotate('', xy=(steps[i+1][0] - 1, steps[i+1][1]),\n",
    "               xytext=(steps[i][0] + 1, steps[i][1]),\n",
    "               arrowprops=dict(arrowstyle='->', lw=2, color='gray'))\n",
    "\n",
    "# Arrow to answer\n",
    "ax.annotate('', xy=(steps2[0][0], steps2[0][1] + 0.6),\n",
    "           xytext=(steps[-1][0], steps[-1][1] - 0.6),\n",
    "           arrowprops=dict(arrowstyle='->', lw=2, color='gray',\n",
    "                          connectionstyle='arc3,rad=0.3'))\n",
    "\n",
    "# Labels\n",
    "ax.text(7, 4.2, 'Reasoning + Acting Loop', ha='center', fontsize=11,\n",
    "        style='italic', color='gray')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## 4. Chain-of-Thought Reasoning\n\n**Chain-of-thought (CoT)** prompting dramatically improves reasoning by making the model \"think step by step.\" For agents, CoT serves as the planning mechanism:\n\n- **Without CoT**: LLM jumps to an action immediately (often wrong)\n- **With CoT**: LLM reasons about what it knows, what it needs, then acts\n\n### Why CoT Works for Agents\n\n1. **Decomposition**: Breaks complex tasks into manageable steps\n2. **Self-correction**: The model can catch its own errors mid-reasoning\n3. **Tool selection**: Explicit reasoning helps choose the right tool\n4. **Transparency**: Users can understand *why* the agent took an action\n\n**F1 analogy:** This is the difference between a junior and senior race engineer. The junior sees rain on the radar and immediately calls for wets. The senior *reasons step by step*: \"Rain probability is 70% in 10 minutes, but we're only 5 laps from the end. Intermediates would be faster if it's light rain, but if it's heavy we need full wets. The car ahead is on old softs so they'll suffer more â€” we might gain positions by staying out one more lap. Let me check the weather radar resolution and the gap to P3 before deciding.\" The chain of thought before acting is what separates good strategy from reactive scrambling."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate CoT benefit with a multi-step problem\n",
    "\n",
    "class PlanningAgent:\n",
    "    \"\"\"Agent that creates an explicit plan before acting.\"\"\"\n",
    "    \n",
    "    def __init__(self, tools):\n",
    "        self.tools = tools\n",
    "    \n",
    "    def plan(self, query):\n",
    "        \"\"\"Create a step-by-step plan (simulated).\"\"\"\n",
    "        query_lower = query.lower()\n",
    "        plan_steps = []\n",
    "        \n",
    "        # Analyze what's needed\n",
    "        needs_search = any(w in query_lower for w in ['tell me', 'how', 'what', 'explain', 'when'])\n",
    "        needs_calc = any(c in query for c in '0123456789+-*/') or 'calculate' in query_lower\n",
    "        needs_lookup = any(w in query_lower for w in ['define', 'definition'])\n",
    "        \n",
    "        if needs_search:\n",
    "            # Extract key topics\n",
    "            topics = [w for w in query_lower.split() if len(w) > 3 and w not in \n",
    "                     {'tell', 'about', 'what', 'how', 'does', 'this', 'that', 'with', 'from'}]\n",
    "            plan_steps.append({\n",
    "                'step': 1,\n",
    "                'description': f'Search for information about: {\", \".join(topics[:3])}',\n",
    "                'tool': 'search',\n",
    "                'args': {'query': ' '.join(topics[:3])}\n",
    "            })\n",
    "        \n",
    "        if needs_lookup:\n",
    "            terms = re.findall(r'define\\s+(\\w+)', query_lower)\n",
    "            if terms:\n",
    "                plan_steps.append({\n",
    "                    'step': len(plan_steps) + 1,\n",
    "                    'description': f'Look up definition of: {terms[0]}',\n",
    "                    'tool': 'lookup',\n",
    "                    'args': {'term': terms[0]}\n",
    "                })\n",
    "        \n",
    "        if needs_calc:\n",
    "            expr = re.findall(r'[\\d\\+\\-\\*/\\(\\)\\. \\*\\*]+', query)\n",
    "            if expr:\n",
    "                plan_steps.append({\n",
    "                    'step': len(plan_steps) + 1,\n",
    "                    'description': f'Calculate: {expr[0].strip()}',\n",
    "                    'tool': 'calculator',\n",
    "                    'args': {'expression': expr[0].strip()}\n",
    "                })\n",
    "        \n",
    "        plan_steps.append({\n",
    "            'step': len(plan_steps) + 1,\n",
    "            'description': 'Synthesize findings into a coherent answer',\n",
    "            'tool': None,\n",
    "            'args': {}\n",
    "        })\n",
    "        \n",
    "        return plan_steps\n",
    "    \n",
    "    def execute_plan(self, query):\n",
    "        \"\"\"Plan then execute.\"\"\"\n",
    "        plan = self.plan(query)\n",
    "        results = []\n",
    "        \n",
    "        print(f\"Query: {query}\")\n",
    "        print(f\"\\nPlan ({len(plan)} steps):\")\n",
    "        for step in plan:\n",
    "            print(f\"  Step {step['step']}: {step['description']}\")\n",
    "        \n",
    "        print(f\"\\nExecution:\")\n",
    "        for step in plan:\n",
    "            if step['tool'] and step['tool'] in self.tools:\n",
    "                result = self.tools[step['tool']].execute(**step['args'])\n",
    "                results.append(result)\n",
    "                print(f\"  Step {step['step']}: {step['tool']}() -> {json.dumps(result)[:100]}\")\n",
    "            else:\n",
    "                print(f\"  Step {step['step']}: Synthesizing answer...\")\n",
    "        \n",
    "        return results\n",
    "\n",
    "\n",
    "planning_agent = PlanningAgent(tools)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "planning_agent.execute_plan(\"Tell me about attention in transformers\")\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "planning_agent.execute_plan(\"What is backpropagation and how does it relate to gradient descent?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## 5. Agent Architectures Compared\n\nDifferent agent architectures suit different tasks:\n\n| Architecture | Description | Best For | F1 Parallel |\n|-------------|-------------|----------|-------------|\n| **ReAct** | Interleave reasoning and acting | General tool use | Race engineer thinking then acting each lap â€” check tires, decide, radio driver |\n| **Plan-then-Execute** | Full plan upfront, then execute | Well-defined tasks | Pre-race strategy briefing: \"We'll start on mediums, pit lap 20 for hards, pit lap 42 for softs\" |\n| **Reflexion** | Act, evaluate, reflect, retry | Tasks needing self-correction | Post-stint analysis: \"That undercut didn't work â€” next time pit 2 laps earlier\" |\n| **Tree of Thoughts** | Explore multiple reasoning paths | Complex problem solving | Simulating 5 different strategy options in parallel before committing |\n| **Multi-Agent** | Multiple specialized agents collaborate | Complex workflows | Separate tire engineer, aero engineer, and strategist all feeding into the race engineer's decision |"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize agent architecture comparison\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# ReAct: Linear interleave\n",
    "ax = axes[0]\n",
    "ax.set_xlim(0, 4)\n",
    "ax.set_ylim(0, 8)\n",
    "ax.axis('off')\n",
    "ax.set_title('ReAct', fontsize=13, fontweight='bold')\n",
    "\n",
    "react_steps = [\n",
    "    (2, 7, 'Think', '#f39c12'),\n",
    "    (2, 5.5, 'Act', '#e74c3c'),\n",
    "    (2, 4, 'Observe', '#2ecc71'),\n",
    "    (2, 2.5, 'Think', '#f39c12'),\n",
    "    (2, 1, 'Answer', '#9b59b6'),\n",
    "]\n",
    "for x, y, label, color in react_steps:\n",
    "    box = mpatches.FancyBboxPatch((x - 0.8, y - 0.35), 1.6, 0.7,\n",
    "                                   boxstyle=\"round,pad=0.1\", facecolor=color,\n",
    "                                   edgecolor='black', linewidth=1.5)\n",
    "    ax.add_patch(box)\n",
    "    ax.text(x, y, label, ha='center', va='center', fontsize=10, fontweight='bold', color='white')\n",
    "\n",
    "for i in range(len(react_steps) - 1):\n",
    "    ax.annotate('', xy=(2, react_steps[i+1][1] + 0.35),\n",
    "               xytext=(2, react_steps[i][1] - 0.35),\n",
    "               arrowprops=dict(arrowstyle='->', lw=1.5, color='gray'))\n",
    "\n",
    "# Plan-then-Execute\n",
    "ax = axes[1]\n",
    "ax.set_xlim(0, 4)\n",
    "ax.set_ylim(0, 8)\n",
    "ax.axis('off')\n",
    "ax.set_title('Plan-then-Execute', fontsize=13, fontweight='bold')\n",
    "\n",
    "box = mpatches.FancyBboxPatch((0.5, 6), 3, 1.2, boxstyle=\"round,pad=0.1\",\n",
    "                               facecolor='#f39c12', edgecolor='black', linewidth=1.5)\n",
    "ax.add_patch(box)\n",
    "ax.text(2, 6.6, 'Plan', ha='center', va='center', fontsize=11, fontweight='bold', color='white')\n",
    "\n",
    "for i, y in enumerate([4.5, 3.2, 1.9]):\n",
    "    box = mpatches.FancyBboxPatch((0.5, y), 3, 0.7, boxstyle=\"round,pad=0.1\",\n",
    "                                   facecolor='#e74c3c', edgecolor='black', linewidth=1.5)\n",
    "    ax.add_patch(box)\n",
    "    ax.text(2, y + 0.35, f'Execute Step {i+1}', ha='center', va='center',\n",
    "            fontsize=9, fontweight='bold', color='white')\n",
    "\n",
    "ax.annotate('', xy=(2, 5.2), xytext=(2, 6),\n",
    "           arrowprops=dict(arrowstyle='->', lw=1.5, color='gray'))\n",
    "for y1, y2 in [(4.5, 3.2), (3.2, 1.9)]:\n",
    "    ax.annotate('', xy=(2, y2 + 0.7), xytext=(2, y1),\n",
    "               arrowprops=dict(arrowstyle='->', lw=1.5, color='gray'))\n",
    "\n",
    "box = mpatches.FancyBboxPatch((0.5, 0.5), 3, 0.7, boxstyle=\"round,pad=0.1\",\n",
    "                               facecolor='#9b59b6', edgecolor='black', linewidth=1.5)\n",
    "ax.add_patch(box)\n",
    "ax.text(2, 0.85, 'Answer', ha='center', va='center', fontsize=10, fontweight='bold', color='white')\n",
    "ax.annotate('', xy=(2, 1.2), xytext=(2, 1.9),\n",
    "           arrowprops=dict(arrowstyle='->', lw=1.5, color='gray'))\n",
    "\n",
    "# Reflexion\n",
    "ax = axes[2]\n",
    "ax.set_xlim(0, 4)\n",
    "ax.set_ylim(0, 8)\n",
    "ax.axis('off')\n",
    "ax.set_title('Reflexion', fontsize=13, fontweight='bold')\n",
    "\n",
    "refl_steps = [\n",
    "    (2, 7, 'Act', '#e74c3c'),\n",
    "    (2, 5.5, 'Evaluate', '#3498db'),\n",
    "    (2, 4, 'Reflect', '#f39c12'),\n",
    "    (2, 2.5, 'Retry', '#e74c3c'),\n",
    "    (2, 1, 'Answer', '#9b59b6'),\n",
    "]\n",
    "\n",
    "for x, y, label, color in refl_steps:\n",
    "    box = mpatches.FancyBboxPatch((x - 0.8, y - 0.35), 1.6, 0.7,\n",
    "                                   boxstyle=\"round,pad=0.1\", facecolor=color,\n",
    "                                   edgecolor='black', linewidth=1.5)\n",
    "    ax.add_patch(box)\n",
    "    ax.text(x, y, label, ha='center', va='center', fontsize=10, fontweight='bold', color='white')\n",
    "\n",
    "for i in range(len(refl_steps) - 1):\n",
    "    ax.annotate('', xy=(2, refl_steps[i+1][1] + 0.35),\n",
    "               xytext=(2, refl_steps[i][1] - 0.35),\n",
    "               arrowprops=dict(arrowstyle='->', lw=1.5, color='gray'))\n",
    "\n",
    "# Loop arrow for reflexion\n",
    "ax.annotate('', xy=(3.3, 7), xytext=(3.3, 4),\n",
    "           arrowprops=dict(arrowstyle='->', lw=1.5, color='#f39c12',\n",
    "                          connectionstyle='arc3,rad=-0.5'))\n",
    "ax.text(3.8, 5.5, 'retry', fontsize=8, color='#f39c12', rotation=90, va='center')\n",
    "\n",
    "plt.suptitle('Agent Architecture Patterns', fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## 6. Agent Safety and Failure Modes\n\nAgents are powerful but dangerous â€” they can take **irreversible actions**. Understanding failure modes is critical.\n\n| Failure Mode | Example | Mitigation | F1 Parallel |\n|-------------|---------|------------|-------------|\n| **Infinite loops** | Agent keeps searching without converging | Max step limit | Engineer keeps re-running the tire model without ever making a decision â€” the race passes you by |\n| **Wrong tool** | Uses calculator when should search | Better tool descriptions | Checking the weather API when you should be checking the gap calculator â€” tools matter |\n| **Hallucinated actions** | Calls a tool that doesn't exist | Strict tool validation | Trying to call a \"track evolution model\" that doesn't exist in your system |\n| **Unsafe actions** | Deletes files, sends emails | Permission system, sandboxing | Agent broadcasting on the team radio frequency without authorization |\n| **Goal drift** | Wanders from original task | Task decomposition, checkpoints | Started optimizing for fastest lap when the goal was to finish P4 â€” lost sight of the objective |\n| **Cascading errors** | Error in step 1 propagates | Error handling, retries | Bad tire temp reading feeds into the degradation model, which produces a wrong pit window, which causes a bad strategy call |"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SafeAgent:\n",
    "    \"\"\"Agent with safety guardrails.\"\"\"\n",
    "    \n",
    "    def __init__(self, tools, max_steps=5, max_tool_calls=10):\n",
    "        self.tools = tools\n",
    "        self.max_steps = max_steps\n",
    "        self.max_tool_calls = max_tool_calls\n",
    "        self.tool_call_count = 0\n",
    "        self.errors = []\n",
    "    \n",
    "    def validate_tool_call(self, tool_name, args):\n",
    "        \"\"\"Validate a tool call before execution.\"\"\"\n",
    "        # Check tool exists\n",
    "        if tool_name not in self.tools:\n",
    "            return False, f\"Unknown tool: {tool_name}\"\n",
    "        \n",
    "        # Check rate limit\n",
    "        if self.tool_call_count >= self.max_tool_calls:\n",
    "            return False, \"Tool call limit exceeded\"\n",
    "        \n",
    "        # Check required parameters\n",
    "        tool = self.tools[tool_name]\n",
    "        for param in tool.parameters:\n",
    "            if param not in args:\n",
    "                return False, f\"Missing required parameter: {param}\"\n",
    "        \n",
    "        return True, \"OK\"\n",
    "    \n",
    "    def safe_execute(self, tool_name, **args):\n",
    "        \"\"\"Execute a tool with error handling.\"\"\"\n",
    "        valid, message = self.validate_tool_call(tool_name, args)\n",
    "        if not valid:\n",
    "            self.errors.append(message)\n",
    "            return {'status': 'blocked', 'reason': message}\n",
    "        \n",
    "        try:\n",
    "            self.tool_call_count += 1\n",
    "            result = self.tools[tool_name].execute(**args)\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            self.errors.append(str(e))\n",
    "            return {'status': 'error', 'error': str(e)}\n",
    "\n",
    "\n",
    "# Demonstrate safety features\n",
    "safe = SafeAgent(tools, max_tool_calls=3)\n",
    "\n",
    "print(\"Safety demonstrations:\")\n",
    "print(\"\\n1. Valid tool call:\")\n",
    "print(f\"   {safe.safe_execute('calculator', expression='2+2')}\")\n",
    "\n",
    "print(\"\\n2. Invalid tool name:\")\n",
    "print(f\"   {safe.safe_execute('delete_database', target='all')}\")\n",
    "\n",
    "print(\"\\n3. Missing parameters:\")\n",
    "print(f\"   {safe.safe_execute('calculator')}\")\n",
    "\n",
    "# Exhaust rate limit\n",
    "safe.safe_execute('calculator', expression='1+1')\n",
    "safe.safe_execute('calculator', expression='1+1')\n",
    "print(\"\\n4. Rate limit exceeded:\")\n",
    "print(f\"   {safe.safe_execute('calculator', expression='1+1')}\")\n",
    "\n",
    "print(f\"\\nErrors logged: {safe.errors}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## 7. Agent Evaluation Metrics\n\nHow do we measure if an agent is good? Key metrics:\n\n| Metric | What It Measures | How | F1 Parallel |\n|--------|-----------------|-----|-------------|\n| **Task completion** | Did the agent finish the task? | Binary success/fail | Did the strategy successfully complete the race? |\n| **Accuracy** | Was the answer correct? | Compare to ground truth | Was the pit stop call optimal based on post-race analysis? |\n| **Efficiency** | How many steps/tool calls? | Count steps | Did we make the call in 3 queries or 15? Fewer is better at race speed |\n| **Tool selection** | Did it use the right tools? | Compare to optimal trace | Did the engineer check the right data sources before deciding? |\n| **Error recovery** | Did it handle failures gracefully? | Inject errors, check recovery | When the weather API went down, did the engineer have a fallback plan? |"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentEvaluator:\n",
    "    \"\"\"Evaluate agent performance on a benchmark.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.results = []\n",
    "    \n",
    "    def evaluate(self, agent, test_cases):\n",
    "        \"\"\"Run agent on test cases and measure performance.\"\"\"\n",
    "        self.results = []\n",
    "        \n",
    "        for test in test_cases:\n",
    "            agent.trace = []\n",
    "            answer = agent.run(test['query'])\n",
    "            \n",
    "            # Measure metrics\n",
    "            trace = agent.trace\n",
    "            n_steps = len([t for t in trace if t['step'] == 'action'])\n",
    "            tools_used = [t['tool'] for t in trace if t['step'] == 'action']\n",
    "            \n",
    "            # Check if expected tool was used\n",
    "            correct_tool = test.get('expected_tool') in tools_used if test.get('expected_tool') else True\n",
    "            \n",
    "            # Check if answer contains expected content\n",
    "            answer_correct = any(\n",
    "                keyword.lower() in answer.lower()\n",
    "                for keyword in test.get('expected_keywords', [])\n",
    "            )\n",
    "            \n",
    "            self.results.append({\n",
    "                'query': test['query'],\n",
    "                'n_steps': n_steps,\n",
    "                'tools_used': tools_used,\n",
    "                'correct_tool': correct_tool,\n",
    "                'answer_correct': answer_correct,\n",
    "                'completed': len(answer) > 10,\n",
    "            })\n",
    "        \n",
    "        return self._compute_metrics()\n",
    "    \n",
    "    def _compute_metrics(self):\n",
    "        n = len(self.results)\n",
    "        return {\n",
    "            'completion_rate': sum(r['completed'] for r in self.results) / n,\n",
    "            'accuracy': sum(r['answer_correct'] for r in self.results) / n,\n",
    "            'tool_accuracy': sum(r['correct_tool'] for r in self.results) / n,\n",
    "            'avg_steps': np.mean([r['n_steps'] for r in self.results]),\n",
    "        }\n",
    "\n",
    "\n",
    "# Evaluation benchmark\n",
    "test_cases = [\n",
    "    {'query': 'Tell me about transformers',\n",
    "     'expected_tool': 'search', 'expected_keywords': ['attention', '2017']},\n",
    "    {'query': 'What is relu?',\n",
    "     'expected_tool': 'lookup', 'expected_keywords': ['max', 'activation']},\n",
    "    {'query': 'How does RLHF work?',\n",
    "     'expected_tool': 'search', 'expected_keywords': ['reward', 'PPO']},\n",
    "    {'query': 'What is backpropagation?',\n",
    "     'expected_tool': 'search', 'expected_keywords': ['gradient', 'chain']},\n",
    "    {'query': 'Tell me about embeddings and semantic similarity',\n",
    "     'expected_tool': 'search', 'expected_keywords': ['vector', 'cosine']},\n",
    "]\n",
    "\n",
    "evaluator = AgentEvaluator()\n",
    "agent = ReActAgent(tools)\n",
    "metrics = evaluator.evaluate(agent, test_cases)\n",
    "\n",
    "print(\"Agent Evaluation Results:\")\n",
    "for metric, value in metrics.items():\n",
    "    print(f\"  {metric}: {value:.2%}\" if 'rate' in metric or 'accuracy' in metric\n",
    "          else f\"  {metric}: {value:.1f}\")\n",
    "\n",
    "# Visualize\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 5))\n",
    "metric_names = list(metrics.keys())\n",
    "metric_values = list(metrics.values())\n",
    "colors = ['#2ecc71', '#3498db', '#f39c12', '#e74c3c']\n",
    "bars = ax.bar(metric_names, metric_values, color=colors, edgecolor='black', alpha=0.8)\n",
    "\n",
    "for bar, val in zip(bars, metric_values):\n",
    "    label = f'{val:.0%}' if val <= 1 else f'{val:.1f}'\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02,\n",
    "            label, ha='center', fontsize=11, fontweight='bold')\n",
    "\n",
    "ax.set_ylabel('Score', fontsize=12)\n",
    "ax.set_title('Agent Performance Metrics', fontsize=13, fontweight='bold')\n",
    "ax.set_xticklabels(metric_names, rotation=15, ha='right')\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## 8. Multi-Agent Systems\n\nComplex tasks often benefit from **multiple specialized agents** working together:\n\n- **Researcher**: Gathers information from search/documents\n- **Coder**: Writes and executes code\n- **Reviewer**: Checks work quality\n- **Orchestrator**: Coordinates the team\n\n**F1 analogy:** This is the entire pit wall operation. The **tire engineer** (specialist agent) monitors compound performance and degradation curves. The **aero engineer** tracks downforce levels and wind conditions. The **weather analyst** monitors the radar. The **strategy chief** (orchestrator) takes input from all specialists and makes the final call. Each agent has deep expertise in their domain, but the orchestrator synthesizes everything into a coherent race strategy. No single person can do it all â€” the system's power comes from specialization plus coordination."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpecializedAgent:\n",
    "    \"\"\"A specialized agent with a specific role.\"\"\"\n",
    "    \n",
    "    def __init__(self, name, role, tools):\n",
    "        self.name = name\n",
    "        self.role = role\n",
    "        self.tools = tools\n",
    "    \n",
    "    def process(self, task, context=None):\n",
    "        \"\"\"Process a task given optional context from other agents.\"\"\"\n",
    "        results = []\n",
    "        for tool_name, args in self._decide_actions(task, context):\n",
    "            if tool_name in self.tools:\n",
    "                result = self.tools[tool_name].execute(**args)\n",
    "                results.append({'tool': tool_name, 'result': result})\n",
    "        return {'agent': self.name, 'role': self.role, 'results': results}\n",
    "    \n",
    "    def _decide_actions(self, task, context):\n",
    "        \"\"\"Decide which tools to use (simplified).\"\"\"\n",
    "        actions = []\n",
    "        if self.role == 'researcher':\n",
    "            actions.append(('search', {'query': task}))\n",
    "        elif self.role == 'fact_checker':\n",
    "            # Check key terms from context\n",
    "            if context:\n",
    "                for r in context.get('results', []):\n",
    "                    if 'result' in r and 'results' in r.get('result', {}):\n",
    "                        for item in r['result']['results']:\n",
    "                            key = item.get('title', '').lower()\n",
    "                            actions.append(('lookup', {'term': key}))\n",
    "                            break\n",
    "        return actions\n",
    "\n",
    "\n",
    "class Orchestrator:\n",
    "    \"\"\"Coordinates multiple specialized agents.\"\"\"\n",
    "    \n",
    "    def __init__(self, agents):\n",
    "        self.agents = {a.name: a for a in agents}\n",
    "    \n",
    "    def run_pipeline(self, task):\n",
    "        \"\"\"Run agents in a pipeline.\"\"\"\n",
    "        print(f\"Orchestrator: Task = '{task}'\\n\")\n",
    "        \n",
    "        # Step 1: Research\n",
    "        researcher = self.agents.get('researcher')\n",
    "        if researcher:\n",
    "            research_output = researcher.process(task)\n",
    "            print(f\"  {researcher.name} ({researcher.role}):\")\n",
    "            for r in research_output['results']:\n",
    "                print(f\"    Tool: {r['tool']} -> {json.dumps(r['result'])[:100]}\")\n",
    "        \n",
    "        # Step 2: Fact check\n",
    "        checker = self.agents.get('fact_checker')\n",
    "        if checker:\n",
    "            check_output = checker.process(task, context=research_output)\n",
    "            print(f\"  {checker.name} ({checker.role}):\")\n",
    "            for r in check_output['results']:\n",
    "                print(f\"    Tool: {r['tool']} -> {json.dumps(r['result'])[:100]}\")\n",
    "        \n",
    "        print(f\"\\n  Orchestrator: Pipeline complete.\")\n",
    "        return {'research': research_output, 'fact_check': check_output if checker else None}\n",
    "\n",
    "\n",
    "# Build multi-agent system\n",
    "researcher = SpecializedAgent('researcher', 'researcher', tools)\n",
    "checker = SpecializedAgent('fact_checker', 'fact_checker', tools)\n",
    "\n",
    "orchestrator = Orchestrator([researcher, checker])\n",
    "result = orchestrator.run_pipeline(\"Explain how attention works in transformers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## Exercises\n\n### Exercise 1: Race Engineer Agent with Weather Tool\n\nCreate a `WeatherTool` (simulated) and integrate it into the ReAct agent. Think of it as the race engineer's weather radar â€” the tool should accept a city name and return simulated weather data (temperature, rain probability, wind speed). Test with queries like \"What's the weather in San Francisco?\" and \"Should I bring an umbrella in New York?\" In F1 terms, this mirrors the engineer querying the weather API mid-race to decide whether to prepare intermediate tires."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: Your code here\n",
    "# Hint: Create a WeatherTool class that extends Tool,\n",
    "# add it to the tools dict, and modify the agent's reasoning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Exercise 2: Reflexion Agent â€” Post-Stint Learning\n\nImplement a Reflexion agent that: (1) attempts to answer, (2) self-evaluates its answer, (3) reflects on what went wrong, (4) retries with improved approach. This mirrors the F1 post-stint analysis loop: the engineer makes a strategy call, evaluates the outcome (\"we lost 2 seconds in the pit window\"), reflects (\"we pitted one lap too late\"), and adjusts for the next stint. Test on a math word problem."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2: Your code here\n",
    "# Hint: After the agent generates an answer, add a \"self-check\" step\n",
    "# that verifies the answer and triggers a retry if needed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Exercise 3: Agent Benchmark Suite â€” Strategy Decision Testing\n\nCreate a benchmark of 10+ test cases with varying difficulty. Compare ReAct vs PlanningAgent on completion rate, accuracy, and efficiency. Which architecture performs better on which types of tasks? Think of this as comparing two strategy approaches: the reactive engineer (ReAct, deciding lap by lap) vs. the pre-race planner (Plan-then-Execute, laying out the full strategy before lights out). Which approach wins on simple one-stop races? On chaotic wet races with safety cars?"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3: Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## Summary\n\n### Key Concepts\n\n| Concept | Definition | F1 Parallel |\n|---------|-----------|-------------|\n| **AI agents** | LLMs as reasoning engines that can take actions through tools | The race engineer who reasons, decides, and acts â€” not just advises |\n| **Tools** | The agent's interface to the world: search, calculate, execute code, call APIs | Weather API, tire model, fuel calculator, gap predictor, team radio |\n| **ReAct** | Interleaves reasoning and acting for flexible problem-solving | Think then act each lap: \"tires degrading â†’ query model â†’ call pit stop\" |\n| **Chain-of-thought** | Explicit reasoning improves tool selection and task decomposition | Senior engineer reasoning step-by-step vs. junior reacting impulsively |\n| **Planning** | Multi-step strategy requiring sequential decisions | Pre-race strategy: medium â†’ hard â†’ soft, with contingencies for rain and safety car |\n| **Memory** | Remembering earlier context for better decisions | Remembering what happened in stint 1 to inform stint 3 strategy |\n| **Safety guardrails** | Rate limits, validation, sandboxing essential for production | You can't have the agent broadcasting on team radio without authorization |\n| **Multi-agent systems** | Specialized agents collaborate on complex tasks | Tire engineer + aero engineer + weather analyst + strategy chief = pit wall |\n\n### Fundamental Insight\n\nAgents transform LLMs from passive text generators into active problem-solvers. The key is not the tools themselves â€” it's the reasoning loop that decides *which* tool to use and *when*. The better the reasoning, the more capable the agent. This is why improvements in base LLM reasoning (from GPT-3 to GPT-4 to Claude) translate directly into more capable agents. In F1 terms, giving a novice engineer the same pit wall tools as Adrian Newey won't produce the same results â€” the quality of the *reasoning* between tool calls is everything."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## Next Steps\n\nBuilding agents is one thing â€” knowing if they actually work is another. In **Notebook 28: Evaluating AI Systems**, we'll learn the science of AI evaluation: benchmarks, automated eval frameworks, LLM-as-judge, red teaming, and the metrics that determine whether an AI system is ready for production. In F1 terms, how do you measure if your strategy model is actually *good*? You need standardized race scenarios for testing, the ability to A/B test two strategies in simulation, and the race engineer's judgment as ground truth."
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

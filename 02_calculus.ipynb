{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Part 1.2: Calculus for Deep Learning — The Formula 1 Edition\n\nCalculus is essential for understanding how neural networks learn. The key insight: **learning = optimization**, and optimization requires derivatives.\n\nBut here's the thing: **F1 engineers live and breathe calculus every race weekend**. When an engineer asks \"how much faster will we go if we reduce the rear wing angle by one degree?\" — that's a derivative. When a strategist asks \"which setup parameter should we change to improve lap time the most?\" — that's a gradient. And when the team iteratively tweaks the car setup between practice sessions to find the optimal configuration — that's gradient descent.\n\nEvery tenth of a second on track is found through the same mathematical machinery that trains neural networks.\n\n## Learning Objectives\n- [ ] Compute partial derivatives of multivariate functions\n- [ ] Apply the chain rule to composite functions\n- [ ] Understand gradients as directions of steepest ascent\n- [ ] Implement gradient descent from scratch\n\n---",
   "id": "cell-0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "np.random.seed(42)"
   ],
   "id": "cell-1"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 1. Derivatives: The Core Concept\n\nThe **derivative** measures the rate of change of a function:\n\n$$f'(x) = \\frac{df}{dx} = \\lim_{h \\to 0} \\frac{f(x + h) - f(x)}{h}$$\n\n**Intuition**: The derivative tells you how much the output changes when you slightly change the input.\n\n**F1 analogy:** The derivative is the speedometer of calculus. Your car's speed is the derivative of its position along the track — it tells you how fast your position is changing at any given instant. Acceleration is the derivative of speed. Tire degradation rate is the derivative of tire performance over laps. Every \"rate of change\" question on the pit wall is a derivative question.\n\n### Why This Matters for Deep Learning\n\nIf `loss = f(weights)`, then the derivative tells us:\n- **Which direction** to change weights to reduce loss\n- **How much** each weight affects the loss",
   "id": "cell-2"
  },
  {
   "cell_type": "markdown",
   "source": "### Deep Dive: What Does a Derivative Really Mean?\n\nThe derivative answers a fundamental question: **\"If I wiggle the input a tiny bit, how much does the output wiggle?\"**\n\nThink of it like this:\n- You're turning a dial (input x)\n- A meter responds (output f(x))\n- The derivative tells you: \"For each unit I turn the dial, how many units does the meter move?\"\n\n**F1 analogy:** Imagine you're the race engineer adjusting the front wing angle on your driver's car. You tweak it by one degree (the \"wiggle\"). The derivative tells you: \"For that one degree of wing change, how many km/h did your top speed change?\" or \"How many tenths did your cornering speed improve?\" The derivative is the sensitivity of performance to your adjustment.\n\n#### The Formal Definition Unpacked\n\n$$f'(x) = \\lim_{h \\to 0} \\frac{f(x + h) - f(x)}{h}$$\n\n| Component | Meaning | F1 Analogy |\n|-----------|---------|------------|\n| $f(x + h)$ | Output after nudging input by tiny amount h | Lap time after a small setup change |\n| $f(x)$ | Original output | Lap time with current setup |\n| $f(x + h) - f(x)$ | Change in output (how much the meter moved) | Time gained or lost from the change |\n| $h$ | Change in input (how much we turned the dial) | Size of the setup adjustment |\n| $\\frac{f(x+h) - f(x)}{h}$ | **Rate of change** = output change per unit input change | Seconds gained per degree of wing angle |\n| $\\lim_{h \\to 0}$ | Take h infinitesimally small (instantaneous rate) | The exact sensitivity at this precise setting |\n\n#### Why Do We Care About Rate of Change?\n\n| Context | What the Derivative Tells Us | F1 Parallel |\n|---------|------------------------------|-------------|\n| **Physics** | Velocity = derivative of position. \"How fast am I moving right now?\" | Instantaneous speed through a corner |\n| **Economics** | Marginal cost = derivative of total cost. \"Cost of making one more unit?\" | Cost per tenth of a second of downforce |\n| **Machine Learning** | Gradient of loss = derivative of loss w.r.t. weights. \"How does changing this weight affect the error?\" | \"How does changing wing angle affect lap time?\" |\n\nIn ML specifically: **Derivatives tell us which direction to adjust weights to reduce error.**\n\nIn F1 specifically: **Derivatives tell the engineer which direction to adjust the setup to reduce lap time.**",
   "metadata": {},
   "id": "cell-3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Numerical derivative approximation\ndef numerical_derivative(f, x, h=1e-5):\n    \"\"\"Approximate derivative using finite differences.\"\"\"\n    return (f(x + h) - f(x - h)) / (2 * h)\n\n# Example: f(x) = x^2 — Think of x as wing angle, f(x) as drag force\nwing_angle = lambda x: x**2\nwing_angle_derivative = lambda x: 2*x  # We know this analytically\n\nangle = 3.0\nprint(f\"f(x) = x² at x = {angle}\")\nprint(f\"  (Think: drag as a function of wing angle)\")\nprint(f\"Numerical derivative: {numerical_derivative(wing_angle, angle):.6f}\")\nprint(f\"Analytical derivative: {wing_angle_derivative(angle):.6f}\")",
   "id": "cell-4"
  },
  {
   "cell_type": "code",
   "source": "# Interactive visualization: Tangent lines at multiple points\n# Shows how the derivative (slope) changes across the function\n# F1 context: Think of this as how the \"sensitivity\" of lap time to a setup \n# parameter changes depending on where you are in the setup range\n\ndef plot_multiple_tangents(f, f_prime, x_range, points, title):\n    \"\"\"\n    Plot a function with tangent lines at multiple points.\n    This visualizes how the derivative changes across the function.\n    \"\"\"\n    x = np.linspace(x_range[0], x_range[1], 200)\n    y = f(x)\n    \n    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n    \n    # Left plot: Function with tangent lines\n    axes[0].plot(x, y, 'b-', linewidth=2, label='f(x)')\n    \n    colors = plt.cm.Reds(np.linspace(0.3, 0.9, len(points)))\n    \n    for x0, color in zip(points, colors):\n        y0 = f(x0)\n        slope = f_prime(x0)\n        \n        # Tangent line: y = f(x0) + f'(x0)(x - x0)\n        x_tangent = np.linspace(x0 - 1.5, x0 + 1.5, 50)\n        y_tangent = y0 + slope * (x_tangent - x0)\n        \n        axes[0].plot(x_tangent, y_tangent, '--', color=color, linewidth=1.5, alpha=0.8)\n        axes[0].scatter([x0], [y0], color=color, s=80, zorder=5)\n        axes[0].annotate(f'slope={slope:.2f}', xy=(x0, y0), xytext=(x0+0.3, y0+0.5),\n                        fontsize=9, color=color)\n    \n    axes[0].set_xlabel('Setup Parameter')\n    axes[0].set_ylabel('Performance')\n    axes[0].set_title(f'{title}\\nTangent lines show instantaneous rate of change')\n    axes[0].legend()\n    axes[0].grid(True, alpha=0.3)\n    axes[0].set_ylim([min(y) - 1, max(y) + 2])\n    \n    # Right plot: The derivative function itself\n    y_prime = f_prime(x)\n    axes[1].plot(x, y_prime, 'r-', linewidth=2, label=\"f'(x) (derivative)\")\n    axes[1].axhline(y=0, color='k', linewidth=0.5)\n    \n    for x0, color in zip(points, colors):\n        slope = f_prime(x0)\n        axes[1].scatter([x0], [slope], color=color, s=80, zorder=5)\n    \n    axes[1].set_xlabel('Setup Parameter')\n    axes[1].set_ylabel(\"f'(x) — Sensitivity\")\n    axes[1].set_title(\"The Derivative Function\\nShows the sensitivity at every point\")\n    axes[1].legend()\n    axes[1].grid(True, alpha=0.3)\n    \n    plt.tight_layout()\n    plt.show()\n\n# Example 1: f(x) = x^2 (parabola) — like drag vs wing angle\nf = lambda x: x**2\nf_prime = lambda x: 2*x\nplot_multiple_tangents(f, f_prime, x_range=(-3, 3), \n                       points=[-2, -1, 0, 1, 2], \n                       title='f(x) = x² — Drag vs Wing Angle')\n\nprint(\"Key observations for f(x) = x²:\")\nprint(\"- At x=0: slope is 0 (bottom of the parabola - minimum!)\")\nprint(\"  F1: At the optimal wing angle, tiny changes don't affect drag\")\nprint(\"- Negative x: slope is negative (function decreasing)\")\nprint(\"- Positive x: slope is positive (function increasing)\")\nprint(\"- Slope magnitude increases as we move away from 0\")\nprint(\"  F1: The further from optimal, the more sensitive the car becomes\")",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "id": "cell-5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Visualize derivative as slope of tangent line\ndef plot_tangent(f, f_prime, x0, title):\n    \"\"\"Plot function with tangent line at x0.\"\"\"\n    x = np.linspace(x0 - 2, x0 + 2, 100)\n    y = f(x)\n    \n    # Tangent line: y = f(x0) + f'(x0)(x - x0)\n    slope = f_prime(x0)\n    tangent = f(x0) + slope * (x - x0)\n    \n    plt.figure(figsize=(10, 6))\n    plt.plot(x, y, 'b-', linewidth=2, label='f(x)')\n    plt.plot(x, tangent, 'r--', linewidth=2, label=f'Tangent (slope = {slope:.2f})')\n    plt.scatter([x0], [f(x0)], color='red', s=100, zorder=5)\n    plt.xlabel('Wing Angle (degrees)')\n    plt.ylabel('Drag Coefficient')\n    plt.title(title)\n    plt.legend()\n    plt.grid(True, alpha=0.3)\n    plt.show()\n\n# f(x) = x² at different points\nf = lambda x: x**2\nf_prime = lambda x: 2*x\n\nplot_tangent(f, f_prime, 1.5, \"Drag vs Wing Angle: f(x) = x² with tangent at x = 1.5\\nSlope tells us how sensitive drag is to wing changes at this point\")",
   "id": "cell-6"
  },
  {
   "cell_type": "code",
   "source": "# Example 2: A more complex function - sine wave\n# F1 context: Oscillating performance, like tire grip over a lap \n# (grip cycles as tire temp rises and falls through corners)\nf = lambda x: np.sin(x)\nf_prime = lambda x: np.cos(x)\nplot_multiple_tangents(f, f_prime, x_range=(-2*np.pi, 2*np.pi), \n                       points=[-np.pi, -np.pi/2, 0, np.pi/2, np.pi], \n                       title='f(x) = sin(x) — Oscillating Tire Grip')\n\nprint(\"\\nKey observations for f(x) = sin(x):\")\nprint(\"- At peaks/troughs (x = +/-pi/2): slope is 0 (maxima/minima)\")\nprint(\"  F1: When grip peaks or bottoms out, it's momentarily stable\")\nprint(\"- At zero crossings (x = 0, +/-pi): slope is +/-1 (steepest)\")\nprint(\"  F1: Grip is changing fastest during transitions\")\nprint(\"- The derivative of sin(x) is cos(x) - shifted by pi/2!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "id": "cell-7"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Common Derivatives\n\n| Function | Derivative | F1 Analogy |\n|----------|------------|------------|\n| $x^n$ | $nx^{n-1}$ | Power-law relationships (aero drag scales with speed squared) |\n| $e^x$ | $e^x$ | Exponential tire degradation — rate of wear proportional to current wear |\n| $\\ln(x)$ | $1/x$ | Diminishing returns — each extra unit of downforce costs more drag |\n| $\\sin(x)$ | $\\cos(x)$ | Oscillating grip through corner sequences |\n| $\\cos(x)$ | $-\\sin(x)$ | Phase-shifted oscillations in suspension response |\n\n### Activation Functions and Their Derivatives\n\nThese are critical for backpropagation!\n\n**F1 analogy:** Activation functions are like driver response curves. A sigmoid is like brake feel — gentle initial response, strong in the middle, saturating at full lock. ReLU is like a rev limiter — nothing below threshold, linear above it.",
   "id": "cell-8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Sigmoid and its derivative — like brake feel: gentle at first, strong in mid-range, saturates\ndef sigmoid(x):\n    return 1 / (1 + np.exp(-x))\n\ndef sigmoid_derivative(x):\n    s = sigmoid(x)\n    return s * (1 - s)  # Nice property!\n\n# ReLU and its derivative — like a rev limiter: nothing below threshold, linear above\ndef relu(x):\n    return np.maximum(0, x)\n\ndef relu_derivative(x):\n    return (x > 0).astype(float)\n\n# Tanh and its derivative — like steering response: symmetric, saturates at extremes\ndef tanh(x):\n    return np.tanh(x)\n\ndef tanh_derivative(x):\n    return 1 - np.tanh(x)**2\n\n# Plot them all\nx = np.linspace(-5, 5, 200)\n\nfig, axes = plt.subplots(2, 3, figsize=(15, 8))\n\nactivations = [\n    (sigmoid, sigmoid_derivative, 'Sigmoid\\n(Brake Feel)'),\n    (relu, relu_derivative, 'ReLU\\n(Rev Limiter)'),\n    (tanh, tanh_derivative, 'Tanh\\n(Steering Response)')\n]\n\nfor i, (func, deriv, name) in enumerate(activations):\n    # Function\n    axes[0, i].plot(x, func(x), 'b-', linewidth=2)\n    axes[0, i].set_title(f'{name}')\n    axes[0, i].set_xlabel('Input Signal')\n    axes[0, i].axhline(y=0, color='k', linewidth=0.5)\n    axes[0, i].axvline(x=0, color='k', linewidth=0.5)\n    axes[0, i].grid(True, alpha=0.3)\n    \n    # Derivative\n    axes[1, i].plot(x, deriv(x), 'r-', linewidth=2)\n    axes[1, i].set_title(f'{name.split(chr(10))[0]} Derivative (Sensitivity)')\n    axes[1, i].set_xlabel('Input Signal')\n    axes[1, i].axhline(y=0, color='k', linewidth=0.5)\n    axes[1, i].axvline(x=0, color='k', linewidth=0.5)\n    axes[1, i].grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\nprint(\"Key observations:\")\nprint(\"- Sigmoid derivative max is 0.25 (causes vanishing gradients)\")\nprint(\"  F1: Like over-assisted brakes — can't feel the road anymore\")\nprint(\"- ReLU derivative is 0 or 1 (no vanishing gradient for positive x)\")\nprint(\"  F1: Clean on/off response — either engaged or not\")\nprint(\"- Tanh derivative max is 1 (better than sigmoid)\")\nprint(\"  F1: Better steering feel, but still saturates at extremes\")",
   "id": "cell-9"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## 2. Partial Derivatives\n\nFor functions of multiple variables, **partial derivatives** measure the rate of change with respect to one variable while holding others constant.\n\n$$\\frac{\\partial f}{\\partial x} = \\lim_{h \\to 0} \\frac{f(x + h, y) - f(x, y)}{h}$$\n\n**F1 analogy:** An F1 car has dozens of setup parameters — wing angles, ride height, spring stiffness, tire pressures, brake bias, differential settings. A partial derivative answers the question: **\"If I change ONLY the front wing angle (holding everything else fixed), how much does the lap time change?\"** This is exactly what engineers do during practice sessions — isolate one variable at a time to understand its individual effect.\n\n### Example\n\nFor $f(x, y) = x^2 + 3xy + y^2$:\n\n$$\\frac{\\partial f}{\\partial x} = 2x + 3y$$\n$$\\frac{\\partial f}{\\partial y} = 3x + 2y$$",
   "id": "cell-10"
  },
  {
   "cell_type": "markdown",
   "source": "### Deep Dive: Why Does the Gradient Point \"Uphill\"?\n\nThis is one of the most important insights in optimization. Let's build intuition for WHY the gradient points in the direction of steepest increase.\n\n#### The Gradient as a \"Which Way is Up?\" Detector\n\nImagine you're standing on a hilly surface (the function) and want to find the steepest uphill direction. The gradient is like a compass that always points uphill.\n\n**F1 analogy:** Think of the car setup landscape as a terrain map, where altitude represents lap time. The gradient at your current setup is like your race engineer's gut feeling about which combination of changes would make the car slower the fastest. To make the car **faster**, you go in the **opposite** direction — down the gradient, toward lower lap times. This is exactly what gradient descent does.\n\n**Mathematical Intuition:**\n\nThe gradient $\\nabla f$ at a point gives you the direction where the function increases **most rapidly**.\n\nThink about it:\n- $\\frac{\\partial f}{\\partial x}$ tells you: \"If I move in the x-direction, how fast does f increase?\"\n- $\\frac{\\partial f}{\\partial y}$ tells you: \"If I move in the y-direction, how fast does f increase?\"\n- The gradient combines these: \"The optimal uphill direction is a blend of these, weighted by how steep each direction is\"\n\n**F1 analogy:** If changing wing angle (x) improves lap time by 0.3s per degree, and changing ride height (y) improves it by 0.5s per mm, the gradient tells you: \"The fastest way to improve is a blend of both, weighted by their individual sensitivities.\"\n\n#### Directional Derivatives: Movement in Any Direction\n\nIf you move in direction $\\mathbf{u}$ (a unit vector), the rate of change is:\n\n$$\\frac{\\partial f}{\\partial \\mathbf{u}} = \\nabla f \\cdot \\mathbf{u} = |\\nabla f| \\cos(\\theta)$$\n\nWhere $\\theta$ is the angle between gradient and movement direction.\n\n| Direction relative to gradient | $\\cos(\\theta)$ | Rate of change | F1 Interpretation |\n|-------------------------------|----------------|----------------|-------------------|\n| Same as gradient ($\\theta = 0$) | 1 | Maximum increase | Worst possible setup change (max lap time increase) |\n| Perpendicular ($\\theta = 90$) | 0 | No change (contour line) | A trade-off change — different but equally fast |\n| Opposite ($\\theta = 180$) | -1 | Maximum decrease | Best possible setup change (max lap time decrease) |\n\n**This is why gradient descent works!** Moving opposite to the gradient gives maximum decrease.",
   "metadata": {},
   "id": "cell-11"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Numerical partial derivatives\ndef partial_derivative(f, point, var_index, h=1e-5):\n    \"\"\"\n    Compute partial derivative of f at point with respect to variable var_index.\n    \n    F1 context: This is like measuring the sensitivity of lap time to ONE \n    setup parameter while holding all others fixed.\n    \n    Args:\n        f: Function taking array of variables (setup parameters)\n        point: Array of variable values (current setup)\n        var_index: Which variable to differentiate (which parameter to tweak)\n        h: Step size (how big a tweak)\n    \"\"\"\n    point = np.array(point, dtype=float)\n    point_plus = point.copy()\n    point_minus = point.copy()\n    point_plus[var_index] += h\n    point_minus[var_index] -= h\n    return (f(point_plus) - f(point_minus)) / (2 * h)\n\n# f(wing_angle, ride_height) = wing_angle² + 3*wing_angle*ride_height + ride_height²\n# Think: lap time as a function of two setup parameters\ndef lap_time_model(p):\n    wing_angle, ride_height = p\n    return wing_angle**2 + 3*wing_angle*ride_height + ride_height**2\n\n# Analytical partial derivatives\ndef dlap_d_wing(wing_angle, ride_height):\n    return 2*wing_angle + 3*ride_height\n\ndef dlap_d_height(wing_angle, ride_height):\n    return 3*wing_angle + 2*ride_height\n\n# Test at point (2, 3) — wing angle=2, ride height=3\nsetup_point = [2, 3]\nprint(f\"At setup point (wing_angle={setup_point[0]}, ride_height={setup_point[1]}):\")\nprint(f\"  d(lap_time)/d(wing_angle) numerical:  {partial_derivative(lap_time_model, setup_point, 0):.6f}\")\nprint(f\"  d(lap_time)/d(wing_angle) analytical: {dlap_d_wing(*setup_point):.6f}\")\nprint(f\"  d(lap_time)/d(ride_height) numerical:  {partial_derivative(lap_time_model, setup_point, 1):.6f}\")\nprint(f\"  d(lap_time)/d(ride_height) analytical: {dlap_d_height(*setup_point):.6f}\")\nprint(f\"\\nInterpretation: ride_height has a bigger derivative ({dlap_d_height(*setup_point)}) than wing_angle ({dlap_d_wing(*setup_point)})\")\nprint(\"=> Changing ride height would affect lap time more at this setup point\")",
   "id": "cell-12"
  },
  {
   "cell_type": "code",
   "source": "# Enhanced gradient field visualization with interactive exploration\n# Shows gradient as arrows pointing uphill, with different movement directions\n# F1: Gradient field over the setup landscape — arrows show \"which way makes the car slower\"\n\ndef visualize_gradient_directions():\n    \"\"\"\n    Interactive visualization showing:\n    1. Gradient field (arrows pointing uphill / toward slower lap times)\n    2. How rate of change varies with direction\n    3. Why opposite-to-gradient is the best descent direction\n    \"\"\"\n    \n    fig = plt.figure(figsize=(16, 5))\n    \n    # Define function: f(x,y) = x² + 0.5*y² (elliptical paraboloid)\n    # F1: Lap time surface — wing_angle² + 0.5*ride_height²\n    def f(x, y):\n        return x**2 + 0.5*y**2\n    \n    def grad_f(x, y):\n        return np.array([2*x, y])\n    \n    # Create grid\n    x = np.linspace(-3, 3, 100)\n    y = np.linspace(-3, 3, 100)\n    X, Y = np.meshgrid(x, y)\n    Z = f(X, Y)\n    \n    # Plot 1: 3D surface\n    ax1 = fig.add_subplot(131, projection='3d')\n    ax1.plot_surface(X, Y, Z, cmap=cm.viridis, alpha=0.7)\n    ax1.set_xlabel('Wing Angle')\n    ax1.set_ylabel('Ride Height')\n    ax1.set_zlabel('Lap Time')\n    ax1.set_title('Lap Time Surface\\n(Bowl = optimal setup at center)')\n    \n    # Plot 2: Contour with gradient field\n    ax2 = fig.add_subplot(132)\n    contour = ax2.contour(X, Y, Z, levels=15, cmap=cm.viridis)\n    ax2.clabel(contour, inline=True, fontsize=8)\n    \n    # Sparse grid for gradient arrows\n    x_sparse = np.linspace(-2.5, 2.5, 8)\n    y_sparse = np.linspace(-2.5, 2.5, 8)\n    X_s, Y_s = np.meshgrid(x_sparse, y_sparse)\n    \n    U = 2 * X_s  # df/d(wing_angle)\n    V = Y_s      # df/d(ride_height)\n    \n    # Normalize for visualization\n    mag = np.sqrt(U**2 + V**2) + 1e-10\n    U_norm = U / mag * 0.4\n    V_norm = V / mag * 0.4\n    \n    ax2.quiver(X_s, Y_s, U_norm, V_norm, mag, cmap=cm.Reds, alpha=0.8)\n    ax2.set_xlabel('Wing Angle')\n    ax2.set_ylabel('Ride Height')\n    ax2.set_title('Gradient Field Over Setup Space\\nArrows point toward SLOWER lap times')\n    ax2.set_aspect('equal')\n    ax2.plot([0], [0], 'k*', markersize=15, label='Optimal Setup')\n    ax2.legend()\n    \n    # Plot 3: Directional derivative at a specific point\n    ax3 = fig.add_subplot(133)\n    \n    # Pick a point (current setup)\n    px, py = 2.0, 1.0\n    grad = grad_f(px, py)\n    grad_mag = np.linalg.norm(grad)\n    \n    # Compute directional derivative for all directions\n    angles = np.linspace(0, 2*np.pi, 100)\n    dir_derivs = []\n    for theta in angles:\n        direction = np.array([np.cos(theta), np.sin(theta)])\n        dir_deriv = np.dot(grad, direction)\n        dir_derivs.append(dir_deriv)\n    \n    # Plot directional derivative vs angle\n    ax3.plot(np.degrees(angles), dir_derivs, 'b-', linewidth=2)\n    ax3.axhline(y=0, color='k', linewidth=0.5)\n    ax3.axhline(y=grad_mag, color='g', linestyle='--', label=f'Max = |grad| = {grad_mag:.2f}')\n    ax3.axhline(y=-grad_mag, color='r', linestyle='--', label=f'Min = -|grad| = {-grad_mag:.2f}')\n    \n    # Mark special directions\n    grad_angle = np.degrees(np.arctan2(grad[1], grad[0]))\n    ax3.axvline(x=grad_angle, color='g', alpha=0.5)\n    ax3.axvline(x=grad_angle + 180, color='r', alpha=0.5)\n    \n    ax3.set_xlabel('Setup Change Direction (degrees)')\n    ax3.set_ylabel('Rate of Lap Time Change')\n    ax3.set_title(f'Sensitivity vs Direction at Setup ({px}, {py})\\nWhich way to adjust?')\n    ax3.legend(loc='lower right')\n    ax3.set_xticks([0, 90, 180, 270, 360])\n    ax3.grid(True, alpha=0.3)\n    \n    plt.tight_layout()\n    plt.show()\n    \n    print(f\"At setup (wing={px}, height={py}):\")\n    print(f\"  Gradient = {grad}\")\n    print(f\"  Gradient magnitude = {grad_mag:.2f}\")\n    print(f\"  Gradient direction = {grad_angle:.1f} degrees\")\n    print(f\"\\n  To make car SLOWER fastest: change setup at {grad_angle:.1f} degrees (with gradient)\")\n    print(f\"  To make car FASTER fastest: change setup at {grad_angle + 180:.1f} degrees (against gradient)\")\n    print(f\"  To trade off (same lap time): change at {grad_angle + 90:.1f} degrees or {grad_angle - 90:.1f} degrees\")\n\nvisualize_gradient_directions()",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "id": "cell-13"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Visualize a 2D function and its partial derivatives\n# F1: Lap time as a function of two setup parameters\ndef lap_time_surface(wing_angle, ride_height):\n    return wing_angle**2 + ride_height**2\n\n# Create meshgrid\nx = np.linspace(-3, 3, 50)\ny = np.linspace(-3, 3, 50)\nX, Y = np.meshgrid(x, y)\nZ = lap_time_surface(X, Y)\n\nfig = plt.figure(figsize=(15, 5))\n\n# 3D surface\nax1 = fig.add_subplot(131, projection='3d')\nax1.plot_surface(X, Y, Z, cmap=cm.viridis, alpha=0.8)\nax1.set_xlabel('Wing Angle')\nax1.set_ylabel('Ride Height')\nax1.set_zlabel('Lap Time')\nax1.set_title('Lap Time = wing² + height²')\n\n# Contour plot with gradient vectors\nax2 = fig.add_subplot(132)\ncontour = ax2.contour(X, Y, Z, levels=15, cmap=cm.viridis)\nax2.clabel(contour, inline=True, fontsize=8)\n\n# Add gradient vectors at some setup points\nsetup_points = [(-2, -2), (-2, 0), (0, 2), (1, 1), (2, -1)]\nfor px, py in setup_points:\n    grad_x = 2 * px  # d(lap_time)/d(wing_angle) = 2*wing_angle\n    grad_y = 2 * py  # d(lap_time)/d(ride_height) = 2*ride_height\n    ax2.arrow(px, py, grad_x*0.3, grad_y*0.3, head_width=0.15, head_length=0.1, fc='red', ec='red')\n\nax2.set_xlabel('Wing Angle')\nax2.set_ylabel('Ride Height')\nax2.set_title('Setup Space with Gradient Vectors\\n(Red arrows = direction of increasing lap time)')\nax2.set_aspect('equal')\n\n# Slice at ride_height=1 — what happens when we only vary wing angle?\nax3 = fig.add_subplot(133)\nheight_fixed = 1\nz_slice = lap_time_surface(x, height_fixed)\nax3.plot(x, z_slice, 'b-', linewidth=2)\nax3.set_xlabel('Wing Angle')\nax3.set_ylabel(f'Lap Time (height={height_fixed})')\nax3.set_title(f'Partial View: Vary Wing Only (height={height_fixed})\\nd(lap_time)/d(wing) = 2*wing')\nax3.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()",
   "id": "cell-14"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## 3. The Gradient\n\nThe **gradient** is the vector of all partial derivatives:\n\n$$\\nabla f = \\begin{bmatrix} \\frac{\\partial f}{\\partial x_1} \\\\ \\frac{\\partial f}{\\partial x_2} \\\\ \\vdots \\\\ \\frac{\\partial f}{\\partial x_n} \\end{bmatrix}$$\n\n**F1 analogy:** The gradient is the engineer's **complete sensitivity report**. Instead of asking about one parameter at a time, the gradient bundles ALL partial derivatives into a single vector: \"Here's how sensitive lap time is to wing angle, ride height, spring stiffness, tire pressure... all at once.\" It tells you which parameter to change to get the biggest improvement, and by how much.\n\n### Key Properties\n\n1. **Direction**: Points in the direction of steepest **increase** (toward slower lap times)\n2. **Magnitude**: Tells how steep that increase is (how sensitive the car is to changes)\n3. **To minimize**: Move in the **opposite** direction (negative gradient = toward faster lap times)",
   "id": "cell-15"
  },
  {
   "cell_type": "markdown",
   "source": "### Deep Dive: Why the Chain Rule is CRITICAL for Deep Learning\n\nThe chain rule is not just another calculus rule - it's the **mathematical heart of backpropagation**. Without it, we couldn't train neural networks.\n\n**F1 analogy:** The chain rule describes **sequential dependencies** in a system. In F1, engine power affects wheel torque, which affects tire slip, which affects cornering speed, which affects lap time. If you want to know \"how does a 5 HP increase in engine power affect lap time?\", you need to chain together the sensitivities at each link: (d_torque/d_power) x (d_slip/d_torque) x (d_cornering/d_slip) x (d_laptime/d_cornering). Each link multiplies the effect through the chain — that's the chain rule.\n\n#### The Core Insight\n\nWhen you have nested functions (f composed with g), changes **propagate** through the chain:\n\n$$\\text{small change in } x \\rightarrow \\text{change in } g(x) \\rightarrow \\text{change in } f(g(x))$$\n\nThe chain rule says: **multiply the rates of change at each step**.\n\n#### Breaking Down the Formula\n\nFor $y = f(g(x))$, let's call $u = g(x)$ (the intermediate value):\n\n$$\\frac{dy}{dx} = \\frac{dy}{du} \\cdot \\frac{du}{dx}$$\n\n| Component | Meaning | Neural Network Terms | F1 Analogy |\n|-----------|---------|----------------------|------------|\n| $\\frac{du}{dx}$ | How much does u change when x changes? | \"Local gradient\" of layer | How torque changes with engine power |\n| $\\frac{dy}{du}$ | How much does y change when u changes? | \"Upstream gradient\" from later layers | How lap time changes with torque |\n| $\\frac{dy}{dx}$ | How much does y change when x changes? | \"Full gradient\" through the network | How lap time changes with engine power |\n\n#### Visual: How Changes Propagate\n\n```\nInput x                        Output y\n   |                              |\n   v                              v\n   x ----[g]----> u = g(x) ----[f]----> y = f(u)\n   \n   Δx    ->     Δu = (dg/dx)·Δx   ->   Δy = (df/du)·Δu\n                                            = (df/du)·(dg/dx)·Δx\n```\n\nThe change in x gets **amplified (or diminished)** at each step, and the total effect is the product!\n\n**F1 analogy:** A small engine mapping change ($\\Delta x$) produces a torque change, which produces a speed change, which produces a lap time change. If each step amplifies by 2x, the total effect is $2 \\times 2 \\times 2 = 8x$. But if one link attenuates (say tire slip absorbs the torque), the effect might be $2 \\times 0.1 \\times 2 = 0.4x$. This \"vanishing\" effect is exactly the **vanishing gradient problem** in deep networks.",
   "metadata": {},
   "id": "cell-16"
  },
  {
   "cell_type": "code",
   "source": "# Step-by-step example with ACTUAL NUMBERS\n# F1 context: How engine mapping affects lap time through a chain of dependencies\n# Let's trace through f(g(x)) = (2x + 1)³ at x = 2\n\nprint(\"=\" * 60)\nprint(\"CHAIN RULE: Step-by-Step with Actual Numbers\")\nprint(\"=\" * 60)\nprint(\"\\nFunction: y = (2x + 1)³\")\nprint(\"This is f(g(x)) where g(x) = 2x + 1 and f(u) = u³\")\nprint(\"\\nF1 context: x = engine power setting, g(x) = wheel torque,\")\nprint(\"f(g(x)) = effect on lap time (cubed relationship)\")\nprint(\"\\n\" + \"-\" * 60)\n\nx = 2\nprint(f\"Evaluating at x = {x}\")\n\n# Step 1: Forward pass - compute intermediate and final values\nu = 2*x + 1  # g(x)\ny = u**3      # f(u)\n\nprint(f\"\\n1. FORWARD PASS:\")\nprint(f\"   u = g(x) = 2({x}) + 1 = {u}\")\nprint(f\"   y = f(u) = {u}³ = {y}\")\n\n# Step 2: Compute local derivatives\ndg_dx = 2          # derivative of g(x) = 2x + 1 is 2\ndf_du = 3 * u**2   # derivative of f(u) = u³ is 3u²\n\nprint(f\"\\n2. LOCAL DERIVATIVES (at this point):\")\nprint(f\"   dg/dx = d(2x+1)/dx = 2\")\nprint(f\"   df/du = d(u³)/du = 3u² = 3({u})² = {df_du}\")\n\n# Step 3: Apply chain rule\ndy_dx = df_du * dg_dx\n\nprint(f\"\\n3. CHAIN RULE:\")\nprint(f\"   dy/dx = (df/du) x (dg/dx)\")\nprint(f\"         = {df_du} x {dg_dx}\")\nprint(f\"         = {dy_dx}\")\n\n# Verify with the analytical derivative\n# y = (2x+1)³, so dy/dx = 3(2x+1)² × 2 = 6(2x+1)²\ndy_dx_analytical = 6 * (2*x + 1)**2\nprint(f\"\\n4. VERIFICATION:\")\nprint(f\"   Analytical formula: dy/dx = 6(2x+1)²\")\nprint(f\"   At x = {x}: dy/dx = 6({2*x+1})² = {dy_dx_analytical}\")\nprint(f\"   Match: {dy_dx == dy_dx_analytical}\")\n\n# What does this mean?\nprint(f\"\\n5. INTERPRETATION:\")\nprint(f\"   If we increase x by a tiny amount dx = 0.001:\")\nprint(f\"   y will increase by approximately {dy_dx} x 0.001 = {dy_dx * 0.001}\")\nprint(f\"   F1: A tiny engine power tweak propagates and amplifies through the chain!\")\n\n# Verify numerically\nh = 0.001\ny_original = (2*x + 1)**3\ny_nudged = (2*(x + h) + 1)**3\nactual_change = y_nudged - y_original\nprint(f\"   Actual change: {y_nudged} - {y_original} = {actual_change:.6f}\")\nprint(f\"   Predicted change: {dy_dx * h:.6f}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "id": "cell-17"
  },
  {
   "cell_type": "code",
   "source": "# Visualization: Chain Rule as Signal Propagation\n# Shows how a small change propagates through composed functions\n# F1: Like tracing how an engine mapping change ripples through the drivetrain\n\ndef visualize_chain_rule_propagation():\n    \"\"\"\n    Visualize how changes propagate through composed functions.\n    f(g(x)) = sin(x²) \n    F1: Think of x as throttle input, g(x) = engine response, f(g(x)) = speed output\n    \"\"\"\n    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n    \n    x = np.linspace(-2, 2, 200)\n    \n    # g(x) = x²  (engine response to throttle)\n    g = x**2\n    # f(u) = sin(u) where u = g(x)  (speed oscillation from engine response)\n    f = np.sin(g)\n    \n    # Plot g(x)\n    axes[0].plot(x, g, 'b-', linewidth=2)\n    axes[0].set_xlabel('Throttle Input (x)')\n    axes[0].set_ylabel('Engine Response u = g(x) = x²')\n    axes[0].set_title('Step 1: Inner function\\nThrottle -> Engine Response')\n    axes[0].grid(True, alpha=0.3)\n    axes[0].axhline(y=0, color='k', linewidth=0.5)\n    axes[0].axvline(x=0, color='k', linewidth=0.5)\n    \n    # Highlight a point\n    x0 = 1.5\n    u0 = x0**2\n    axes[0].scatter([x0], [u0], color='red', s=100, zorder=5)\n    axes[0].annotate(f'x={x0}\\nu={u0:.2f}', xy=(x0, u0), xytext=(x0+0.3, u0-0.5), fontsize=10)\n    \n    # Plot f(u) = sin(u)\n    u = np.linspace(0, 4, 200)\n    axes[1].plot(u, np.sin(u), 'g-', linewidth=2)\n    axes[1].set_xlabel('Engine Response (u)')\n    axes[1].set_ylabel('Speed Output y = f(u) = sin(u)')\n    axes[1].set_title('Step 2: Outer function\\nEngine Response -> Speed')\n    axes[1].grid(True, alpha=0.3)\n    axes[1].axhline(y=0, color='k', linewidth=0.5)\n    \n    y0 = np.sin(u0)\n    axes[1].scatter([u0], [y0], color='red', s=100, zorder=5)\n    axes[1].annotate(f'u={u0:.2f}\\ny={y0:.2f}', xy=(u0, y0), xytext=(u0+0.3, y0+0.2), fontsize=10)\n    \n    # Plot the composition f(g(x))\n    axes[2].plot(x, f, 'm-', linewidth=2)\n    axes[2].set_xlabel('Throttle Input (x)')\n    axes[2].set_ylabel('Speed Output y = sin(x²)')\n    axes[2].set_title('Result: Full Chain\\nThrottle -> Speed (composed)')\n    axes[2].grid(True, alpha=0.3)\n    axes[2].axhline(y=0, color='k', linewidth=0.5)\n    axes[2].axvline(x=0, color='k', linewidth=0.5)\n    \n    axes[2].scatter([x0], [y0], color='red', s=100, zorder=5)\n    axes[2].annotate(f'x={x0}\\ny={y0:.2f}', xy=(x0, y0), xytext=(x0+0.2, y0+0.3), fontsize=10)\n    \n    plt.tight_layout()\n    plt.show()\n    \n    # Now show the gradient computation\n    print(\"\\n\" + \"=\" * 60)\n    print(\"CHAIN RULE COMPUTATION for y = sin(x²) at x = 1.5\")\n    print(\"F1: How does a small throttle change affect final speed?\")\n    print(\"=\" * 60)\n    \n    # At x = 1.5\n    x_val = 1.5\n    u_val = x_val**2\n    y_val = np.sin(u_val)\n    \n    # Local gradients\n    dg_dx = 2 * x_val          # d(x²)/dx = 2x\n    df_du = np.cos(u_val)       # d(sin(u))/du = cos(u)\n    \n    # Chain rule\n    dy_dx = df_du * dg_dx\n    \n    print(f\"\\n1. Forward pass (throttle -> engine -> speed):\")\n    print(f\"   x (throttle) = {x_val}\")\n    print(f\"   u (engine response) = x² = {u_val}\")\n    print(f\"   y (speed) = sin(u) = {y_val:.4f}\")\n    \n    print(f\"\\n2. Backward pass (computing sensitivities):\")\n    print(f\"   dy/du = cos(u) = cos({u_val}) = {df_du:.4f}\")\n    print(f\"   du/dx = 2x = 2({x_val}) = {dg_dx}\")\n    \n    print(f\"\\n3. Chain rule (total sensitivity):\")\n    print(f\"   dy/dx = (dy/du) x (du/dx)\")\n    print(f\"         = {df_du:.4f} x {dg_dx}\")\n    print(f\"         = {dy_dx:.4f}\")\n    \n    # Verify numerically\n    h = 1e-5\n    numerical_grad = (np.sin((x_val + h)**2) - np.sin((x_val - h)**2)) / (2*h)\n    print(f\"\\n4. Numerical verification: {numerical_grad:.4f}\")\n\nvisualize_chain_rule_propagation()",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "id": "cell-18"
  },
  {
   "cell_type": "markdown",
   "source": "### Computational Graphs: The Key to Backpropagation\n\nA **computational graph** is a visual representation of how a function computes its output. Each node is an operation, and edges show data flow.\n\n**Why does this matter?** Neural networks are just big computational graphs, and backpropagation is just the chain rule applied systematically through the graph!\n\n**F1 analogy:** An F1 car's performance model is itself a computational graph. Inputs like fuel load, wing settings, and tire compound flow through physics equations (nodes) to produce outputs like predicted lap time. When the team wants to know \"how does fuel load affect lap time?\", they trace the graph backward — just like backpropagation.\n\n#### Example: Computing gradients through a simple graph\n\nConsider: $L = (wx + b - y)^2$ (squared error loss)\n\n```\n     w                              \n     |                              \n     v                              \nx -->[ * ]--> z1 -->[ + ]--> z2 -->[ - ]--> z3 -->[ ² ]--> L\n                      ^              ^\n                      |              |\n                      b              y (target)\n```\n\n**Forward pass (left to right):** Compute values at each node\n**Backward pass (right to left):** Compute gradients using chain rule",
   "metadata": {},
   "id": "cell-19"
  },
  {
   "cell_type": "code",
   "source": "# Detailed walkthrough of forward and backward pass through computational graph\n# L = (w*x + b - y)²\n# F1 context: L = predicted lap time error, w = setup gain, x = parameter, b = baseline, y = target time\n\ndef computational_graph_example():\n    \"\"\"\n    Step-by-step forward and backward pass through a computational graph.\n    This is EXACTLY how neural network libraries compute gradients!\n    \n    F1 parallel: Like tracing how setup parameters flow through a \n    performance model to produce predicted lap time, then tracing back\n    to find which parameter matters most.\n    \"\"\"\n    print(\"=\" * 70)\n    print(\"COMPUTATIONAL GRAPH: L = (w*x + b - y)²\")\n    print(\"F1: Predicted lap time error from a simple car model\")\n    print(\"=\" * 70)\n    \n    # Input values\n    x = 2.0   # input (e.g., wing angle setting)\n    y = 7.0   # target (e.g., target lap time)\n    w = 3.0   # weight (e.g., sensitivity coefficient)\n    b = 1.0   # bias (e.g., baseline performance)\n    \n    print(f\"\\nInputs: x={x} (wing angle), y={y} (target time), w={w} (sensitivity), b={b} (baseline)\")\n    print(\"\\n\" + \"-\" * 70)\n    print(\"FORWARD PASS (compute values left to right)\")\n    print(\"-\" * 70)\n    \n    # Forward pass - compute each node\n    z1 = w * x          # multiplication\n    print(f\"z1 = w * x = {w} * {x} = {z1}\")\n    \n    z2 = z1 + b         # addition\n    print(f\"z2 = z1 + b = {z1} + {b} = {z2}\")\n    \n    z3 = z2 - y         # subtraction (error)\n    print(f\"z3 = z2 - y = {z2} - {y} = {z3}\")\n    \n    L = z3 ** 2         # square (loss)\n    print(f\"L = z3² = {z3}² = {L}\")\n    \n    print(\"\\n\" + \"-\" * 70)\n    print(\"BACKWARD PASS (compute gradients right to left)\")\n    print(\"-\" * 70)\n    print(\"Starting from dL/dL = 1 (gradient of L with respect to itself)\\n\")\n    \n    # Backward pass - apply chain rule at each node\n    \n    # Start with gradient of loss w.r.t. itself\n    dL_dL = 1\n    print(f\"dL/dL = {dL_dL}\")\n    \n    # Node: L = z3² \n    # dL/dz3 = d(z3²)/dz3 = 2*z3\n    dL_dz3 = dL_dL * (2 * z3)\n    print(f\"\\nNode L = z3²:\")\n    print(f\"  Local gradient: d(z3²)/dz3 = 2*z3 = 2*{z3} = {2*z3}\")\n    print(f\"  dL/dz3 = dL/dL x d(z3²)/dz3 = {dL_dL} x {2*z3} = {dL_dz3}\")\n    \n    # Node: z3 = z2 - y\n    # dz3/dz2 = 1, dz3/dy = -1\n    dL_dz2 = dL_dz3 * 1\n    dL_dy = dL_dz3 * (-1)\n    print(f\"\\nNode z3 = z2 - y:\")\n    print(f\"  Local gradients: dz3/dz2 = 1, dz3/dy = -1\")\n    print(f\"  dL/dz2 = dL/dz3 x 1 = {dL_dz3} x 1 = {dL_dz2}\")\n    print(f\"  dL/dy = dL/dz3 x (-1) = {dL_dz3} x (-1) = {dL_dy}\")\n    \n    # Node: z2 = z1 + b\n    # dz2/dz1 = 1, dz2/db = 1\n    dL_dz1 = dL_dz2 * 1\n    dL_db = dL_dz2 * 1\n    print(f\"\\nNode z2 = z1 + b:\")\n    print(f\"  Local gradients: dz2/dz1 = 1, dz2/db = 1\")\n    print(f\"  dL/dz1 = dL/dz2 x 1 = {dL_dz2} x 1 = {dL_dz1}\")\n    print(f\"  dL/db = dL/dz2 x 1 = {dL_dz2} x 1 = {dL_db}\")\n    \n    # Node: z1 = w * x\n    # dz1/dw = x, dz1/dx = w\n    dL_dw = dL_dz1 * x\n    dL_dx = dL_dz1 * w\n    print(f\"\\nNode z1 = w * x:\")\n    print(f\"  Local gradients: dz1/dw = x = {x}, dz1/dx = w = {w}\")\n    print(f\"  dL/dw = dL/dz1 x x = {dL_dz1} x {x} = {dL_dw}\")\n    print(f\"  dL/dx = dL/dz1 x w = {dL_dz1} x {w} = {dL_dx}\")\n    \n    print(\"\\n\" + \"-\" * 70)\n    print(\"SUMMARY OF GRADIENTS\")\n    print(\"-\" * 70)\n    print(f\"dL/dw = {dL_dw}  <- How much changing sensitivity coefficient affects error\")\n    print(f\"dL/db = {dL_db}  <- How much changing baseline affects error\")\n    print(f\"dL/dx = {dL_dx}  <- How much changing wing angle affects error\")\n    \n    print(\"\\n\" + \"-\" * 70)\n    print(\"VERIFICATION with numerical gradients\")\n    print(\"-\" * 70)\n    h = 1e-5\n    \n    loss = lambda w, b, x, y: (w*x + b - y)**2\n    \n    dL_dw_num = (loss(w+h, b, x, y) - loss(w-h, b, x, y)) / (2*h)\n    dL_db_num = (loss(w, b+h, x, y) - loss(w, b-h, x, y)) / (2*h)\n    \n    print(f\"dL/dw: analytical = {dL_dw}, numerical = {dL_dw_num:.4f}\")\n    print(f\"dL/db: analytical = {dL_db}, numerical = {dL_db_num:.4f}\")\n    \n    return dL_dw, dL_db\n\ndL_dw, dL_db = computational_graph_example()",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "id": "cell-20"
  },
  {
   "cell_type": "markdown",
   "source": "### Deep Dive: Understanding Gradient Descent\n\nGradient descent is the **optimization engine** of deep learning. Let's build deep intuition.\n\n#### The Core Idea in Plain English\n\nYou're lost on a foggy mountainside and want to reach the lowest valley. What do you do?\n1. **Feel the slope** under your feet (compute gradient)\n2. **Take a step downhill** (move opposite to gradient)\n3. **Repeat** until you reach flat ground (gradient is zero)\n\nThat's gradient descent!\n\n**F1 analogy:** Think of this as **iterative car setup optimization**. Your team arrives at a new circuit on Friday morning with a baseline setup. Each practice session is a gradient descent step:\n1. **Run the car** and collect data (compute loss)\n2. **Analyze which setup changes** would improve lap time most (compute gradient)\n3. **Make the changes** in the direction of improvement (update parameters)\n4. **Repeat** until you've found the optimal setup (converged)\n\nThe team can't test every possible setup combination — there are too many parameters. Instead, they iteratively move \"downhill\" in setup space toward the fastest lap time.\n\n#### The Update Rule Decoded\n\n$$\\theta_{\\text{new}} = \\theta_{\\text{old}} - \\alpha \\nabla L(\\theta)$$\n\n| Component | Meaning | Mountain Analogy | F1 Analogy |\n|-----------|---------|------------------|------------|\n| $\\theta$ | Parameters (weights) | Your position on the mountain | Current car setup |\n| $\\nabla L(\\theta)$ | Gradient of loss | Which way is uphill | Which setup direction makes the car slower |\n| $-\\nabla L(\\theta)$ | Negative gradient | Which way is downhill | Which setup direction makes the car faster |\n| $\\alpha$ | Learning rate | Size of your steps | How aggressive the setup changes are |\n| $\\alpha \\nabla L(\\theta)$ | The actual step | How far you move | The actual setup adjustment made |\n\n#### The Learning Rate $\\alpha$ is Critical\n\n| Learning rate | What happens | Problem | F1 Parallel |\n|---------------|--------------|---------|-------------|\n| **Too small** | Tiny steps, very slow progress | Takes forever to converge | Conservative engineer: 0.1-degree wing changes, wastes practice sessions |\n| **Too large** | Big steps, overshoots minimum | Oscillates or diverges | Aggressive engineer: 5-degree wing changes, car oscillates between too much/too little downforce |\n| **Just right** | Steady progress, converges | Sweet spot (hard to find!) | Experienced engineer: right-sized changes that converge to optimal setup |\n\nThis is why learning rate scheduling and adaptive optimizers (Adam) are important in practice.",
   "metadata": {},
   "id": "cell-21"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def compute_gradient(f, point, h=1e-5):\n    \"\"\"Compute gradient of f at point using numerical differentiation.\n    \n    F1 context: Compute the full sensitivity vector — how does lap time\n    respond to changes in each setup parameter?\n    \"\"\"\n    point = np.array(point, dtype=float)\n    grad = np.zeros_like(point)\n    for i in range(len(point)):\n        grad[i] = partial_derivative(f, point, i, h)\n    return grad\n\n# Example: lap_time(wing, height) = wing² + height²\n# The optimal setup is at (0, 0)\ndef lap_time(p):\n    return p[0]**2 + p[1]**2\n\nsetup = np.array([3.0, 4.0])\ngrad = compute_gradient(lap_time, setup)\n\nprint(f\"Current setup (wing={setup[0]}, height={setup[1]}):\")\nprint(f\"  Lap time = {lap_time(setup)}\")\nprint(f\"  Gradient (sensitivity) = {grad}\")\nprint(f\"  Gradient magnitude = {np.linalg.norm(grad):.4f}\")\nprint(f\"\\nTo improve lap time, adjust setup by: {-grad}\")\nprint(\"(Move opposite to gradient = toward faster lap times)\")",
   "id": "cell-22"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Visualize gradient field over the setup landscape\n# F1: Each arrow shows which direction makes the car SLOWER at that setup point\ndef lap_time_2d(wing, height):\n    return wing**2 + height**2\n\n# Create grid of setup combinations\nwing_range = np.linspace(-3, 3, 15)\nheight_range = np.linspace(-3, 3, 15)\nW, H = np.meshgrid(wing_range, height_range)\n\n# Compute gradient at each setup point\nU = 2 * W  # d(lap_time)/d(wing)\nV = 2 * H  # d(lap_time)/d(height)\n\n# Normalize for better visualization\nmagnitude = np.sqrt(U**2 + V**2)\nU_norm = U / (magnitude + 1e-10)\nV_norm = V / (magnitude + 1e-10)\n\nplt.figure(figsize=(10, 8))\n\n# Contour plot (iso-lap-time lines)\nwing_fine = np.linspace(-3, 3, 100)\nheight_fine = np.linspace(-3, 3, 100)\nW_fine, H_fine = np.meshgrid(wing_fine, height_fine)\nZ_fine = lap_time_2d(W_fine, H_fine)\nplt.contour(W_fine, H_fine, Z_fine, levels=15, cmap=cm.viridis, alpha=0.5)\n\n# Gradient vectors (pointing toward slower lap times)\nplt.quiver(W, H, U_norm, V_norm, magnitude, cmap=cm.Reds, alpha=0.8)\n\nplt.xlabel('Wing Angle')\nplt.ylabel('Ride Height')\nplt.title('Gradient Field: Setup Sensitivity Landscape\\nArrows point toward SLOWER lap times — go OPPOSITE for faster!')\nplt.colorbar(label='Gradient magnitude (sensitivity)')\nplt.axis('equal')\nplt.show()\n\nprint(\"Notice: Gradients point away from the optimal setup (origin)\")\nprint(\"To find the fastest setup, follow the NEGATIVE gradient (opposite direction)\")",
   "id": "cell-23"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## 4. The Chain Rule\n\nThe **chain rule** is the foundation of backpropagation. It tells us how to differentiate composite functions.\n\n### Single Variable\n\nIf $y = f(g(x))$, then:\n\n$$\\frac{dy}{dx} = \\frac{df}{dg} \\cdot \\frac{dg}{dx}$$\n\n### Intuition\n\nIf $x$ changes by a small amount $\\Delta x$:\n- $g$ changes by $\\frac{dg}{dx} \\cdot \\Delta x$\n- This causes $f$ to change by $\\frac{df}{dg} \\cdot (\\frac{dg}{dx} \\cdot \\Delta x)$\n\nThe changes **multiply** through the chain!\n\n**F1 analogy:** The chain rule is how F1 teams trace the effect of a low-level change (like fuel mixture) through a sequence of dependencies: fuel mixture affects combustion temperature, which affects power output, which affects wheel torque, which affects lap time. Each link has its own sensitivity, and the total effect is the product of all of them.",
   "id": "cell-24"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Example: y = (3x + 2)²\n# F1: Like \"lap time = (3*fuel_load + baseline)²\"\n# Let g(x) = 3x + 2, f(g) = g²\n# dy/dx = df/dg * dg/dx = 2g * 3 = 6(3x + 2)\n\ndef y(x):\n    return (3*x + 2)**2\n\ndef dy_dx_analytical(x):\n    return 6 * (3*x + 2)\n\nfuel_load = 1.0\nprint(f\"y = (3x + 2)² at x = {fuel_load}\")\nprint(f\"  (F1: Lap time model with fuel_load = {fuel_load})\")\nprint(f\"y({fuel_load}) = {y(fuel_load)}\")\nprint(f\"dy/dx numerical:  {numerical_derivative(y, fuel_load):.6f}\")\nprint(f\"dy/dx analytical: {dy_dx_analytical(fuel_load):.6f}\")\nprint(f\"\\nF1 interpretation: At fuel_load={fuel_load}, each unit of fuel changes\")\nprint(f\"lap time by {dy_dx_analytical(fuel_load):.1f} units (chain rule in action)\")",
   "id": "cell-25"
  },
  {
   "cell_type": "code",
   "source": "# Comprehensive visualization of gradient descent behavior\n# F1: Like watching the team iterate on car setup across practice sessions\n# Shows the path, learning rate effects, and convergence\n\ndef visualize_gradient_descent_comprehensive():\n    \"\"\"\n    Create a comprehensive visualization showing:\n    1. 3D view of the lap time surface with setup optimization path\n    2. Top-down view (contour) with path\n    3. Lap time over iterations\n    4. Effect of different learning rates (setup aggressiveness)\n    \"\"\"\n    \n    # Define a lap time landscape: f(wing,height) = wing² + 10*height² (elongated bowl)\n    # Height is more sensitive than wing — common in real F1 setups\n    def f(p):\n        return p[0]**2 + 10*p[1]**2\n    \n    def grad_f(p):\n        return np.array([2*p[0], 20*p[1]])\n    \n    def gradient_descent(start, lr, n_steps):\n        point = np.array(start, dtype=float)\n        history = [point.copy()]\n        for _ in range(n_steps):\n            point = point - lr * grad_f(point)\n            history.append(point.copy())\n        return np.array(history)\n    \n    # Run setup optimization with different \"aggressiveness\" levels\n    start = [3.0, 1.0]  # Initial setup: wing=3, height=1\n    n_steps = 30\n    \n    lr_conservative = 0.01   # Very cautious engineer\n    lr_good = 0.05           # Experienced engineer\n    lr_aggressive = 0.09     # Bold engineer\n    lr_reckless = 0.11       # Too aggressive — overshoots!\n    \n    hist_conservative = gradient_descent(start, lr_conservative, n_steps)\n    hist_good = gradient_descent(start, lr_good, n_steps)\n    hist_aggressive = gradient_descent(start, lr_aggressive, n_steps)\n    hist_reckless = gradient_descent(start, lr_reckless, n_steps)\n    \n    # Create figure\n    fig = plt.figure(figsize=(16, 10))\n    \n    # Create grid for surface plots\n    x = np.linspace(-4, 4, 100)\n    y = np.linspace(-2, 2, 100)\n    X, Y = np.meshgrid(x, y)\n    Z = X**2 + 10*Y**2\n    \n    # Plot 1: 3D surface with setup optimization path\n    ax1 = fig.add_subplot(221, projection='3d')\n    ax1.plot_surface(X, Y, Z, cmap=cm.viridis, alpha=0.6)\n    \n    # Add optimization path on surface\n    path_z = [f(p) for p in hist_good]\n    ax1.plot(hist_good[:, 0], hist_good[:, 1], path_z, 'r.-', \n             markersize=8, linewidth=2, label='Setup path')\n    ax1.scatter([start[0]], [start[1]], [f(start)], color='green', s=100, marker='o')\n    ax1.scatter([0], [0], [0], color='red', s=100, marker='*')\n    \n    ax1.set_xlabel('Wing Angle')\n    ax1.set_ylabel('Ride Height')\n    ax1.set_zlabel('Lap Time')\n    ax1.set_title('3D View: Setup Optimization Path\\n(Learning rate = 0.05)')\n    \n    # Plot 2: Contour with all paths\n    ax2 = fig.add_subplot(222)\n    contour = ax2.contour(X, Y, Z, levels=20, cmap=cm.viridis)\n    ax2.clabel(contour, inline=True, fontsize=8)\n    \n    ax2.plot(hist_conservative[:, 0], hist_conservative[:, 1], 'b.-', markersize=5, \n             linewidth=1.5, label=f'lr={lr_conservative} (conservative)')\n    ax2.plot(hist_good[:, 0], hist_good[:, 1], 'g.-', markersize=5, \n             linewidth=1.5, label=f'lr={lr_good} (experienced)')\n    ax2.plot(hist_aggressive[:, 0], hist_aggressive[:, 1], 'orange', marker='.', markersize=5, \n             linewidth=1.5, label=f'lr={lr_aggressive} (aggressive)')\n    ax2.plot(hist_reckless[:, 0], hist_reckless[:, 1], 'r.-', markersize=5, \n             linewidth=1.5, label=f'lr={lr_reckless} (reckless)')\n    \n    ax2.scatter([start[0]], [start[1]], color='green', s=150, marker='o', zorder=5, label='Friday Baseline')\n    ax2.scatter([0], [0], color='red', s=150, marker='*', zorder=5, label='Optimal Setup')\n    \n    ax2.set_xlabel('Wing Angle')\n    ax2.set_ylabel('Ride Height')\n    ax2.set_title('Top View: Different Engineer Strategies')\n    ax2.legend(loc='upper right', fontsize=9)\n    ax2.set_aspect('equal')\n    \n    # Plot 3: Lap time curves\n    ax3 = fig.add_subplot(223)\n    \n    losses_conservative = [f(p) for p in hist_conservative]\n    losses_good = [f(p) for p in hist_good]\n    losses_aggressive = [f(p) for p in hist_aggressive]\n    losses_reckless = [f(p) for p in hist_reckless]\n    \n    ax3.plot(losses_conservative, 'b-', linewidth=2, label=f'lr={lr_conservative}')\n    ax3.plot(losses_good, 'g-', linewidth=2, label=f'lr={lr_good}')\n    ax3.plot(losses_aggressive, color='orange', linewidth=2, label=f'lr={lr_aggressive}')\n    ax3.plot(losses_reckless, 'r-', linewidth=2, label=f'lr={lr_reckless}')\n    \n    ax3.set_xlabel('Practice Session (Iteration)')\n    ax3.set_ylabel('Lap Time')\n    ax3.set_title('Lap Time Improvement Over Sessions')\n    ax3.legend()\n    ax3.set_yscale('log')\n    ax3.grid(True, alpha=0.3)\n    \n    # Plot 4: Zoomed in first few steps\n    ax4 = fig.add_subplot(224)\n    \n    # Show step-by-step for good learning rate\n    for i in range(min(8, len(hist_good)-1)):\n        p1 = hist_good[i]\n        p2 = hist_good[i+1]\n        grad = grad_f(p1)\n        \n        # Point\n        ax4.scatter([p1[0]], [p1[1]], color='blue', s=60, zorder=5)\n        ax4.annotate(f'{i}', xy=(p1[0], p1[1]), xytext=(p1[0]+0.1, p1[1]+0.1), fontsize=9)\n        \n        # Gradient (scaled for visualization)\n        ax4.arrow(p1[0], p1[1], -grad[0]*0.02, -grad[1]*0.02, \n                 head_width=0.05, head_length=0.02, fc='red', ec='red', alpha=0.5)\n        \n        # Actual step\n        ax4.arrow(p1[0], p1[1], (p2[0]-p1[0])*0.95, (p2[1]-p1[1])*0.95,\n                 head_width=0.05, head_length=0.02, fc='green', ec='green')\n    \n    contour2 = ax4.contour(X, Y, Z, levels=20, cmap=cm.viridis, alpha=0.5)\n    ax4.set_xlabel('Wing Angle')\n    ax4.set_ylabel('Ride Height')\n    ax4.set_title('Step-by-Step Setup Changes (lr=0.05)\\nGreen: actual changes, Red: gradient direction')\n    ax4.set_xlim([-1, 4])\n    ax4.set_ylim([-0.5, 1.5])\n    \n    plt.tight_layout()\n    plt.show()\n    \n    print(\"Key observations (F1 setup optimization):\")\n    print(f\"- lr={lr_conservative} (conservative): Too cautious — wastes practice sessions\")\n    print(f\"- lr={lr_good} (experienced): Efficient — reaches optimal setup quickly\")\n    print(f\"- lr={lr_aggressive} (aggressive): Oscillates but finds the neighborhood\")\n    print(f\"- lr={lr_reckless} (reckless): Overshoots wildly — car gets worse before better!\")\n\nvisualize_gradient_descent_comprehensive()",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "id": "cell-26"
  },
  {
   "cell_type": "markdown",
   "source": "### The Local Minima Problem\n\nReal loss surfaces are rarely simple bowls. They often have:\n- **Local minima**: Points that look like minima locally but aren't the global best\n- **Saddle points**: Points where gradient is zero but it's neither min nor max\n- **Plateaus**: Flat regions where gradient is tiny\n\n**F1 analogy:** This is the classic \"good enough\" setup trap. Your team finds a setup that feels fast — the car is balanced, the driver is happy, and small tweaks make it slower. But there might be a completely different setup philosophy (say, switching from high-downforce to low-downforce) that's actually faster overall. You've found a **local minimum** — a setup that's locally optimal but not globally. Getting out requires a big, bold change (like momentum in gradient descent) or starting from a different baseline entirely.\n\nNeural networks have extremely complex loss landscapes. Fortunately:\n1. In high dimensions, true local minima are rare (saddle points are more common)\n2. Many local minima have similar loss values\n3. Modern optimizers (Adam, etc.) can escape shallow local minima",
   "metadata": {},
   "id": "cell-27"
  },
  {
   "cell_type": "code",
   "source": "# Visualize local minima, saddle points, and the challenges they pose\n# F1: Multiple \"fast\" setups exist — but which is THE fastest?\n\ndef visualize_local_minima_problem():\n    \"\"\"\n    Visualize a lap time landscape with multiple local minima\n    and show how gradient descent can get stuck in a \"good enough\" setup.\n    \"\"\"\n    \n    # Create a function with multiple local minima\n    # f(x) = sin(x) + 0.1*x² (creates multiple valleys — multiple \"fast\" setups)\n    def f_1d(x):\n        return np.sin(3*x) + 0.1*x**2\n    \n    def df_1d(x):\n        return 3*np.cos(3*x) + 0.2*x\n    \n    # 1D visualization\n    fig, axes = plt.subplots(1, 3, figsize=(16, 4))\n    \n    x = np.linspace(-4, 4, 200)\n    y = f_1d(x)\n    \n    axes[0].plot(x, y, 'b-', linewidth=2)\n    axes[0].set_xlabel('Setup Parameter')\n    axes[0].set_ylabel('Lap Time')\n    axes[0].set_title('Lap Time Landscape with Multiple \"Fast\" Setups')\n    axes[0].grid(True, alpha=0.3)\n    \n    # Mark local minima (where derivative crosses zero from - to +)\n    for xi in np.linspace(-4, 4, 1000):\n        if abs(df_1d(xi)) < 0.05 and f_1d(xi-0.01) > f_1d(xi) < f_1d(xi+0.01):\n            axes[0].scatter([xi], [f_1d(xi)], color='red', s=100, marker='v', zorder=5)\n    \n    axes[0].annotate('Fastest\\nsetup', xy=(-2.1, f_1d(-2.1)), xytext=(-3, 1),\n                    arrowprops=dict(arrowstyle='->', color='green'), fontsize=10, color='green')\n    axes[0].annotate('\"Good enough\"\\nsetup', xy=(0.0, f_1d(0.0)), xytext=(1, 1.5),\n                    arrowprops=dict(arrowstyle='->', color='red'), fontsize=10, color='red')\n    \n    # Run GD from different starting setups\n    def gd_1d(x0, lr=0.1, n_steps=50):\n        x = x0\n        history = [x]\n        for _ in range(n_steps):\n            x = x - lr * df_1d(x)\n            history.append(x)\n        return np.array(history)\n    \n    starts = [-3.5, -1.0, 1.5, 3.0]\n    colors = ['green', 'red', 'orange', 'purple']\n    \n    axes[1].plot(x, y, 'b-', linewidth=2, alpha=0.5)\n    for start, color in zip(starts, colors):\n        hist = gd_1d(start, lr=0.05, n_steps=100)\n        y_hist = f_1d(hist)\n        axes[1].plot(hist, y_hist, '.-', color=color, markersize=4, \n                    linewidth=1, label=f'Start={start}')\n        axes[1].scatter([start], [f_1d(start)], color=color, s=100, marker='o', zorder=5)\n    \n    axes[1].set_xlabel('Setup Parameter')\n    axes[1].set_ylabel('Lap Time')\n    axes[1].set_title('Optimization from Different Friday Baselines')\n    axes[1].legend(fontsize=9)\n    axes[1].grid(True, alpha=0.3)\n    \n    # Show final lap times\n    final_times = []\n    for start in starts:\n        hist = gd_1d(start, lr=0.05, n_steps=100)\n        final_times.append(f_1d(hist[-1]))\n    \n    axes[2].bar(range(len(starts)), final_times, color=colors)\n    axes[2].set_xticks(range(len(starts)))\n    axes[2].set_xticklabels([f'Start={s}' for s in starts])\n    axes[2].set_xlabel('Friday Baseline Setup')\n    axes[2].set_ylabel('Final Lap Time')\n    axes[2].set_title('Final Lap Time Depends on Starting Setup!\\n(Different baselines = different local optima)')\n    axes[2].grid(True, alpha=0.3, axis='y')\n    \n    plt.tight_layout()\n    plt.show()\n    \n    print(\"Key insight: Gradient descent finds LOCAL optima, not necessarily the GLOBAL optimum.\")\n    print(\"The final setup depends on where you started!\")\n    print(\"\\nF1 strategies to escape local minima:\")\n    print(\"1. Try multiple baseline setups on Friday (multiple random starts)\")\n    print(\"2. Use momentum to 'carry speed' past shallow local minima\")\n    print(\"3. Add randomness (SGD noise = trying random setup experiments)\")\n    print(\"4. Use learning rate schedules (big changes early, fine-tuning later)\")\n\nvisualize_local_minima_problem()",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "id": "cell-28"
  },
  {
   "cell_type": "code",
   "source": "# Visualize saddle points in 2D\n# F1: A setup where one parameter is optimized but another isn't —\n# e.g., wing angle is perfect but ride height is wrong\n\ndef visualize_saddle_point():\n    \"\"\"\n    Visualize a saddle point and why it's problematic for gradient descent.\n    F1: Like a setup that's optimal for straight-line speed but terrible for corners.\n    \"\"\"\n    # Classic saddle: f(x,y) = x² - y²\n    def f_saddle(x, y):\n        return x**2 - y**2\n    \n    def grad_saddle(p):\n        return np.array([2*p[0], -2*p[1]])\n    \n    fig = plt.figure(figsize=(16, 5))\n    \n    # Create grid\n    x = np.linspace(-2, 2, 100)\n    y = np.linspace(-2, 2, 100)\n    X, Y = np.meshgrid(x, y)\n    Z = f_saddle(X, Y)\n    \n    # 3D surface\n    ax1 = fig.add_subplot(131, projection='3d')\n    ax1.plot_surface(X, Y, Z, cmap=cm.coolwarm, alpha=0.8)\n    ax1.scatter([0], [0], [0], color='black', s=200, marker='o')\n    ax1.set_xlabel('Wing Angle')\n    ax1.set_ylabel('Ride Height')\n    ax1.set_zlabel('Lap Time')\n    ax1.set_title('Saddle Point: f = wing² - height²\\nOptimal in one dimension, not the other')\n    \n    # Contour plot\n    ax2 = fig.add_subplot(132)\n    contour = ax2.contour(X, Y, Z, levels=20, cmap=cm.coolwarm)\n    ax2.clabel(contour, inline=True, fontsize=8)\n    ax2.scatter([0], [0], color='black', s=200, marker='o', label='Saddle point')\n    \n    # Draw gradient arrows around saddle point\n    for px, py in [(0.5, 0), (-0.5, 0), (0, 0.5), (0, -0.5)]:\n        grad = grad_saddle([px, py])\n        ax2.arrow(px, py, -grad[0]*0.15, -grad[1]*0.15, head_width=0.05, \n                 head_length=0.02, fc='green', ec='green')\n    \n    ax2.set_xlabel('Wing Angle')\n    ax2.set_ylabel('Ride Height')\n    ax2.set_title('Setup Space Contours\\nGreen arrows: negative gradient direction')\n    ax2.legend()\n    ax2.set_aspect('equal')\n    \n    # 1D slices through saddle point\n    ax3 = fig.add_subplot(133)\n    x_slice = np.linspace(-2, 2, 100)\n    ax3.plot(x_slice, x_slice**2, 'b-', linewidth=2, label='Vary wing only: minimum')\n    ax3.plot(x_slice, -x_slice**2, 'r-', linewidth=2, label='Vary height only: maximum')\n    ax3.axhline(y=0, color='k', linewidth=0.5)\n    ax3.axvline(x=0, color='k', linewidth=0.5)\n    ax3.scatter([0], [0], color='black', s=100, zorder=5)\n    ax3.set_xlabel('Parameter Value')\n    ax3.set_ylabel('Lap Time')\n    ax3.set_title('1D Slices Through Saddle\\nSame point is min AND max!')\n    ax3.legend()\n    ax3.grid(True, alpha=0.3)\n    \n    plt.tight_layout()\n    plt.show()\n    \n    print(\"At a saddle point:\")\n    print(\"- Gradient is zero (looks like an optimum)\")\n    print(\"- But it's a minimum in some directions, maximum in others\")\n    print(\"- GD can get stuck here if approaching from certain directions\")\n    print(\"\\nF1 analogy: A setup where wing angle is perfect but ride height\")\n    print(\"is all wrong. The engineer who only looks at wing data thinks\")\n    print(\"the car is optimized — but changing ride height would unlock more pace!\")\n    print(\"\\nIn high-dimensional neural network loss landscapes:\")\n    print(\"- Saddle points are MUCH more common than local minima\")\n    print(\"- Momentum helps escape saddle points by building up velocity\")\n\nvisualize_saddle_point()",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "id": "cell-29"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Chain Rule in Neural Networks\n\nConsider a simple network:\n\n$$\\text{Input } x \\rightarrow z = wx + b \\rightarrow a = \\sigma(z) \\rightarrow L = (a - y)^2$$\n\nTo find $\\frac{\\partial L}{\\partial w}$, we apply the chain rule:\n\n$$\\frac{\\partial L}{\\partial w} = \\frac{\\partial L}{\\partial a} \\cdot \\frac{\\partial a}{\\partial z} \\cdot \\frac{\\partial z}{\\partial w}$$\n\n**F1 analogy:** This is like tracing: \"How does changing a suspension spring rate (w) affect the ride dynamics (z), which affects the tire contact patch (a), which affects the lap time (L)?\" Each link has its own sensitivity, and we multiply them all together to get the total effect of the spring rate on lap time.",
   "id": "cell-30"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Computational graph example\n# Forward pass: x -> z = wx + b -> a = sigmoid(z) -> L = (a - y)²\n# F1: wing_angle -> aero_force = w*wing + bias -> grip = sigmoid(aero) -> lap_time_error\n\ndef forward_and_backward(x, y_true, w, b):\n    \"\"\"Compute forward pass and gradients using chain rule.\n    \n    F1 parallel: Trace how a setup parameter flows through a performance\n    model and back again to find sensitivities.\n    \"\"\"\n    \n    # Forward pass\n    z = w * x + b\n    a = sigmoid(z)\n    L = (a - y_true)**2\n    \n    print(\"=== Forward Pass (Setup -> Performance -> Lap Time Error) ===\")\n    print(f\"x (wing angle) = {x}\")\n    print(f\"z = w*x + b = {w}*{x} + {b} = {z}\")\n    print(f\"a = sigmoid(z) = {a:.6f}\")\n    print(f\"L = (a - y_target)² = ({a:.6f} - {y_true})² = {L:.6f}\")\n    \n    # Backward pass (chain rule)\n    print(\"\\n=== Backward Pass (Chain Rule: Tracing Sensitivities Back) ===\")\n    \n    # dL/da\n    dL_da = 2 * (a - y_true)\n    print(f\"dL/da = 2(a - y) = {dL_da:.6f}\")\n    \n    # da/dz (sigmoid derivative)\n    da_dz = a * (1 - a)\n    print(f\"da/dz = sigmoid(z)(1 - sigmoid(z)) = {da_dz:.6f}\")\n    \n    # dz/dw\n    dz_dw = x\n    print(f\"dz/dw = x = {dz_dw}\")\n    \n    # dz/db\n    dz_db = 1\n    print(f\"dz/db = 1\")\n    \n    # Chain rule\n    dL_dz = dL_da * da_dz\n    dL_dw = dL_dz * dz_dw\n    dL_db = dL_dz * dz_db\n    \n    print(f\"\\ndL/dw = dL/da * da/dz * dz/dw = {dL_dw:.6f}\")\n    print(f\"dL/db = dL/da * da/dz * dz/db = {dL_db:.6f}\")\n    \n    return L, dL_dw, dL_db\n\n# Example\nx = 2.0\ny_true = 1.0\nw = 0.5\nb = 0.1\n\nL, dL_dw, dL_db = forward_and_backward(x, y_true, w, b)",
   "id": "cell-31"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Verify with numerical gradient — the \"sanity check\" every engineer should do\nh = 1e-5\n\ndef loss(w, b, x=2.0, y=1.0):\n    z = w * x + b\n    a = sigmoid(z)\n    return (a - y)**2\n\n# Numerical gradients\ndL_dw_numerical = (loss(w + h, b) - loss(w - h, b)) / (2 * h)\ndL_db_numerical = (loss(w, b + h) - loss(w, b - h)) / (2 * h)\n\nprint(\"Verification with numerical gradients (the engineer's double-check):\")\nprint(f\"dL/dw: analytical = {dL_dw:.6f}, numerical = {dL_dw_numerical:.6f}\")\nprint(f\"dL/db: analytical = {dL_db:.6f}, numerical = {dL_db_numerical:.6f}\")",
   "id": "cell-32"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Multivariate Chain Rule\n\nWhen a variable affects the output through multiple paths:\n\n$$\\frac{\\partial L}{\\partial x} = \\sum_{i} \\frac{\\partial L}{\\partial y_i} \\cdot \\frac{\\partial y_i}{\\partial x}$$\n\nThis is why we **sum** gradients when a variable is used multiple times.\n\n**F1 analogy:** Tire pressure affects lap time through multiple paths simultaneously — it changes both straight-line grip AND cornering grip AND tire wear rate. The total effect of tire pressure on lap time is the **sum** of its effects through each path. This is the multivariate chain rule in action.",
   "id": "cell-33"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Example: f = x*y + x*z where y and z both depend on x\n# F1: Tire pressure (x) affects cornering (x*y path) AND straight-line (x*z path)\n# Actually, let's do: f(x) = x² + x (x is used twice)\n\n# Computational graph:\n# x --> a = x  --\\\n#                 +--> c = a * b --> f = c + d\n# x --> b = x  --/                      |\n#                                       |\n# x --> d = x  -------------------------/\n\n# This is: f = x*x + x = x² + x\n# df/dx = 2x + 1 (by calculus)\n\n# But through the graph:\n# df/dx = df/dc * dc/da * da/dx + df/dc * dc/db * db/dx + df/dd * dd/dx\n#       = 1 * b * 1 + 1 * a * 1 + 1 * 1\n#       = x + x + 1 = 2x + 1\n\ntire_pressure = 3.0\nprint(f\"f(x) = x² + x at x = {tire_pressure}\")\nprint(f\"F1: Total lap time effect when tire pressure appears in multiple paths\")\nprint(f\"f({tire_pressure}) = {tire_pressure**2 + tire_pressure}\")\nprint(f\"df/dx (analytical) = 2x + 1 = {2*tire_pressure + 1}\")\n\n# Through computational graph — summing all paths\na = tire_pressure\nb = tire_pressure  \nc = a * b  # = x² (cornering effect)\nd = tire_pressure  # (straight-line effect)\nf = c + d  # = x² + x (total)\n\n# Backward — sum gradients from all paths\ndf_dc = 1\ndf_dd = 1\ndc_da = b  # = x\ndc_db = a  # = x\nda_dx = 1\ndb_dx = 1\ndd_dx = 1\n\n# Sum all paths from f to x\ndf_dx = df_dc * dc_da * da_dx + df_dc * dc_db * db_dx + df_dd * dd_dx\nprint(f\"df/dx (computational graph, summing paths) = {df_dx}\")\nprint(f\"\\nKey: We SUM the contributions from each path x takes through the graph\")",
   "id": "cell-34"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## 5. Gradient Descent\n\n**Gradient descent** is the optimization algorithm that powers deep learning:\n\n$$\\theta_{\\text{new}} = \\theta_{\\text{old}} - \\alpha \\nabla L(\\theta)$$\n\nWhere:\n- $\\theta$: Parameters (weights)\n- $\\alpha$: Learning rate (step size)\n- $\\nabla L$: Gradient of loss with respect to parameters\n\n**F1 analogy:** This is the mathematical version of what every F1 team does during a race weekend. $\\theta$ is the car setup. $L(\\theta)$ is the lap time. $\\nabla L$ tells you which parameters to change and by how much. $\\alpha$ controls how aggressive those changes are. Each practice session is an iteration of gradient descent, moving the setup toward the fastest possible lap time.",
   "id": "cell-35"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def gradient_descent_1d(f, df, x0, learning_rate=0.1, n_steps=50):\n    \"\"\"Gradient descent for 1D function.\n    \n    F1: Iteratively adjust a single setup parameter to minimize lap time.\n    \"\"\"\n    x = x0\n    history = [(x, f(x))]\n    \n    for i in range(n_steps):\n        grad = df(x)\n        x = x - learning_rate * grad\n        history.append((x, f(x)))\n        \n    return x, history\n\n# Minimize f(x) = (x - 3)² — optimal setup parameter is at x=3\n# F1: \"Find the optimal brake bias setting\"\nf = lambda x: (x - 3)**2\ndf = lambda x: 2 * (x - 3)\n\nbrake_bias_final, history = gradient_descent_1d(f, df, x0=10.0, learning_rate=0.1, n_steps=30)\n\nprint(f\"Brake bias optimization:\")\nprint(f\"  Starting value: 10.0\")\nprint(f\"  Optimal found:  {brake_bias_final:.6f}\")\nprint(f\"  Lap time at optimum: {f(brake_bias_final):.6f}\")\nprint(f\"  True optimum: x = 3\")\n\n# Visualize\nx_range = np.linspace(-2, 12, 100)\nplt.figure(figsize=(12, 4))\n\nplt.subplot(1, 2, 1)\nplt.plot(x_range, f(x_range), 'b-', linewidth=2, label='Lap time = (brake_bias - 3)²')\nxs, ys = zip(*history)\nplt.scatter(xs, ys, c=range(len(xs)), cmap='Reds', s=50, zorder=5)\nplt.plot(xs, ys, 'r--', alpha=0.5)\nplt.xlabel('Brake Bias Setting')\nplt.ylabel('Lap Time Penalty')\nplt.title('Gradient Descent: Finding Optimal Brake Bias')\nplt.legend()\nplt.colorbar(label='Iteration (Practice Run)')\n\nplt.subplot(1, 2, 2)\nplt.plot([h[1] for h in history], 'b-o')\nplt.xlabel('Practice Run (Iteration)')\nplt.ylabel('Lap Time Penalty')\nplt.title('Lap Time Improvement Over Runs')\n\nplt.tight_layout()\nplt.show()",
   "id": "cell-36"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 2D Gradient Descent\n\nNow let's optimize two setup parameters simultaneously — this is where the gradient (not just the derivative) comes in. The gradient tells us the optimal combined direction to adjust **both** parameters at once.",
   "id": "cell-37"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def gradient_descent_2d(f, grad_f, start, learning_rate=0.1, n_steps=50):\n    \"\"\"Gradient descent for 2D function.\n    \n    F1: Simultaneously optimize two setup parameters (e.g., wing angle and ride height).\n    \"\"\"\n    point = np.array(start, dtype=float)\n    history = [point.copy()]\n    \n    for i in range(n_steps):\n        grad = grad_f(point)\n        point = point - learning_rate * grad\n        history.append(point.copy())\n        \n    return point, np.array(history)\n\n# Minimize lap_time(wing, height) = wing² + height²\n# Optimal setup at (0, 0)\ndef f(p):\n    return p[0]**2 + p[1]**2\n\ndef grad_f(p):\n    return np.array([2*p[0], 2*p[1]])\n\nstart = [4.0, 3.0]  # Friday morning baseline setup\nfinal, history = gradient_descent_2d(f, grad_f, start, learning_rate=0.1, n_steps=30)\n\nprint(f\"Friday baseline setup: wing={start[0]}, height={start[1]}\")\nprint(f\"Optimal setup found:   wing={final[0]:.6f}, height={final[1]:.6f}\")\nprint(f\"Final lap time: {f(final):.10f}\")\n\n# Visualize the setup optimization path\nx = np.linspace(-5, 5, 100)\ny = np.linspace(-5, 5, 100)\nX, Y = np.meshgrid(x, y)\nZ = X**2 + Y**2\n\nplt.figure(figsize=(10, 8))\nplt.contour(X, Y, Z, levels=20, cmap=cm.viridis)\nplt.plot(history[:, 0], history[:, 1], 'r.-', markersize=10, linewidth=2)\nplt.scatter([start[0]], [start[1]], color='green', s=200, marker='o', label='Friday Baseline', zorder=5)\nplt.scatter([final[0]], [final[1]], color='red', s=200, marker='*', label='Optimal Setup', zorder=5)\nplt.xlabel('Wing Angle')\nplt.ylabel('Ride Height')\nplt.title('Gradient Descent: Finding Optimal Car Setup\\nlap_time(wing, height) = wing² + height²')\nplt.legend()\nplt.colorbar(label='Lap Time')\nplt.axis('equal')\nplt.show()",
   "id": "cell-38"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Effect of Learning Rate\n\n**F1 analogy:** The learning rate is the engineer's **aggressiveness dial**. How big a setup change do you make between runs? Too small and you waste precious practice time making imperceptible changes. Too large and the car oscillates between being too stiff and too soft, never settling on the optimum.",
   "id": "cell-39"
  },
  {
   "cell_type": "markdown",
   "source": "### Calculus Concepts and Their ML Applications\n\n| Calculus Concept | What it Means | ML Application | F1 Parallel |\n|------------------|---------------|----------------|-------------|\n| **Derivative** | Rate of change of output w.r.t. input | How loss changes when we change one weight | How lap time changes when we adjust wing angle |\n| **Partial Derivative** | Rate of change w.r.t. one variable (others fixed) | Gradient component for one parameter | Effect of changing ONLY ride height on lap time |\n| **Gradient** | Vector of all partial derivatives | Direction to update ALL weights at once | Complete sensitivity report for all setup parameters |\n| **Chain Rule** | Derivative of composed functions = product of derivatives | Backpropagation through network layers | How engine power flows through drivetrain to affect speed |\n| **Gradient Descent** | Iteratively move opposite to gradient | Core training algorithm for neural networks | Iterative car setup optimization across practice sessions |\n| **Learning Rate** | Step size in gradient descent | Hyperparameter controlling training speed | How aggressive setup changes are between runs |\n| **Local Minimum** | Point where gradient = 0 and function curves up | Where training might get stuck | A \"good enough\" setup that isn't actually the fastest |\n| **Saddle Point** | Point where gradient = 0 but not min or max | Common in high-dim; momentum helps escape | Setup optimal in one dimension but not others |\n\n### The Full Picture: How a Neural Network Learns\n\n1. **Forward pass**: Input flows through network, computing activations layer by layer\n2. **Loss computation**: Compare output to target, get a single number (the loss)\n3. **Backward pass**: Use chain rule to compute gradient of loss w.r.t. every weight\n4. **Parameter update**: Use gradient descent to update all weights\n5. **Repeat**: Until loss is small enough\n\n**F1 parallel:** This is exactly the race weekend workflow:\n1. **Run the car** (forward pass through the physics of the track)\n2. **Check the lap time** (compute the loss)\n3. **Analyze telemetry** to find what to change (backward pass / gradient computation)\n4. **Adjust the setup** (parameter update via gradient descent)\n5. **Run again** (repeat until qualifying)",
   "metadata": {},
   "id": "cell-40"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Compare different learning rates — the engineer's aggressiveness dial\nlearning_rates = [0.01, 0.1, 0.5, 0.95]\ncolors = ['blue', 'green', 'orange', 'red']\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\n# Contour plot with paths\nx = np.linspace(-5, 5, 100)\ny = np.linspace(-5, 5, 100)\nX, Y = np.meshgrid(x, y)\nZ = X**2 + Y**2\n\naxes[0].contour(X, Y, Z, levels=20, cmap=cm.viridis, alpha=0.5)\n\nfor lr, color in zip(learning_rates, colors):\n    final, history = gradient_descent_2d(f, grad_f, [4.0, 3.0], learning_rate=lr, n_steps=20)\n    axes[0].plot(history[:, 0], history[:, 1], '.-', color=color, markersize=8, \n                 linewidth=2, label=f'lr={lr}')\n    \n    # Lap time curve\n    losses = [f(p) for p in history]\n    axes[1].plot(losses, color=color, linewidth=2, label=f'lr={lr}')\n\naxes[0].set_xlabel('Wing Angle')\naxes[0].set_ylabel('Ride Height')\naxes[0].set_title('Setup Optimization Paths\\n(Different Engineer Aggressiveness)')\naxes[0].legend()\naxes[0].axis('equal')\n\naxes[1].set_xlabel('Practice Run (Iteration)')\naxes[1].set_ylabel('Lap Time')\naxes[1].set_title('Lap Time Convergence')\naxes[1].legend()\naxes[1].set_yscale('log')\n\nplt.tight_layout()\nplt.show()\n\nprint(\"F1 observations on learning rate (engineer aggressiveness):\")\nprint(\"- Too small (0.01): Conservative — wastes practice sessions, slow to find pace\")\nprint(\"- Good (0.1): Experienced — steady progress toward optimal setup\")\nprint(\"- Larger (0.5): Bold — finds neighborhood fast but oscillates around it\")\nprint(\"- Too large (0.95): Reckless — car swings wildly between extremes\")",
   "id": "cell-41"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### A More Challenging Function: Rosenbrock\n\nThe Rosenbrock function is a classic optimization test:\n\n$$f(x, y) = (1 - x)^2 + 100(y - x^2)^2$$\n\nMinimum at $(1, 1)$. Famous for its narrow, curved valley.\n\n**F1 analogy:** This is like a setup landscape with a narrow \"sweet spot\" — a long, winding valley of decent performance but only one truly optimal point. Think of it like the Monaco setup window: there's a narrow corridor of setups that work, and the optimal point requires precise tuning of correlated parameters (wing angle and ride height that depend on each other). This is why simple gradient descent struggles and why adaptive optimizers (like Adam in ML, or experienced engineers in F1) are so valuable.",
   "id": "cell-42"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def rosenbrock(p):\n    x, y = p\n    return (1 - x)**2 + 100 * (y - x**2)**2\n\ndef rosenbrock_grad(p):\n    x, y = p\n    dx = -2*(1 - x) - 400*x*(y - x**2)\n    dy = 200*(y - x**2)\n    return np.array([dx, dy])\n\n# Visualize the Rosenbrock \"Monaco setup landscape\"\nx = np.linspace(-2, 2, 200)\ny = np.linspace(-1, 3, 200)\nX, Y = np.meshgrid(x, y)\nZ = (1 - X)**2 + 100 * (Y - X**2)**2\n\nplt.figure(figsize=(10, 8))\nplt.contour(X, Y, Z, levels=np.logspace(0, 3, 30), cmap=cm.viridis)\nplt.scatter([1], [1], color='red', s=200, marker='*', label='Optimal Setup (1,1)', zorder=5)\nplt.xlabel('Wing Angle')\nplt.ylabel('Ride Height')\nplt.title('The Rosenbrock \"Monaco\" Setup Landscape\\nNotice the narrow curved valley — hard to optimize!')\nplt.colorbar(label='Lap Time')\nplt.legend()\nplt.show()",
   "id": "cell-43"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Gradient descent on Rosenbrock (challenging! — like optimizing a Monaco setup)\nstart = [-1.0, 1.0]\nfinal, history = gradient_descent_2d(rosenbrock, rosenbrock_grad, start, \n                                      learning_rate=0.001, n_steps=5000)\n\nprint(f\"Starting setup: {start}\")\nprint(f\"Final setup:    [{final[0]:.4f}, {final[1]:.4f}]\")\nprint(f\"Lap time at final: {rosenbrock(final):.6f}\")\nprint(f\"True optimal setup: (1, 1), lap_time = 0\")\n\n# Visualize\nplt.figure(figsize=(12, 5))\n\nplt.subplot(1, 2, 1)\nplt.contour(X, Y, Z, levels=np.logspace(0, 3, 30), cmap=cm.viridis, alpha=0.5)\nplt.plot(history[::50, 0], history[::50, 1], 'r.-', markersize=5, linewidth=1)  # Every 50th point\nplt.scatter([start[0]], [start[1]], color='green', s=100, marker='o', label='Friday Baseline', zorder=5)\nplt.scatter([final[0]], [final[1]], color='red', s=100, marker='*', label='Final Setup', zorder=5)\nplt.xlabel('Wing Angle')\nplt.ylabel('Ride Height')\nplt.title('Setup Optimization on Rosenbrock (Monaco)')\nplt.legend()\n\nplt.subplot(1, 2, 2)\nlosses = [rosenbrock(p) for p in history[::10]]\nplt.plot(losses)\nplt.xlabel('Iteration (x10)')\nplt.ylabel('Lap Time')\nplt.title('Lap Time Over Optimization Steps')\nplt.yscale('log')\n\nplt.tight_layout()\nplt.show()\n\nprint(\"\\nNote: Simple gradient descent struggles with narrow valleys!\")\nprint(\"F1: This is why experienced engineers and advanced tools are needed\")\nprint(\"for circuits like Monaco with tight setup windows.\")\nprint(\"More advanced optimizers (Adam, etc.) handle this better.\")",
   "id": "cell-44"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## 6. Putting It Together: Training a Linear Model\n\nLet's train a simple linear regression model using gradient descent.\n\n**F1 scenario:** We're building a simple model to predict lap time from fuel load. The relationship is roughly linear: heavier fuel means slower laps. We'll use gradient descent to find the best-fit line — exactly how a team might calibrate their performance model from practice data.",
   "id": "cell-45"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Generate synthetic F1 data: lap time vs fuel load\nnp.random.seed(42)\nn_laps = 100\n\n# True parameters: each kg of fuel adds ~0.035s per lap, baseline time is 1:30.000\n# We'll use scaled values for numerical convenience\nfuel_effect_true = 2.5    # scaled fuel-to-laptime sensitivity\nbaseline_time_true = 1.0  # scaled baseline lap time\n\n# Generate data: lap_time = fuel_effect * fuel_load + baseline + noise\nfuel_load = np.random.uniform(-3, 3, n_laps)  # centered fuel load values\nlap_time = fuel_effect_true * fuel_load + baseline_time_true + np.random.normal(0, 0.5, n_laps)\n\nplt.figure(figsize=(10, 6))\nplt.scatter(fuel_load, lap_time, alpha=0.6, label='Practice lap data')\nplt.plot(fuel_load, fuel_effect_true * fuel_load + baseline_time_true, 'r-', linewidth=2, \n         label=f'True model: time = {fuel_effect_true}*fuel + {baseline_time_true}')\nplt.xlabel('Fuel Load (centered)')\nplt.ylabel('Lap Time (scaled)')\nplt.title('F1 Practice Data: Lap Time vs Fuel Load\\n(Each dot = one practice lap)')\nplt.legend()\nplt.show()",
   "id": "cell-46"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def train_fuel_model(X, y, learning_rate=0.01, n_epochs=100):\n    \"\"\"\n    Train a linear fuel-to-laptime model using gradient descent.\n    \n    Model: predicted_time = w * fuel_load + b\n    Loss: MSE = (1/n) * sum((predicted_time - actual_time)^2)\n    \n    F1 context: The team wants to learn the fuel effect coefficient\n    and baseline lap time from practice data.\n    \"\"\"\n    n = len(X)\n    \n    # Initialize parameters (start with no knowledge)\n    w = 0.0  # fuel effect coefficient\n    b = 0.0  # baseline time\n    \n    history = {'loss': [], 'w': [], 'b': []}\n    \n    for epoch in range(n_epochs):\n        # Forward pass: predict lap times\n        y_pred = w * X + b\n        \n        # Compute loss (MSE — how wrong are our predictions?)\n        loss = np.mean((y_pred - y)**2)\n        \n        # Compute gradients (which direction improves the model?)\n        # d(loss)/dw = (2/n) * sum((y_pred - y) * x)\n        # d(loss)/db = (2/n) * sum(y_pred - y)\n        dw = (2/n) * np.sum((y_pred - y) * X)\n        db = (2/n) * np.sum(y_pred - y)\n        \n        # Update parameters (gradient descent step)\n        w = w - learning_rate * dw\n        b = b - learning_rate * db\n        \n        # Record history\n        history['loss'].append(loss)\n        history['w'].append(w)\n        history['b'].append(b)\n        \n        if epoch % 20 == 0:\n            print(f\"Epoch {epoch:3d}: loss = {loss:.4f}, fuel_effect = {w:.4f}, baseline = {b:.4f}\")\n    \n    return w, b, history\n\n# Train the fuel model\nw_learned, b_learned, history = train_fuel_model(fuel_load, lap_time, learning_rate=0.1, n_epochs=100)\n\nprint(f\"\\nLearned: fuel_effect = {w_learned:.4f}, baseline = {b_learned:.4f}\")\nprint(f\"True:    fuel_effect = {fuel_effect_true:.4f}, baseline = {baseline_time_true:.4f}\")\nprint(f\"\\nThe model successfully learned the fuel correction from practice data!\")",
   "id": "cell-47"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Visualize the training process\nfig, axes = plt.subplots(1, 3, figsize=(15, 4))\n\n# Loss curve\naxes[0].plot(history['loss'])\naxes[0].set_xlabel('Training Epoch')\naxes[0].set_ylabel('MSE Loss')\naxes[0].set_title('Prediction Error Over Training')\n\n# Parameter trajectory\naxes[1].plot(history['w'], label='fuel_effect (w)')\naxes[1].plot(history['b'], label='baseline (b)')\naxes[1].axhline(y=fuel_effect_true, color='blue', linestyle='--', alpha=0.5, \n                label=f'true fuel_effect={fuel_effect_true}')\naxes[1].axhline(y=baseline_time_true, color='orange', linestyle='--', alpha=0.5, \n                label=f'true baseline={baseline_time_true}')\naxes[1].set_xlabel('Training Epoch')\naxes[1].set_ylabel('Parameter Value')\naxes[1].set_title('Parameter Convergence\\n(Model learns the true values!)')\naxes[1].legend()\n\n# Final fit\naxes[2].scatter(fuel_load, lap_time, alpha=0.6, label='Practice data')\nx_line = np.linspace(-3, 3, 100)\naxes[2].plot(x_line, fuel_effect_true * x_line + baseline_time_true, 'g-', linewidth=2, \n             label=f'True: {fuel_effect_true}*fuel + {baseline_time_true}')\naxes[2].plot(x_line, w_learned * x_line + b_learned, 'r--', linewidth=2, \n             label=f'Learned: {w_learned:.2f}*fuel + {b_learned:.2f}')\naxes[2].set_xlabel('Fuel Load')\naxes[2].set_ylabel('Lap Time')\naxes[2].set_title('Final Model Fit\\n(Red dashed = learned, Green = true)')\naxes[2].legend()\n\nplt.tight_layout()\nplt.show()",
   "id": "cell-48"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## Exercises\n\n### Exercise 1: Implement Gradient Checking for a Tire Degradation Model\n\n**F1 scenario:** You've built an analytical model of tire degradation and computed its gradients by hand. Before trusting those gradients for setup optimization, you need to **verify** them against numerical gradients. This is gradient checking — the engineer's sanity check before making expensive setup changes based on model predictions.\n\nGradient checking is crucial for debugging backpropagation. Compare analytical gradients with numerical gradients.",
   "id": "cell-49"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def gradient_check(f, grad_f, point, h=1e-5, threshold=1e-5):\n    \"\"\"\n    Compare analytical gradient with numerical gradient.\n    Returns True if they match within threshold.\n    \n    F1 context: Verify that your hand-derived tire model gradients \n    match numerical estimates before using them to make setup decisions.\n    \"\"\"\n    point = np.array(point, dtype=float)\n    analytical_grad = grad_f(point)\n    numerical_grad = compute_gradient(f, point, h)\n    \n    # Compute relative error\n    diff = np.abs(analytical_grad - numerical_grad)\n    denom = np.maximum(np.abs(analytical_grad) + np.abs(numerical_grad), 1e-10)\n    relative_error = diff / denom\n    \n    print(f\"Setup point: {point}\")\n    print(f\"Analytical gradient:  {analytical_grad}\")\n    print(f\"Numerical gradient:   {numerical_grad}\")\n    print(f\"Relative error: {relative_error}\")\n    print(f\"Max relative error: {np.max(relative_error):.2e}\")\n    \n    return np.all(relative_error < threshold)\n\n# Test on a tire degradation model: f(temp, pressure) = temp³ + 2*temp*pressure + pressure²\n# F1: How tire performance depends on temperature and pressure\ndef tire_degradation(p):\n    temp, pressure = p\n    return temp**3 + 2*temp*pressure + pressure**2\n\ndef tire_degradation_grad(p):\n    temp, pressure = p\n    return np.array([3*temp**2 + 2*pressure, 2*temp + 2*pressure])\n\npassed = gradient_check(tire_degradation, tire_degradation_grad, [2.0, 3.0])\nprint(f\"\\nGradient check passed: {passed}\")\nprint(\"The analytical gradients are trustworthy for setup optimization!\")",
   "id": "cell-50"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Exercise 2: Implement Softmax and Its Gradient\n\n**F1 scenario:** Your strategy team needs to convert raw \"fitness scores\" for different tire compounds (soft, medium, hard) into **probabilities** — \"What's the probability that each compound is the optimal choice for the next stint?\" Softmax is the standard way to do this conversion, and it's critical for classification in ML.\n\nSoftmax is critical for classification. Implement it and its gradient.",
   "id": "cell-51"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def softmax(x):\n    \"\"\"\n    Compute softmax: softmax(x)_i = exp(x_i) / sum(exp(x_j))\n    Subtract max for numerical stability.\n    \n    F1 context: Convert tire compound fitness scores into selection probabilities.\n    \"\"\"\n    # TODO: Implement softmax\n    x_shifted = x - np.max(x)  # For numerical stability\n    exp_x = np.exp(x_shifted)\n    return exp_x / np.sum(exp_x)\n\ndef softmax_jacobian(x):\n    \"\"\"\n    Compute Jacobian of softmax.\n    J[i,j] = d(softmax_i)/d(x_j)\n    \n    Formula: J[i,j] = softmax_i * (delta_ij - softmax_j)\n    where delta_ij = 1 if i==j, else 0\n    \n    F1 context: How does changing the fitness score of one compound \n    affect the selection probability of every compound?\n    \"\"\"\n    s = softmax(x)\n    n = len(s)\n    jacobian = np.zeros((n, n))\n    \n    # TODO: Implement Jacobian\n    for i in range(n):\n        for j in range(n):\n            if i == j:\n                jacobian[i, j] = s[i] * (1 - s[j])\n            else:\n                jacobian[i, j] = -s[i] * s[j]\n    \n    return jacobian\n\n# Test — tire compound fitness scores: [soft, medium, hard]\ncompound_scores = np.array([2.0, 1.0, 0.1])\nprint(f\"Compound fitness scores: {compound_scores}\")\nprint(f\"  (Soft=2.0, Medium=1.0, Hard=0.1)\")\nprint(f\"\\nSelection probabilities: {softmax(compound_scores)}\")\nprint(f\"Sum (should be 1): {softmax(compound_scores).sum():.6f}\")\nprint(f\"\\nJacobian (how each score affects each probability):\")\nprint(f\"{softmax_jacobian(compound_scores)}\")\nprint(f\"\\nF1 interpretation: Soft compound has highest probability ({softmax(compound_scores)[0]:.1%})\")\nprint(f\"because it has the highest fitness score.\")",
   "id": "cell-52"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Exercise 3: Gradient Descent with Momentum\n\n**F1 scenario:** Standard gradient descent can get stuck in local minima or oscillate in narrow valleys. Momentum is like giving your setup optimizer \"inertia\" — it builds up speed in consistent directions and carries through small bumps. In F1 terms, instead of reacting purely to the last practice session's data, momentum lets you carry the \"trend\" from multiple sessions. If the car has been getting faster with more wing for 3 sessions straight, momentum says \"keep going in that direction even if this one session was noisy.\"\n\nMomentum helps accelerate gradient descent. Implement it!",
   "id": "cell-53"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def gradient_descent_momentum(f, grad_f, start, learning_rate=0.01, momentum=0.9, n_steps=100):\n    \"\"\"\n    Gradient descent with momentum.\n    \n    v = momentum * v - learning_rate * gradient\n    x = x + v\n    \n    F1 context: The velocity term carries the \"trend\" from previous sessions,\n    helping the optimizer build speed in consistent directions and carry past\n    noisy bumps in the setup landscape.\n    \"\"\"\n    point = np.array(start, dtype=float)\n    velocity = np.zeros_like(point)\n    history = [point.copy()]\n    \n    for i in range(n_steps):\n        grad = grad_f(point)\n        velocity = momentum * velocity - learning_rate * grad\n        point = point + velocity\n        history.append(point.copy())\n        \n    return point, np.array(history)\n\n# Compare regular GD vs GD with momentum on Rosenbrock (the \"Monaco\" landscape)\nstart = [-1.0, 1.0]\nn_steps = 1000\n\nfinal_gd, history_gd = gradient_descent_2d(rosenbrock, rosenbrock_grad, start, \n                                            learning_rate=0.001, n_steps=n_steps)\nfinal_mom, history_mom = gradient_descent_momentum(rosenbrock, rosenbrock_grad, start,\n                                                    learning_rate=0.001, momentum=0.9, n_steps=n_steps)\n\nprint(f\"Regular GD final lap time:  {rosenbrock(final_gd):.6f}\")\nprint(f\"Momentum GD final lap time: {rosenbrock(final_mom):.6f}\")\nprint(f\"\\nMomentum finds a better setup in the same number of iterations!\")\n\n# Visualize\nplt.figure(figsize=(14, 5))\n\nplt.subplot(1, 2, 1)\nplt.contour(X, Y, Z, levels=np.logspace(0, 3, 30), cmap=cm.viridis, alpha=0.5)\nplt.plot(history_gd[::20, 0], history_gd[::20, 1], 'b.-', markersize=3, label='Standard GD')\nplt.plot(history_mom[::20, 0], history_mom[::20, 1], 'r.-', markersize=3, label='With Momentum')\nplt.xlabel('Wing Angle')\nplt.ylabel('Ride Height')\nplt.title('Setup Optimization Paths\\n(Momentum carries through the narrow valley)')\nplt.legend()\n\nplt.subplot(1, 2, 2)\nlosses_gd = [rosenbrock(p) for p in history_gd]\nlosses_mom = [rosenbrock(p) for p in history_mom]\nplt.plot(losses_gd, 'b-', label='Standard GD')\nplt.plot(losses_mom, 'r-', label='With Momentum')\nplt.xlabel('Iteration')\nplt.ylabel('Lap Time')\nplt.title('Lap Time: Standard GD vs Momentum\\n(Momentum converges faster)')\nplt.yscale('log')\nplt.legend()\n\nplt.tight_layout()\nplt.show()",
   "id": "cell-54"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## Summary\n\n### Key Concepts\n\n| Concept | Mathematical Meaning | F1 Parallel |\n|---------|---------------------|-------------|\n| **Derivatives** | Measure rate of change — essential for optimization | How lap time changes when you tweak a setup parameter (acceleration is the derivative of speed) |\n| **Partial derivatives** | Handle functions of multiple variables | Effect of changing ONE parameter (e.g., wing angle) while holding everything else fixed |\n| **The gradient** | Points in the direction of steepest ascent | The engineer's \"sensitivity report\" — which setup parameter to change to improve lap time fastest |\n| **Chain rule** | Compute gradients through composed functions (backprop!) | How engine power flows through torque, tire slip, cornering speed to affect lap time (sequential dependencies) |\n| **Gradient descent** | Minimize loss by following the negative gradient | Iteratively tuning car setup across practice sessions to minimize lap time |\n| **Learning rate** | How big each optimization step is | How aggressive the engineer's setup changes are (too big = overshoot, too small = slow progress) |\n| **Local minima** | A point that's locally optimal but not globally | A \"good enough\" setup that's not actually the fastest — getting stuck |\n| **Momentum** | Build up \"velocity\" in consistent directions | Carrying the trend from multiple sessions to power through noise and shallow local minima |\n\n### Connection to Deep Learning\n\n- **Forward pass**: Compute function values through the network\n- **Loss**: Scalar measuring prediction quality\n- **Backward pass**: Apply chain rule to compute gradients\n- **Update**: Move parameters in negative gradient direction\n\n### Checklist\n- [ ] I can compute derivatives of common functions\n- [ ] I understand partial derivatives and gradients\n- [ ] I can apply the chain rule to composite functions\n- [ ] I can implement gradient descent from scratch\n- [ ] I understand the effect of learning rate",
   "id": "cell-55"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## Next Steps\n\nContinue to **Part 1.3: Probability & Statistics** where we'll cover:\n- Probability distributions\n- Bayes' theorem\n- Maximum likelihood estimation\n- Information theory (entropy, KL divergence)\n\n**F1 preview:** Probability and statistics are how F1 teams make decisions under uncertainty — \"What's the probability it will rain in 20 minutes?\", \"Given the current tire wear rate, what's the optimal pit stop window?\", \"How confident are we that this setup change actually improved the car vs. random variation?\" These are all probability and statistics questions.",
   "id": "cell-56"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Part 1.5: Optimization & Linear Programming\n",
    "\n",
    "Every machine learning algorithm is, at its core, an optimization problem. When we train a neural network, we are searching for the set of weights that minimizes a loss function. When we fit a support vector machine, we are solving a constrained quadratic program. When we tune hyperparameters, we are optimizing a noisy black-box function.\n",
    "\n",
    "Understanding optimization gives you the vocabulary and intuition to answer questions like:\n",
    "- *Why does gradient descent work?* (Because loss functions are often convex, or at least locally convex.)\n",
    "- *Why does regularization help?* (It adds a constraint to the optimization, shrinking the feasible region.)\n",
    "- *Why do SVMs find the \"best\" boundary?* (They solve a convex optimization problem with a unique global solution.)\n",
    "\n",
    "This notebook builds the mathematical foundation you need before diving into gradient-based methods in the next notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you should be able to:\n",
    "\n",
    "- [ ] Define an optimization problem (objective, constraints, feasible region)\n",
    "- [ ] Formulate and solve linear programs graphically and with `scipy`\n",
    "- [ ] Explain the Simplex method at a conceptual level\n",
    "- [ ] State weak and strong duality and explain their significance\n",
    "- [ ] Distinguish convex from non-convex problems and explain why convexity matters\n",
    "- [ ] Apply Lagrange multipliers to equality-constrained problems\n",
    "- [ ] State the KKT conditions and explain their role in inequality constraints\n",
    "- [ ] Recognize ML algorithms as optimization problems (SVM, regularized regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import linprog, minimize\n",
    "from matplotlib.patches import Polygon\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. What is Optimization?\n",
    "\n",
    "### Intuitive Explanation\n",
    "\n",
    "Optimization is the art and science of finding the **best** solution from a set of possible solutions. In everyday life, you optimize constantly:\n",
    "- Choosing the fastest route to work (minimize travel time)\n",
    "- Allocating a budget across expenses (maximize value subject to spending limits)\n",
    "- Setting a thermostat (minimize energy use while staying comfortable)\n",
    "\n",
    "In mathematics, an optimization problem has three parts:\n",
    "\n",
    "1. **Objective function** $f(x)$: The quantity we want to minimize (or maximize)\n",
    "2. **Decision variables** $x$: The knobs we can turn\n",
    "3. **Constraints**: Rules that limit which values of $x$ are allowed\n",
    "\n",
    "The general form is:\n",
    "\n",
    "$$\\min_{x} f(x) \\quad \\text{subject to} \\quad g_i(x) \\leq 0, \\quad h_j(x) = 0$$\n",
    "\n",
    "The set of all $x$ that satisfy the constraints is called the **feasible region**. The best point within the feasible region is the **optimal solution**.\n",
    "\n",
    "**What this means:** Think of the objective function as a landscape of hills and valleys. The constraints fence off a region you are allowed to explore. Your job is to find the lowest valley (for minimization) inside the fence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a simple 2D optimization landscape\n",
    "def objective_landscape(x1, x2):\n",
    "    \"\"\"A quadratic objective: f(x1, x2) = (x1 - 2)^2 + (x2 - 1)^2\"\"\"\n",
    "    return (x1 - 2)**2 + (x2 - 1)**2\n",
    "\n",
    "x1 = np.linspace(-1, 5, 300)\n",
    "x2 = np.linspace(-1, 4, 300)\n",
    "X1, X2 = np.meshgrid(x1, x2)\n",
    "Z = objective_landscape(X1, X2)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Left: contour plot\n",
    "ax = axes[0]\n",
    "contour = ax.contourf(X1, X2, Z, levels=20, cmap='Blues_r', alpha=0.7)\n",
    "ax.contour(X1, X2, Z, levels=20, colors='navy', alpha=0.3, linewidths=0.5)\n",
    "ax.plot(2, 1, 'r*', markersize=15, label='Optimal point (2, 1)')\n",
    "plt.colorbar(contour, ax=ax, label='f(x₁, x₂)')\n",
    "ax.set_xlabel('x₁')\n",
    "ax.set_ylabel('x₂')\n",
    "ax.set_title('Unconstrained Optimization Landscape')\n",
    "ax.legend()\n",
    "\n",
    "# Right: same landscape with a constraint region\n",
    "ax = axes[1]\n",
    "contour = ax.contourf(X1, X2, Z, levels=20, cmap='Blues_r', alpha=0.7)\n",
    "ax.contour(X1, X2, Z, levels=20, colors='navy', alpha=0.3, linewidths=0.5)\n",
    "\n",
    "# Constraint: x1 + x2 <= 2 and x1 >= 0 and x2 >= 0\n",
    "feasible_vertices = np.array([[0, 0], [2, 0], [0, 2]])\n",
    "feasible_region = Polygon(feasible_vertices, alpha=0.3, color='green', label='Feasible region')\n",
    "ax.add_patch(feasible_region)\n",
    "ax.plot([0, 2], [2, 0], 'g-', linewidth=2)\n",
    "ax.plot([0, 0], [0, 2], 'g-', linewidth=2)\n",
    "ax.plot([0, 2], [0, 0], 'g-', linewidth=2)\n",
    "\n",
    "# The constrained optimum is at (1, 1) — closest feasible point to (2,1)\n",
    "# Actually, minimize (x1-2)^2 + (x2-1)^2 s.t. x1+x2<=2, x1>=0, x2>=0\n",
    "# Optimal is at (1, 1) on the boundary x1+x2=2\n",
    "ax.plot(2, 1, 'r*', markersize=12, alpha=0.3, label='Unconstrained optimum')\n",
    "ax.plot(1, 1, 'r^', markersize=12, label='Constrained optimum (1, 1)')\n",
    "ax.annotate('', xy=(1, 1), xytext=(2, 1),\n",
    "            arrowprops=dict(arrowstyle='->', color='red', lw=1.5, ls='--'))\n",
    "plt.colorbar(contour, ax=ax, label='f(x₁, x₂)')\n",
    "ax.set_xlabel('x₁')\n",
    "ax.set_ylabel('x₂')\n",
    "ax.set_title('Constrained Optimization')\n",
    "ax.legend(loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Left: Without constraints, the minimum is at (2, 1) where f = 0.\")\n",
    "print(\"Right: With the constraint x₁ + x₂ ≤ 2 (and x₁, x₂ ≥ 0),\")\n",
    "print(\"       the minimum shifts to (1, 1) on the constraint boundary, where f = 1.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "### Deep Dive: Types of Optimization Problems\n",
    "\n",
    "Optimization problems are classified by the nature of their objective and constraints:\n",
    "\n",
    "| Type | Objective | Constraints | Example in ML |\n",
    "|------|-----------|-------------|---------------|\n",
    "| **Linear Programming (LP)** | Linear | Linear inequalities/equalities | Resource allocation, network flow |\n",
    "| **Quadratic Programming (QP)** | Quadratic | Linear | SVM (dual form), ridge regression |\n",
    "| **Convex Optimization** | Convex | Convex set | Logistic regression, LASSO |\n",
    "| **Non-convex Optimization** | Non-convex | Any | Neural network training |\n",
    "| **Integer Programming** | Linear/Quadratic | Integer variables | Feature selection |\n",
    "\n",
    "#### Key Insight\n",
    "\n",
    "The difficulty of an optimization problem depends on its **structure**, not its size. A convex problem with a million variables is easier (in principle) than a non-convex problem with ten variables. This is why understanding convexity matters so much in ML."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Linear Programming\n",
    "\n",
    "### Intuitive Explanation\n",
    "\n",
    "A **linear program (LP)** is the simplest type of optimization problem: both the objective function and all constraints are linear.\n",
    "\n",
    "**Standard form:**\n",
    "\n",
    "$$\\min_{x} \\mathbf{c}^T \\mathbf{x} \\quad \\text{subject to} \\quad A\\mathbf{x} \\leq \\mathbf{b}, \\quad \\mathbf{x} \\geq 0$$\n",
    "\n",
    "#### Breaking down the formula:\n",
    "\n",
    "| Component | Meaning | Role |\n",
    "|-----------|---------|------|\n",
    "| $\\mathbf{c}^T \\mathbf{x}$ | Dot product of cost vector and decision variables | Objective to minimize |\n",
    "| $A\\mathbf{x} \\leq \\mathbf{b}$ | Matrix inequality | Constraint on resources |\n",
    "| $\\mathbf{x} \\geq 0$ | Non-negativity | Variables must be non-negative |\n",
    "\n",
    "**What this means:** Imagine you run a factory making two products. Each product gives you a different profit (the objective). Each product uses different amounts of labor and materials (the constraints). How much of each product should you make to maximize profit?\n",
    "\n",
    "### Geometric Intuition\n",
    "\n",
    "The feasible region of an LP is always a **convex polytope** (a polygon in 2D, a polyhedron in 3D, etc.). The objective function creates parallel hyperplanes across the space. The optimal solution always occurs at a **vertex** of the polytope.\n",
    "\n",
    "Why a vertex? Because a linear function over a convex region achieves its extreme values at the boundary, and specifically at a corner point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example LP: A factory production problem\n",
    "# Maximize: 5*x1 + 4*x2 (profit)\n",
    "# Subject to:\n",
    "#   6*x1 + 4*x2 <= 24  (labor hours)\n",
    "#   x1 + 2*x2 <= 6     (raw material)\n",
    "#   x1, x2 >= 0\n",
    "\n",
    "# Graphical solution\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "x = np.linspace(0, 5, 400)\n",
    "\n",
    "# Constraint boundaries\n",
    "y1 = (24 - 6*x) / 4   # 6x1 + 4x2 = 24\n",
    "y2 = (6 - x) / 2       # x1 + 2x2 = 6\n",
    "\n",
    "# Plot constraints\n",
    "ax.plot(x, y1, 'b-', linewidth=2, label='6x₁ + 4x₂ ≤ 24 (labor)')\n",
    "ax.plot(x, y2, 'orange', linewidth=2, label='x₁ + 2x₂ ≤ 6 (material)')\n",
    "ax.axhline(y=0, color='k', linewidth=0.8)\n",
    "ax.axvline(x=0, color='k', linewidth=0.8)\n",
    "\n",
    "# Feasible region vertices (found by solving intersection equations)\n",
    "vertices = np.array([\n",
    "    [0, 0],\n",
    "    [4, 0],    # x1=4, x2=0: from 6*4 + 4*0 = 24\n",
    "    [3, 1.5],  # intersection of 6x1+4x2=24 and x1+2x2=6\n",
    "    [0, 3],    # x1=0, x2=3: from 0 + 2*3 = 6\n",
    "])\n",
    "\n",
    "# Fill feasible region\n",
    "feasible = Polygon(vertices, alpha=0.2, color='green', label='Feasible region')\n",
    "ax.add_patch(feasible)\n",
    "\n",
    "# Mark vertices\n",
    "for v in vertices:\n",
    "    profit = 5*v[0] + 4*v[1]\n",
    "    ax.plot(v[0], v[1], 'ko', markersize=8)\n",
    "    ax.annotate(f'({v[0]:.1f}, {v[1]:.1f})\\nProfit = {profit:.1f}',\n",
    "                xy=(v[0], v[1]), xytext=(v[0]+0.15, v[1]+0.2),\n",
    "                fontsize=9, fontweight='bold')\n",
    "\n",
    "# Optimal vertex\n",
    "ax.plot(3, 1.5, 'r*', markersize=20, zorder=5, label='Optimal: (3, 1.5), Profit = 21')\n",
    "\n",
    "# Objective function contours (iso-profit lines)\n",
    "for profit_level in [5, 10, 15, 21]:\n",
    "    y_obj = (profit_level - 5*x) / 4\n",
    "    ax.plot(x, y_obj, '--', color='red', alpha=0.3, linewidth=1)\n",
    "    # Label the iso-profit line\n",
    "    idx = np.argmin(np.abs(y_obj - 0.5))\n",
    "    if 0 < x[idx] < 4.5:\n",
    "        ax.text(x[idx], y_obj[idx] + 0.1, f'Profit={profit_level}',\n",
    "                color='red', fontsize=8, alpha=0.6)\n",
    "\n",
    "ax.set_xlim(-0.5, 5.5)\n",
    "ax.set_ylim(-0.5, 5)\n",
    "ax.set_xlabel('x₁ (Product 1 quantity)', fontsize=12)\n",
    "ax.set_ylabel('x₂ (Product 2 quantity)', fontsize=12)\n",
    "ax.set_title('Linear Programming: Graphical Solution', fontsize=14)\n",
    "ax.legend(loc='upper right', fontsize=10)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"The optimal solution is at vertex (3, 1.5) with profit = 21.\")\n",
    "print(\"Notice: the optimum is at a vertex of the feasible polytope — this always\")\n",
    "print(\"happens for linear programs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solving the same LP with scipy.optimize.linprog\n",
    "# Note: linprog MINIMIZES, so we negate the objective for maximization\n",
    "\n",
    "# Maximize 5*x1 + 4*x2 → Minimize -5*x1 - 4*x2\n",
    "c = [-5, -4]  # negated for minimization\n",
    "\n",
    "# Inequality constraints: A_ub @ x <= b_ub\n",
    "A_ub = [\n",
    "    [6, 4],   # 6x1 + 4x2 <= 24\n",
    "    [1, 2],   # x1 + 2x2 <= 6\n",
    "]\n",
    "b_ub = [24, 6]\n",
    "\n",
    "# Bounds: x1 >= 0, x2 >= 0\n",
    "x1_bounds = (0, None)\n",
    "x2_bounds = (0, None)\n",
    "\n",
    "result = linprog(c, A_ub=A_ub, b_ub=b_ub, bounds=[x1_bounds, x2_bounds], method='highs')\n",
    "\n",
    "print(\"=== LP Solution (scipy.optimize.linprog) ===\")\n",
    "print(f\"Optimal x₁: {result.x[0]:.4f}\")\n",
    "print(f\"Optimal x₂: {result.x[1]:.4f}\")\n",
    "print(f\"Maximum profit: {-result.fun:.4f}\")  # negate back\n",
    "print(f\"Solver status: {result.message}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "### Deep Dive: Why LPs Always Have Vertex Solutions\n",
    "\n",
    "A linear objective function $\\mathbf{c}^T \\mathbf{x}$ defines a family of parallel hyperplanes (lines in 2D). As we slide these hyperplanes in the direction of improvement, the last point of contact with the feasible polytope must be a vertex (or an edge/face, in degenerate cases where the objective is parallel to a constraint).\n",
    "\n",
    "This geometric fact is the foundation of the Simplex method: instead of searching the entire feasible region, we only need to check vertices.\n",
    "\n",
    "#### Common Misconceptions\n",
    "\n",
    "| Misconception | Reality |\n",
    "|---------------|---------|\n",
    "| LP solutions can be interior points | The optimum is always on the boundary (at a vertex or edge) |\n",
    "| More constraints make the problem harder | More constraints reduce the feasible region, often making the search easier |\n",
    "| LP can only handle simple problems | LP underlies many sophisticated algorithms (network flows, assignment problems) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. The Simplex Method\n",
    "\n",
    "### Intuitive Explanation\n",
    "\n",
    "The **Simplex method** (George Dantzig, 1947) is the classic algorithm for solving linear programs. Its strategy is elegantly simple:\n",
    "\n",
    "1. **Start** at any vertex of the feasible polytope\n",
    "2. **Look** at all neighboring vertices (connected by an edge)\n",
    "3. **Move** to the neighbor that improves the objective the most\n",
    "4. **Repeat** until no neighbor is better — you are at the optimum\n",
    "\n",
    "**What this means:** Imagine standing on one corner of a diamond. You look along each edge and walk to whichever adjacent corner is downhill. When every direction is uphill, you have found the lowest corner.\n",
    "\n",
    "In theory, the Simplex method could visit exponentially many vertices. In practice, it is remarkably fast — typically visiting $O(m)$ vertices where $m$ is the number of constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the Simplex method: vertex hopping\n",
    "# We'll trace the path the Simplex method takes on our factory LP\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "x = np.linspace(0, 5, 400)\n",
    "y1 = (24 - 6*x) / 4\n",
    "y2 = (6 - x) / 2\n",
    "\n",
    "# Feasible region\n",
    "vertices = np.array([[0, 0], [4, 0], [3, 1.5], [0, 3]])\n",
    "feasible = Polygon(vertices, alpha=0.15, color='green')\n",
    "ax.add_patch(feasible)\n",
    "ax.plot(x, np.clip(y1, 0, 10), 'b-', linewidth=1.5, alpha=0.5)\n",
    "ax.plot(x, np.clip(y2, 0, 10), color='orange', linewidth=1.5, alpha=0.5)\n",
    "\n",
    "# Simplex path: start at origin, hop along vertices\n",
    "simplex_path = [\n",
    "    [0, 0],     # Step 0: start at origin\n",
    "    [4, 0],     # Step 1: move along x1 axis (improves objective most)\n",
    "    [3, 1.5],   # Step 2: move to intersection vertex (still improving)\n",
    "]\n",
    "\n",
    "colors_path = ['blue', 'purple', 'red']\n",
    "labels = ['Start: (0,0)\\nProfit=0', 'Step 1: (4,0)\\nProfit=20', 'Optimal: (3,1.5)\\nProfit=21']\n",
    "\n",
    "for i, (point, color, label) in enumerate(zip(simplex_path, colors_path, labels)):\n",
    "    ax.plot(point[0], point[1], 'o', color=color, markersize=12, zorder=5)\n",
    "    offset = [(0.2, 0.3), (0.2, 0.3), (-2.0, 0.3)][i]\n",
    "    ax.annotate(label, xy=point, xytext=(point[0]+offset[0], point[1]+offset[1]),\n",
    "                fontsize=10, fontweight='bold', color=color,\n",
    "                arrowprops=dict(arrowstyle='->', color=color, lw=1.5))\n",
    "\n",
    "# Draw path arrows\n",
    "for i in range(len(simplex_path) - 1):\n",
    "    start = simplex_path[i]\n",
    "    end = simplex_path[i+1]\n",
    "    ax.annotate('', xy=end, xytext=start,\n",
    "                arrowprops=dict(arrowstyle='->', color='darkgreen', lw=2.5,\n",
    "                                connectionstyle='arc3,rad=0.1'))\n",
    "\n",
    "ax.set_xlim(-0.5, 5.5)\n",
    "ax.set_ylim(-0.5, 4.5)\n",
    "ax.set_xlabel('x₁', fontsize=12)\n",
    "ax.set_ylabel('x₂', fontsize=12)\n",
    "ax.set_title('Simplex Method: Vertex Hopping', fontsize=14)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"The Simplex method visits only 3 of 4 vertices to find the optimum.\")\n",
    "print(\"It never explores the interior — only vertices and edges.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplex_2d(c, A_ub, b_ub):\n",
    "    \"\"\"\n",
    "    A simplified 2D Simplex implementation for educational purposes.\n",
    "    Finds all vertices of the feasible polytope and evaluates the objective.\n",
    "    \n",
    "    This is NOT a full Simplex implementation — it is a brute-force vertex\n",
    "    enumeration to illustrate the concept.\n",
    "    \n",
    "    Args:\n",
    "        c: Objective coefficients [c1, c2] (minimize c^T x)\n",
    "        A_ub: Inequality constraint matrix (A_ub @ x <= b_ub)\n",
    "        b_ub: Right-hand side of inequalities\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (optimal_vertex, optimal_value, all_vertices)\n",
    "    \"\"\"\n",
    "    from itertools import combinations\n",
    "    \n",
    "    c = np.array(c)\n",
    "    A = np.array(A_ub)\n",
    "    b = np.array(b_ub)\n",
    "    \n",
    "    # Add non-negativity constraints: -x1 <= 0, -x2 <= 0\n",
    "    A_full = np.vstack([A, [[-1, 0], [0, -1]]])\n",
    "    b_full = np.concatenate([b, [0, 0]])\n",
    "    \n",
    "    n_constraints = len(A_full)\n",
    "    vertices = []\n",
    "    \n",
    "    # Find all intersections of pairs of constraint lines\n",
    "    for i, j in combinations(range(n_constraints), 2):\n",
    "        A_pair = A_full[[i, j]]\n",
    "        b_pair = b_full[[i, j]]\n",
    "        try:\n",
    "            vertex = np.linalg.solve(A_pair, b_pair)\n",
    "            # Check if this vertex satisfies ALL constraints\n",
    "            if np.all(A_full @ vertex <= b_full + 1e-10):\n",
    "                vertices.append(vertex)\n",
    "        except np.linalg.LinAlgError:\n",
    "            continue  # Parallel constraints, no intersection\n",
    "    \n",
    "    if not vertices:\n",
    "        return None, None, []\n",
    "    \n",
    "    vertices = np.array(vertices)\n",
    "    # Remove duplicates\n",
    "    unique = [vertices[0]]\n",
    "    for v in vertices[1:]:\n",
    "        if not any(np.allclose(v, u) for u in unique):\n",
    "            unique.append(v)\n",
    "    vertices = np.array(unique)\n",
    "    \n",
    "    # Evaluate objective at each vertex\n",
    "    obj_values = vertices @ c\n",
    "    best_idx = np.argmin(obj_values)\n",
    "    \n",
    "    return vertices[best_idx], obj_values[best_idx], vertices\n",
    "\n",
    "\n",
    "# Test on our factory problem (minimize -5x1 - 4x2)\n",
    "opt_vertex, opt_value, all_vertices = simplex_2d(\n",
    "    c=[-5, -4],\n",
    "    A_ub=[[6, 4], [1, 2]],\n",
    "    b_ub=[24, 6]\n",
    ")\n",
    "\n",
    "print(\"=== Simplified Simplex (Vertex Enumeration) ===\")\n",
    "print(f\"\\nAll feasible vertices:\")\n",
    "for v in all_vertices:\n",
    "    profit = 5*v[0] + 4*v[1]\n",
    "    print(f\"  ({v[0]:.2f}, {v[1]:.2f}) → Profit = {profit:.2f}\")\n",
    "print(f\"\\nOptimal vertex: ({opt_vertex[0]:.2f}, {opt_vertex[1]:.2f})\")\n",
    "print(f\"Maximum profit: {-opt_value:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "### Deep Dive: Simplex vs Interior Point Methods\n",
    "\n",
    "The Simplex method walks along edges of the polytope. An alternative family of algorithms — **interior point methods** — takes a very different approach: they walk *through the interior* of the polytope, approaching the optimal vertex from inside.\n",
    "\n",
    "| Property | Simplex | Interior Point |\n",
    "|----------|---------|----------------|\n",
    "| Path | Along edges (vertex to vertex) | Through the interior |\n",
    "| Worst case | Exponential | Polynomial |\n",
    "| Practical speed | Very fast for most LPs | Slightly slower on small LPs, faster on huge ones |\n",
    "| Solution type | Exact vertex solution | Approaches vertex asymptotically |\n",
    "| Used in `scipy` | `method='revised simplex'` | `method='highs'` (default, hybrid) |\n",
    "\n",
    "**What this means for ML:** Most modern LP/QP solvers (like those inside SVM implementations) use interior point methods because they have reliable polynomial-time guarantees."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Duality Theory\n",
    "\n",
    "### Intuitive Explanation\n",
    "\n",
    "Every linear program (the **primal**) has a companion problem called the **dual**. If the primal asks \"What is the minimum cost to meet these requirements?\", the dual asks \"What is the maximum value of the resources?\"\n",
    "\n",
    "**Primal (minimize):**\n",
    "$$\\min_{x} \\mathbf{c}^T \\mathbf{x} \\quad \\text{s.t.} \\quad A\\mathbf{x} \\geq \\mathbf{b}, \\; \\mathbf{x} \\geq 0$$\n",
    "\n",
    "**Dual (maximize):**\n",
    "$$\\max_{y} \\mathbf{b}^T \\mathbf{y} \\quad \\text{s.t.} \\quad A^T\\mathbf{y} \\leq \\mathbf{c}, \\; \\mathbf{y} \\geq 0$$\n",
    "\n",
    "The dual variables $\\mathbf{y}$ are sometimes called **shadow prices** — they tell you how much the optimal objective would change if you relaxed a constraint by one unit.\n",
    "\n",
    "### Key Duality Theorems\n",
    "\n",
    "1. **Weak Duality:** The dual objective is always a lower bound for the primal:\n",
    "   $$\\mathbf{b}^T \\mathbf{y} \\leq \\mathbf{c}^T \\mathbf{x} \\quad \\text{(for all feasible } x, y\\text{)}$$\n",
    "\n",
    "2. **Strong Duality:** At optimality, the bounds meet exactly:\n",
    "   $$\\mathbf{b}^T \\mathbf{y}^* = \\mathbf{c}^T \\mathbf{x}^*$$\n",
    "\n",
    "3. **Complementary Slackness:** At optimality, either a constraint is tight (active) or its dual variable is zero. No resource is both unused and valued.\n",
    "\n",
    "**What this means:** Duality gives us two views of the same problem. If we can solve the dual, we automatically get the primal solution (and vice versa). In ML, the SVM dual formulation is actually easier to solve than the primal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate duality with a concrete example\n",
    "# Primal: min c^T x  s.t. Ax >= b, x >= 0\n",
    "# Reformulated as: min c^T x  s.t. -Ax <= -b, x >= 0 (for linprog)\n",
    "\n",
    "# Primal problem:\n",
    "# min 4x1 + 3x2\n",
    "# s.t.  2x1 + x2 >= 8\n",
    "#        x1 + 2x2 >= 6\n",
    "#        x1, x2 >= 0\n",
    "\n",
    "# Primal with linprog (convert >= to <=)\n",
    "c_primal = [4, 3]\n",
    "A_primal = [[-2, -1], [-1, -2]]  # negated for <=\n",
    "b_primal = [-8, -6]\n",
    "\n",
    "result_primal = linprog(c_primal, A_ub=A_primal, b_ub=b_primal,\n",
    "                        bounds=[(0, None), (0, None)], method='highs')\n",
    "\n",
    "# Dual problem:\n",
    "# max 8y1 + 6y2 → min -8y1 - 6y2\n",
    "# s.t.  2y1 + y2 <= 4\n",
    "#        y1 + 2y2 <= 3\n",
    "#        y1, y2 >= 0\n",
    "\n",
    "c_dual = [-8, -6]  # negated for minimization\n",
    "A_dual = [[2, 1], [1, 2]]\n",
    "b_dual = [4, 3]\n",
    "\n",
    "result_dual = linprog(c_dual, A_ub=A_dual, b_ub=b_dual,\n",
    "                      bounds=[(0, None), (0, None)], method='highs')\n",
    "\n",
    "print(\"=== Primal-Dual Comparison ===\")\n",
    "print(f\"\\nPrimal optimal x: ({result_primal.x[0]:.4f}, {result_primal.x[1]:.4f})\")\n",
    "print(f\"Primal optimal value: {result_primal.fun:.4f}\")\n",
    "print(f\"\\nDual optimal y: ({result_dual.x[0]:.4f}, {result_dual.x[1]:.4f})\")\n",
    "print(f\"Dual optimal value: {-result_dual.fun:.4f}\")  # negate back\n",
    "print(f\"\\nStrong duality holds: {np.isclose(result_primal.fun, -result_dual.fun)}\")\n",
    "print(f\"Duality gap: {abs(result_primal.fun - (-result_dual.fun)):.10f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize primal and dual feasible regions side by side\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "x = np.linspace(0, 6, 400)\n",
    "\n",
    "# --- Primal ---\n",
    "ax = axes[0]\n",
    "# Constraints: 2x1 + x2 >= 8, x1 + 2x2 >= 6\n",
    "y_c1 = 8 - 2*x       # x2 >= 8 - 2x1\n",
    "y_c2 = (6 - x) / 2   # x2 >= (6 - x1)/2\n",
    "\n",
    "ax.plot(x, y_c1, 'b-', linewidth=2, label='2x₁ + x₂ = 8')\n",
    "ax.plot(x, y_c2, color='orange', linewidth=2, label='x₁ + 2x₂ = 6')\n",
    "\n",
    "# Fill feasible region (above both lines)\n",
    "y_lower = np.maximum(y_c1, y_c2)\n",
    "y_lower = np.maximum(y_lower, 0)\n",
    "ax.fill_between(x, y_lower, 10, where=(y_lower <= 10) & (x >= 0),\n",
    "                alpha=0.15, color='green', label='Feasible region')\n",
    "\n",
    "# Optimal point\n",
    "ax.plot(result_primal.x[0], result_primal.x[1], 'r*', markersize=15,\n",
    "        label=f'Optimal: ({result_primal.x[0]:.1f}, {result_primal.x[1]:.1f})', zorder=5)\n",
    "\n",
    "ax.set_xlim(-0.5, 6)\n",
    "ax.set_ylim(-0.5, 10)\n",
    "ax.set_xlabel('x₁', fontsize=12)\n",
    "ax.set_ylabel('x₂', fontsize=12)\n",
    "ax.set_title(f'Primal Problem (min = {result_primal.fun:.2f})', fontsize=13)\n",
    "ax.legend(fontsize=9)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# --- Dual ---\n",
    "ax = axes[1]\n",
    "# Constraints: 2y1 + y2 <= 4, y1 + 2y2 <= 3\n",
    "y_d1 = 4 - 2*x       # y2 <= 4 - 2y1\n",
    "y_d2 = (3 - x) / 2   # y2 <= (3 - y1)/2\n",
    "\n",
    "ax.plot(x, y_d1, 'b-', linewidth=2, label='2y₁ + y₂ = 4')\n",
    "ax.plot(x, y_d2, color='orange', linewidth=2, label='y₁ + 2y₂ = 3')\n",
    "\n",
    "# Feasible region vertices for dual\n",
    "dual_verts = np.array([[0, 0], [2, 0], [5/3, 2/3], [0, 1.5]])\n",
    "dual_poly = Polygon(dual_verts, alpha=0.15, color='green', label='Feasible region')\n",
    "ax.add_patch(dual_poly)\n",
    "\n",
    "# Optimal point\n",
    "ax.plot(result_dual.x[0], result_dual.x[1], 'r*', markersize=15,\n",
    "        label=f'Optimal: ({result_dual.x[0]:.2f}, {result_dual.x[1]:.2f})', zorder=5)\n",
    "\n",
    "ax.set_xlim(-0.5, 3.5)\n",
    "ax.set_ylim(-0.5, 3)\n",
    "ax.set_xlabel('y₁', fontsize=12)\n",
    "ax.set_ylabel('y₂', fontsize=12)\n",
    "ax.set_title(f'Dual Problem (max = {-result_dual.fun:.2f})', fontsize=13)\n",
    "ax.legend(fontsize=9)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Strong duality: both problems achieve the same optimal value.\")\n",
    "print(\"The dual variables tell us the 'shadow prices' of the primal constraints.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "### Deep Dive: Why Duality Matters in ML\n",
    "\n",
    "Duality is not just a theoretical curiosity — it is the engine behind several important ML algorithms:\n",
    "\n",
    "| ML Application | How Duality is Used |\n",
    "|----------------|---------------------|\n",
    "| **Support Vector Machines** | The SVM primal is hard (minimize over $w, b$). The dual is easier and reveals the kernel trick. |\n",
    "| **Regularization** | Adding an $\\ell_2$ penalty is equivalent to constraining the norm (Lagrangian duality). |\n",
    "| **Maximum Entropy Models** | The dual of the constrained entropy problem yields logistic regression. |\n",
    "| **Variational Inference** | ELBO (Evidence Lower BOund) is a dual bound on the marginal likelihood. |\n",
    "\n",
    "#### Key Insight\n",
    "\n",
    "The dual often reveals hidden structure. For SVMs, the dual formulation depends only on dot products of data points $\\langle x_i, x_j \\rangle$, which lets us use the **kernel trick** to work in infinite-dimensional feature spaces."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Convex Optimization\n",
    "\n",
    "### Intuitive Explanation\n",
    "\n",
    "A set is **convex** if the line segment between any two points in the set lies entirely within the set. Think of a filled circle (convex) versus a crescent moon (not convex).\n",
    "\n",
    "A function is **convex** if it curves upward — like a bowl. Formally, $f$ is convex if:\n",
    "\n",
    "$$f(\\lambda x + (1-\\lambda)y) \\leq \\lambda f(x) + (1-\\lambda)f(y) \\quad \\forall \\lambda \\in [0,1]$$\n",
    "\n",
    "**What this means:** Draw a line between any two points on the function's graph. If the function always lies below (or on) the line, it is convex. A bowl has this property; a roller coaster does not.\n",
    "\n",
    "### Why Convexity Matters\n",
    "\n",
    "**The fundamental theorem of convex optimization:** For a convex function over a convex set, every local minimum is a global minimum.\n",
    "\n",
    "This means:\n",
    "- No getting stuck in local minima\n",
    "- Gradient descent is guaranteed to find the global optimum\n",
    "- The solution is unique (for strictly convex functions)\n",
    "\n",
    "This is why much of ML theory revolves around convex loss functions (squared error, cross-entropy, hinge loss) and convex regularizers ($\\ell_1$, $\\ell_2$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize convex vs non-convex sets and functions\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# --- Top Left: Convex set ---\n",
    "ax = axes[0, 0]\n",
    "theta = np.linspace(0, 2*np.pi, 100)\n",
    "# Ellipse (convex)\n",
    "cx, cy = 2*np.cos(theta), np.sin(theta)\n",
    "ax.fill(cx, cy, alpha=0.3, color='green')\n",
    "ax.plot(cx, cy, 'g-', linewidth=2)\n",
    "# Show line segment test\n",
    "p1, p2 = np.array([-1.5, 0.3]), np.array([1.2, -0.6])\n",
    "ax.plot([p1[0], p2[0]], [p1[1], p2[1]], 'r-', linewidth=2, label='Line segment (inside)')\n",
    "ax.plot(*p1, 'ro', markersize=8)\n",
    "ax.plot(*p2, 'ro', markersize=8)\n",
    "ax.set_title('Convex Set', fontsize=13)\n",
    "ax.set_aspect('equal')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# --- Top Right: Non-convex set ---\n",
    "ax = axes[0, 1]\n",
    "# Star shape (non-convex)\n",
    "angles = np.linspace(0, 2*np.pi, 11)\n",
    "radii = [1.5 if i % 2 == 0 else 0.6 for i in range(11)]\n",
    "sx = [r*np.cos(a) for r, a in zip(radii, angles)]\n",
    "sy = [r*np.sin(a) for r, a in zip(radii, angles)]\n",
    "ax.fill(sx, sy, alpha=0.3, color='red')\n",
    "ax.plot(sx, sy, 'r-', linewidth=2)\n",
    "# Show line segment test failing\n",
    "p1, p2 = np.array([-1.0, 0.8]), np.array([1.0, 0.8])\n",
    "ax.plot([p1[0], p2[0]], [p1[1], p2[1]], 'b-', linewidth=2, label='Line segment (goes outside!)')\n",
    "ax.plot(*p1, 'bo', markersize=8)\n",
    "ax.plot(*p2, 'bo', markersize=8)\n",
    "ax.set_title('Non-Convex Set', fontsize=13)\n",
    "ax.set_aspect('equal')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# --- Bottom Left: Convex function ---\n",
    "ax = axes[1, 0]\n",
    "x = np.linspace(-3, 3, 200)\n",
    "y_convex = x**2\n",
    "ax.plot(x, y_convex, 'g-', linewidth=2.5, label='f(x) = x² (convex)')\n",
    "# Secant line\n",
    "xa, xb = -2, 1.5\n",
    "ya, yb = xa**2, xb**2\n",
    "ax.plot([xa, xb], [ya, yb], 'r--', linewidth=2, label='Secant line (always above f)')\n",
    "ax.fill_between(x[(x >= xa) & (x <= xb)],\n",
    "                x[(x >= xa) & (x <= xb)]**2,\n",
    "                np.interp(x[(x >= xa) & (x <= xb)], [xa, xb], [ya, yb]),\n",
    "                alpha=0.2, color='green')\n",
    "ax.plot(0, 0, 'r*', markersize=15, label='Global minimum', zorder=5)\n",
    "ax.set_title('Convex Function', fontsize=13)\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('f(x)')\n",
    "ax.legend(fontsize=9)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# --- Bottom Right: Non-convex function ---\n",
    "ax = axes[1, 1]\n",
    "y_nonconvex = np.sin(2*x) + 0.3*x**2\n",
    "ax.plot(x, y_nonconvex, 'r-', linewidth=2.5, label='f(x) = sin(2x) + 0.3x² (non-convex)')\n",
    "# Mark local minima\n",
    "from scipy.signal import argrelmin\n",
    "local_mins = argrelmin(y_nonconvex, order=20)[0]\n",
    "for lm in local_mins:\n",
    "    color = 'red' if y_nonconvex[lm] == min(y_nonconvex[local_mins]) else 'orange'\n",
    "    label = 'Global minimum' if color == 'red' else 'Local minimum'\n",
    "    ax.plot(x[lm], y_nonconvex[lm], '*', color=color, markersize=15, zorder=5, label=label)\n",
    "ax.set_title('Non-Convex Function', fontsize=13)\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('f(x)')\n",
    "ax.legend(fontsize=9)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Top row: Convex sets pass the line-segment test; non-convex sets fail it.\")\n",
    "print(\"Bottom row: Convex functions have one minimum; non-convex functions may have many.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": "# Demonstrate: gradient descent finds the global optimum on convex functions\n# but can get stuck on non-convex functions\n\ndef gradient_descent_1d(f, df, x0, lr=0.1, n_steps=30):\n    \"\"\"\n    Simple 1D gradient descent.\n    \n    Args:\n        f: Objective function\n        df: Gradient of objective\n        x0: Starting point\n        lr: Learning rate\n        n_steps: Number of steps\n    \n    Returns:\n        List of (x, f(x)) at each step\n    \"\"\"\n    path = [(x0, f(x0))]\n    x = x0\n    for _ in range(n_steps):\n        x = x - lr * df(x)\n        path.append((x, f(x)))\n    return path\n\n\n# Convex: f(x) = (x-1)^2\nf_convex = lambda x: (x - 1)**2\ndf_convex = lambda x: 2*(x - 1)\n\n# Non-convex: f(x) = sin(3x) + 0.3*x^2\nf_nonconvex = lambda x: np.sin(3*x) + 0.3*x**2\ndf_nonconvex = lambda x: 3*np.cos(3*x) + 0.6*x\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\nx_range = np.linspace(-3, 4, 300)\n\n# Convex case\nax = axes[0]\nax.plot(x_range, f_convex(x_range), 'g-', linewidth=2, label='f(x) = (x-1)²')\nfor x0, color, ls in [(-2.5, 'blue', '-'), (3.5, 'red', '--')]:\n    path = gradient_descent_1d(f_convex, df_convex, x0, lr=0.1, n_steps=20)\n    xs, ys = zip(*path)\n    ax.plot(xs, ys, 'o-', color=color, markersize=4, linewidth=1, alpha=0.7,\n            label=f'Start x={x0}')\n    ax.plot(xs[0], ys[0], 's', color=color, markersize=10)\nax.set_title('Convex: Both paths find global min', fontsize=13)\nax.set_xlabel('x')\nax.set_ylabel('f(x)')\nax.legend()\nax.grid(True, alpha=0.3)\n\n# Non-convex case\nax = axes[1]\nax.plot(x_range, f_nonconvex(x_range), 'r-', linewidth=2, label='f(x) = sin(3x) + 0.3x²')\nfor x0, color, ls in [(-2.0, 'blue', '-'), (2.0, 'red', '--')]:\n    path = gradient_descent_1d(f_nonconvex, df_nonconvex, x0, lr=0.05, n_steps=40)\n    xs, ys = zip(*path)\n    ax.plot(xs, ys, 'o-', color=color, markersize=4, linewidth=1, alpha=0.7,\n            label=f'Start x={x0}')\n    ax.plot(xs[0], ys[0], 's', color=color, markersize=10)\nax.set_title('Non-convex: Different starts → different minima', fontsize=13)\nax.set_xlabel('x')\nax.set_ylabel('f(x)')\nax.legend()\nax.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\nprint(\"Convex functions: Every starting point leads to the same global minimum.\")\nprint(\"Non-convex functions: Different starting points can lead to different local minima.\")\nprint(\"\\nThis is why neural network training (non-convex) depends on initialization,\")\nprint(\"while logistic regression (convex) converges to the same solution regardless.\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "### Deep Dive: Common Convex Functions in ML\n",
    "\n",
    "Many loss functions used in ML are convex by design:\n",
    "\n",
    "| Function | Formula | Convex? | Used in |\n",
    "|----------|---------|---------|----------|\n",
    "| **Squared error** | $(y - \\hat{y})^2$ | Yes (strictly) | Linear regression |\n",
    "| **Cross-entropy** | $-y \\log \\hat{y} - (1-y)\\log(1-\\hat{y})$ | Yes (strictly) | Logistic regression |\n",
    "| **Hinge loss** | $\\max(0, 1 - y \\hat{y})$ | Yes (not strictly) | SVM |\n",
    "| **$\\ell_2$ penalty** | $\\|\\mathbf{w}\\|_2^2$ | Yes (strictly) | Ridge regression |\n",
    "| **$\\ell_1$ penalty** | $\\|\\mathbf{w}\\|_1$ | Yes (not strictly) | LASSO |\n",
    "| **Neural network loss** | Complex composition | No (generally) | Deep learning |\n",
    "\n",
    "#### Key Insight\n",
    "\n",
    "A sum of convex functions is convex. This is why \"loss + regularization\" stays convex when both components are convex: the composite objective inherits the nice optimization properties of its parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize common ML loss functions and their convexity\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "z = np.linspace(-3, 3, 300)\n",
    "\n",
    "# Squared loss\n",
    "ax = axes[0]\n",
    "ax.plot(z, z**2, 'b-', linewidth=2.5)\n",
    "ax.set_title('Squared Loss: (y - ŷ)²', fontsize=12)\n",
    "ax.set_xlabel('y - ŷ (residual)')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.text(0.05, 0.85, 'Convex ✓\\nSmooth ✓\\nStrictly convex ✓',\n",
    "        transform=ax.transAxes, fontsize=10, color='green',\n",
    "        bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Hinge loss\n",
    "ax = axes[1]\n",
    "hinge = np.maximum(0, 1 - z)\n",
    "ax.plot(z, hinge, 'r-', linewidth=2.5)\n",
    "ax.set_title('Hinge Loss: max(0, 1 - yŷ)', fontsize=12)\n",
    "ax.set_xlabel('y·ŷ (margin)')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.text(0.05, 0.85, 'Convex ✓\\nNot smooth ✗\\nNot strictly convex ✗',\n",
    "        transform=ax.transAxes, fontsize=10, color='orange',\n",
    "        bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Cross-entropy / logistic loss\n",
    "ax = axes[2]\n",
    "logistic_loss = np.log(1 + np.exp(-z))\n",
    "ax.plot(z, logistic_loss, 'purple', linewidth=2.5)\n",
    "ax.set_title('Logistic Loss: log(1 + e⁻ᶻ)', fontsize=12)\n",
    "ax.set_xlabel('y·ŷ (margin)')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.text(0.05, 0.85, 'Convex ✓\\nSmooth ✓\\nStrictly convex ✓',\n",
    "        transform=ax.transAxes, fontsize=10, color='green',\n",
    "        bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"All three are convex — gradient descent will find the global minimum.\")\n",
    "print(\"Squared loss is smooth and easy to optimize.\")\n",
    "print(\"Hinge loss has a 'kink' at 1, requiring subgradient methods.\")\n",
    "print(\"Logistic loss is a smooth approximation of hinge loss.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-23",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Constrained Optimization & Lagrange Multipliers\n",
    "\n",
    "### Intuitive Explanation\n",
    "\n",
    "How do you minimize a function when you must stay on a specific curve or surface? This is the **constrained optimization** problem.\n",
    "\n",
    "**The setup:**\n",
    "$$\\min_{x} f(x) \\quad \\text{subject to} \\quad g(x) = 0$$\n",
    "\n",
    "**Lagrange's insight (1788):** At the constrained optimum, the gradient of the objective $\\nabla f$ must be parallel to the gradient of the constraint $\\nabla g$. If they were not parallel, you could slide along the constraint and still improve the objective.\n",
    "\n",
    "This gives us the **Lagrangian**:\n",
    "$$\\mathcal{L}(x, \\lambda) = f(x) + \\lambda \\, g(x)$$\n",
    "\n",
    "The optimal point satisfies:\n",
    "$$\\nabla_x \\mathcal{L} = 0 \\quad \\text{and} \\quad \\nabla_\\lambda \\mathcal{L} = 0$$\n",
    "\n",
    "The variable $\\lambda$ is called the **Lagrange multiplier**. It tells you the rate at which the optimal objective value changes as you relax the constraint.\n",
    "\n",
    "**What this means:** Imagine hiking downhill but you must stay on a trail (the constraint). You stop when the steepest downhill direction is perpendicular to the trail — because moving along the trail no longer takes you downhill."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geometric visualization of Lagrange multipliers\n",
    "# Minimize f(x,y) = x^2 + y^2 subject to x + y = 4\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "x_range = np.linspace(-1, 6, 300)\n",
    "y_range = np.linspace(-1, 6, 300)\n",
    "X, Y = np.meshgrid(x_range, y_range)\n",
    "Z = X**2 + Y**2  # objective\n",
    "\n",
    "# Contours of the objective\n",
    "levels = [1, 2, 4, 8, 12, 16, 20, 25, 32]\n",
    "contour = ax.contour(X, Y, Z, levels=levels, cmap='Blues', alpha=0.7)\n",
    "ax.clabel(contour, fmt='%.0f', fontsize=9)\n",
    "\n",
    "# Constraint: x + y = 4\n",
    "ax.plot(x_range, 4 - x_range, 'r-', linewidth=3, label='Constraint: x + y = 4')\n",
    "\n",
    "# Optimal point: x = y = 2 (by symmetry, or solve the system)\n",
    "opt_x, opt_y = 2, 2\n",
    "ax.plot(opt_x, opt_y, 'r*', markersize=20, zorder=5, label='Constrained optimum (2, 2)')\n",
    "\n",
    "# Draw gradients at the optimal point\n",
    "# grad f = (2x, 2y) = (4, 4)\n",
    "# grad g = (1, 1)  where g(x,y) = x + y - 4\n",
    "scale = 0.3\n",
    "ax.annotate('', xy=(opt_x + 4*scale, opt_y + 4*scale), xytext=(opt_x, opt_y),\n",
    "            arrowprops=dict(arrowstyle='->', color='blue', lw=2.5))\n",
    "ax.text(opt_x + 4*scale + 0.1, opt_y + 4*scale + 0.1, '∇f = (4, 4)',\n",
    "        fontsize=11, color='blue', fontweight='bold')\n",
    "\n",
    "ax.annotate('', xy=(opt_x + 1*scale*2, opt_y + 1*scale*2), xytext=(opt_x, opt_y),\n",
    "            arrowprops=dict(arrowstyle='->', color='green', lw=2.5))\n",
    "ax.text(opt_x + 1*scale*2 - 0.7, opt_y + 1*scale*2 + 0.2, '∇g = (1, 1)',\n",
    "        fontsize=11, color='green', fontweight='bold')\n",
    "\n",
    "# Unconstrained optimum\n",
    "ax.plot(0, 0, 'b*', markersize=15, alpha=0.4, label='Unconstrained optimum (0, 0)')\n",
    "\n",
    "ax.set_xlabel('x', fontsize=12)\n",
    "ax.set_ylabel('y', fontsize=12)\n",
    "ax.set_title('Lagrange Multipliers: Gradient Alignment at Optimum', fontsize=14)\n",
    "ax.legend(fontsize=10, loc='upper right')\n",
    "ax.set_aspect('equal')\n",
    "ax.set_xlim(-1, 6)\n",
    "ax.set_ylim(-1, 6)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"At the constrained optimum (2, 2):\")\n",
    "print(\"  ∇f = (4, 4) is parallel to ∇g = (1, 1)\")\n",
    "print(\"  λ = 4 (the Lagrange multiplier: ∇f = λ·∇g)\")\n",
    "print(\"  The multiplier λ = 4 means: relaxing the constraint by ε\")\n",
    "print(\"  would improve the objective by approximately 4ε.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solving constrained optimization with scipy.optimize.minimize\n",
    "\n",
    "# Problem: minimize x^2 + y^2 subject to x + y = 4\n",
    "def objective(xy):\n",
    "    return xy[0]**2 + xy[1]**2\n",
    "\n",
    "def constraint_eq(xy):\n",
    "    return xy[0] + xy[1] - 4  # equals zero at feasibility\n",
    "\n",
    "# Using SLSQP (Sequential Least Squares Quadratic Programming)\n",
    "result = minimize(\n",
    "    objective,\n",
    "    x0=[0, 0],  # starting guess\n",
    "    method='SLSQP',\n",
    "    constraints={'type': 'eq', 'fun': constraint_eq}\n",
    ")\n",
    "\n",
    "print(\"=== Constrained Optimization with scipy ===\")\n",
    "print(f\"Optimal point: ({result.x[0]:.4f}, {result.x[1]:.4f})\")\n",
    "print(f\"Optimal value: {result.fun:.4f}\")\n",
    "print(f\"Constraint satisfied: {np.isclose(constraint_eq(result.x), 0)}\")\n",
    "print(f\"Solver converged: {result.success}\")\n",
    "\n",
    "# Verify: analytical solution is (2, 2) with f = 8\n",
    "print(f\"\\nAnalytical solution: (2, 2), f = 8\")\n",
    "print(f\"Match: {np.allclose(result.x, [2, 2]) and np.isclose(result.fun, 8)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-26",
   "metadata": {},
   "source": [
    "### KKT Conditions: The Full Picture\n",
    "\n",
    "Lagrange multipliers handle **equality** constraints. For **inequality** constraints ($g_i(x) \\leq 0$), we need the **Karush-Kuhn-Tucker (KKT) conditions**, which generalize Lagrange multipliers.\n",
    "\n",
    "For the problem:\n",
    "$$\\min_x f(x) \\quad \\text{s.t.} \\quad g_i(x) \\leq 0, \\quad h_j(x) = 0$$\n",
    "\n",
    "The KKT conditions are:\n",
    "\n",
    "| Condition | Statement | Intuition |\n",
    "|-----------|-----------|----------|\n",
    "| **Stationarity** | $\\nabla f + \\sum \\mu_i \\nabla g_i + \\sum \\lambda_j \\nabla h_j = 0$ | Gradient balance at optimum |\n",
    "| **Primal feasibility** | $g_i(x) \\leq 0, \\; h_j(x) = 0$ | Solution must be feasible |\n",
    "| **Dual feasibility** | $\\mu_i \\geq 0$ | Inequality multipliers are non-negative |\n",
    "| **Complementary slackness** | $\\mu_i \\, g_i(x) = 0$ | Either constraint is active or multiplier is zero |\n",
    "\n",
    "**What this means:** \n",
    "- If a constraint is **not active** ($g_i(x) < 0$, you are strictly inside the boundary), then $\\mu_i = 0$ — the constraint does not affect the solution.\n",
    "- If a constraint **is active** ($g_i(x) = 0$, you are on the boundary), then $\\mu_i > 0$ — the constraint is \"pushing back\" and preventing you from going further.\n",
    "\n",
    "For **convex** problems, the KKT conditions are both necessary and sufficient for optimality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize KKT conditions: inequality constraints\n",
    "# Minimize f(x,y) = (x-3)^2 + (y-3)^2 subject to x + y <= 4, x >= 0, y >= 0\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "x_range = np.linspace(-0.5, 5, 300)\n",
    "y_range = np.linspace(-0.5, 5, 300)\n",
    "X, Y = np.meshgrid(x_range, y_range)\n",
    "\n",
    "# Case 1: Unconstrained optimum is feasible\n",
    "ax = axes[0]\n",
    "Z = (X - 1.5)**2 + (Y - 1)**2\n",
    "contour = ax.contour(X, Y, Z, levels=10, cmap='Blues', alpha=0.7)\n",
    "ax.clabel(contour, fmt='%.1f', fontsize=8)\n",
    "\n",
    "# Feasible region: x + y <= 4, x >= 0, y >= 0\n",
    "feas_verts = np.array([[0, 0], [4, 0], [0, 4]])\n",
    "feas_poly = Polygon(feas_verts, alpha=0.15, color='green', label='Feasible region')\n",
    "ax.add_patch(feas_poly)\n",
    "ax.plot([0, 4], [4, 0], 'g-', linewidth=2)\n",
    "\n",
    "ax.plot(1.5, 1, 'r*', markersize=15, zorder=5, label='Optimum (1.5, 1) — interior')\n",
    "ax.set_title('Constraint NOT Active (μ = 0)', fontsize=13)\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "ax.legend(fontsize=9)\n",
    "ax.set_aspect('equal')\n",
    "ax.set_xlim(-0.5, 5)\n",
    "ax.set_ylim(-0.5, 5)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Case 2: Unconstrained optimum is infeasible → constraint active\n",
    "ax = axes[1]\n",
    "Z2 = (X - 3)**2 + (Y - 3)**2\n",
    "contour = ax.contour(X, Y, Z2, levels=10, cmap='Blues', alpha=0.7)\n",
    "ax.clabel(contour, fmt='%.1f', fontsize=8)\n",
    "\n",
    "feas_poly2 = Polygon(feas_verts, alpha=0.15, color='green', label='Feasible region')\n",
    "ax.add_patch(feas_poly2)\n",
    "ax.plot([0, 4], [4, 0], 'g-', linewidth=2)\n",
    "\n",
    "# Constrained optimum: closest point on x+y=4 to (3,3) is (2,2)\n",
    "ax.plot(3, 3, 'b*', markersize=12, alpha=0.4, label='Unconstrained optimum (3, 3)')\n",
    "ax.plot(2, 2, 'r*', markersize=15, zorder=5, label='Constrained optimum (2, 2) — on boundary')\n",
    "ax.annotate('', xy=(2, 2), xytext=(3, 3),\n",
    "            arrowprops=dict(arrowstyle='->', color='red', lw=1.5, ls='--'))\n",
    "\n",
    "ax.set_title('Constraint IS Active (μ > 0)', fontsize=13)\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "ax.legend(fontsize=9)\n",
    "ax.set_aspect('equal')\n",
    "ax.set_xlim(-0.5, 5)\n",
    "ax.set_ylim(-0.5, 5)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Left: The unconstrained optimum (1.5, 1) is inside the feasible region.\")\n",
    "print(\"  → The constraint is NOT active, and the multiplier μ = 0.\")\n",
    "print(\"  → The constraint doesn't affect the solution at all.\")\n",
    "print(\"\\nRight: The unconstrained optimum (3, 3) is OUTSIDE the feasible region.\")\n",
    "print(\"  → The constraint IS active, pushing the solution to (2, 2) on the boundary.\")\n",
    "print(\"  → The multiplier μ > 0, representing the 'cost' of the constraint.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-28",
   "metadata": {},
   "source": [
    "### Deep Dive: Complementary Slackness — The Either/Or Rule\n",
    "\n",
    "Complementary slackness ($\\mu_i \\cdot g_i(x) = 0$) is perhaps the most elegant condition. It says:\n",
    "\n",
    "For each inequality constraint, exactly one of two things is true:\n",
    "1. The constraint is **slack** ($g_i(x) < 0$): the boundary is not reached, so the multiplier is zero ($\\mu_i = 0$).\n",
    "2. The constraint is **tight** ($g_i(x) = 0$): the boundary is hit, and the multiplier is positive ($\\mu_i > 0$).\n",
    "\n",
    "In ML terms:\n",
    "- In an SVM, most data points have $\\mu_i = 0$ — they do not affect the decision boundary.\n",
    "- Only the **support vectors** (points on the margin boundary) have $\\mu_i > 0$.\n",
    "- This is why SVMs are sparse: the solution depends only on a few critical data points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-29",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Connection to Machine Learning\n",
    "\n",
    "### ML as Optimization\n",
    "\n",
    "Nearly every ML algorithm can be framed as an optimization problem:\n",
    "\n",
    "| Algorithm | Objective | Constraints | Type |\n",
    "|-----------|-----------|-------------|------|\n",
    "| **Linear regression** | $\\min_w \\|Xw - y\\|^2$ | None | Unconstrained convex |\n",
    "| **Ridge regression** | $\\min_w \\|Xw - y\\|^2 + \\alpha\\|w\\|^2$ | None (equivalent to constrained) | Unconstrained convex |\n",
    "| **LASSO** | $\\min_w \\|Xw - y\\|^2 + \\alpha\\|w\\|_1$ | None (equivalent to constrained) | Unconstrained convex |\n",
    "| **Logistic regression** | $\\min_w \\sum \\log(1 + e^{-y_i w^T x_i})$ | None | Unconstrained convex |\n",
    "| **SVM (primal)** | $\\min_{w,b} \\frac{1}{2}\\|w\\|^2$ | $y_i(w^T x_i + b) \\geq 1$ | Constrained convex (QP) |\n",
    "| **SVM (dual)** | $\\max_\\alpha \\sum \\alpha_i - \\frac{1}{2}\\sum \\alpha_i \\alpha_j y_i y_j x_i^T x_j$ | $0 \\leq \\alpha_i \\leq C$ | Constrained convex (QP) |\n",
    "| **Neural networks** | $\\min_\\theta \\mathcal{L}(f_\\theta(X), y)$ | None | Unconstrained **non-convex** |\n",
    "\n",
    "Notice: everything except neural networks is convex. This is why classical ML has nice convergence guarantees, while deep learning requires more art (learning rate schedules, initialization strategies, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate: SVM as a constrained optimization problem\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "# Generate linearly separable data\n",
    "np.random.seed(42)\n",
    "X_train, y_train = make_blobs(n_samples=40, centers=2, cluster_std=1.2, random_state=42)\n",
    "y_train = 2*y_train - 1  # Convert to {-1, +1}\n",
    "\n",
    "# Train SVM\n",
    "svm = SVC(kernel='linear', C=10.0)\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Extract the optimization solution\n",
    "w = svm.coef_[0]\n",
    "b = svm.intercept_[0]\n",
    "support_vectors = svm.support_vectors_\n",
    "n_support = len(support_vectors)\n",
    "\n",
    "print(\"=== SVM as Optimization ===\")\n",
    "print(f\"Weight vector w: [{w[0]:.4f}, {w[1]:.4f}]\")\n",
    "print(f\"Bias b: {b:.4f}\")\n",
    "print(f\"Margin width: {2 / np.linalg.norm(w):.4f}\")\n",
    "print(f\"Number of support vectors: {n_support} out of {len(X_train)} points\")\n",
    "print(f\"\\nOnly {n_support}/{len(X_train)} points have non-zero dual variables (α > 0).\")\n",
    "print(\"This is complementary slackness in action!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the SVM solution with margin and support vectors\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "# Plot data points\n",
    "colors = ['blue' if y == -1 else 'red' for y in y_train]\n",
    "for cls, color, label in [(-1, 'blue', 'Class -1'), (1, 'red', 'Class +1')]:\n",
    "    mask = y_train == cls\n",
    "    ax.scatter(X_train[mask, 0], X_train[mask, 1], c=color, s=50,\n",
    "               edgecolors='k', linewidth=0.5, label=label, alpha=0.7)\n",
    "\n",
    "# Plot support vectors\n",
    "ax.scatter(support_vectors[:, 0], support_vectors[:, 1], s=200,\n",
    "           facecolors='none', edgecolors='green', linewidths=2.5,\n",
    "           label=f'Support vectors ({n_support})', zorder=5)\n",
    "\n",
    "# Plot decision boundary and margins\n",
    "x_boundary = np.linspace(X_train[:, 0].min() - 1, X_train[:, 0].max() + 1, 200)\n",
    "\n",
    "# Decision boundary: w[0]*x + w[1]*y + b = 0\n",
    "y_boundary = -(w[0] * x_boundary + b) / w[1]\n",
    "y_margin_pos = -(w[0] * x_boundary + b - 1) / w[1]\n",
    "y_margin_neg = -(w[0] * x_boundary + b + 1) / w[1]\n",
    "\n",
    "ax.plot(x_boundary, y_boundary, 'k-', linewidth=2, label='Decision boundary')\n",
    "ax.plot(x_boundary, y_margin_pos, 'k--', linewidth=1, alpha=0.5, label='Margin boundaries')\n",
    "ax.plot(x_boundary, y_margin_neg, 'k--', linewidth=1, alpha=0.5)\n",
    "ax.fill_between(x_boundary, y_margin_neg, y_margin_pos, alpha=0.08, color='green')\n",
    "\n",
    "ax.set_xlabel('Feature 1', fontsize=12)\n",
    "ax.set_ylabel('Feature 2', fontsize=12)\n",
    "ax.set_title('SVM: Maximum-Margin Classifier (Constrained Optimization)', fontsize=14)\n",
    "ax.legend(fontsize=10)\n",
    "ax.set_xlim(X_train[:, 0].min() - 1, X_train[:, 0].max() + 1)\n",
    "ax.set_ylim(X_train[:, 1].min() - 1, X_train[:, 1].max() + 1)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"The SVM solves: min ½||w||² subject to yᵢ(w·xᵢ + b) ≥ 1\")\n",
    "print(\"This is a quadratic program (QP) — convex with linear constraints.\")\n",
    "print(\"The support vectors are the points with active constraints (on the margin).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate: Regularization as a constraint\n",
    "# Ridge regression: min ||Xw - y||^2 + alpha * ||w||^2\n",
    "# This is equivalent to: min ||Xw - y||^2 subject to ||w||^2 <= t\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Create a simple regression problem\n",
    "np.random.seed(42)\n",
    "w_true = np.array([3, -2])\n",
    "X_reg = np.random.randn(20, 2)\n",
    "y_reg = X_reg @ w_true + 0.5 * np.random.randn(20)\n",
    "\n",
    "# Compute loss surface\n",
    "w1_range = np.linspace(-1, 6, 200)\n",
    "w2_range = np.linspace(-5, 2, 200)\n",
    "W1, W2 = np.meshgrid(w1_range, w2_range)\n",
    "\n",
    "Loss = np.zeros_like(W1)\n",
    "for i in range(len(w1_range)):\n",
    "    for j in range(len(w2_range)):\n",
    "        w_test = np.array([W1[j, i], W2[j, i]])\n",
    "        Loss[j, i] = np.sum((X_reg @ w_test - y_reg)**2) / len(y_reg)\n",
    "\n",
    "# Left: Regularization view (penalized objective)\n",
    "ax = axes[0]\n",
    "ax.contour(W1, W2, Loss, levels=15, cmap='Blues', alpha=0.7)\n",
    "\n",
    "# Show effect of different regularization strengths\n",
    "for alpha, color, name in [(0, 'red', 'No reg (α=0)'), (2, 'orange', 'α=2'),\n",
    "                            (10, 'green', 'α=10')]:\n",
    "    # Analytical solution: (X^T X + alpha*I)^{-1} X^T y\n",
    "    w_ridge = np.linalg.solve(X_reg.T @ X_reg + alpha * np.eye(2), X_reg.T @ y_reg)\n",
    "    ax.plot(w_ridge[0], w_ridge[1], '*', color=color, markersize=15, label=name, zorder=5)\n",
    "\n",
    "ax.set_xlabel('w₁', fontsize=12)\n",
    "ax.set_ylabel('w₂', fontsize=12)\n",
    "ax.set_title('Regularization Shrinks Weights Toward Origin', fontsize=13)\n",
    "ax.legend(fontsize=10)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Right: Constraint view (norm ball)\n",
    "ax = axes[1]\n",
    "ax.contour(W1, W2, Loss, levels=15, cmap='Blues', alpha=0.7)\n",
    "\n",
    "# L2 constraint ball\n",
    "theta = np.linspace(0, 2*np.pi, 100)\n",
    "for radius, color, ls in [(2.0, 'green', '-'), (3.0, 'orange', '--'), (5.0, 'red', ':')]:\n",
    "    ax.plot(radius*np.cos(theta), radius*np.sin(theta), color=color, linewidth=2,\n",
    "            linestyle=ls, label=f'||w||₂ ≤ {radius}')\n",
    "\n",
    "# OLS solution (no constraint)\n",
    "w_ols = np.linalg.solve(X_reg.T @ X_reg, X_reg.T @ y_reg)\n",
    "ax.plot(w_ols[0], w_ols[1], 'r*', markersize=15, label='OLS (unconstrained)', zorder=5)\n",
    "\n",
    "ax.set_xlabel('w₁', fontsize=12)\n",
    "ax.set_ylabel('w₂', fontsize=12)\n",
    "ax.set_title('Equivalent View: Constraint on Weight Norm', fontsize=13)\n",
    "ax.legend(fontsize=9)\n",
    "ax.set_aspect('equal')\n",
    "ax.set_xlim(-1, 6)\n",
    "ax.set_ylim(-5, 2)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Left: Adding α||w||² to the loss shrinks weights toward zero.\")\n",
    "print(\"Right: Equivalent to constraining ||w||₂ ≤ t (Lagrangian duality).\")\n",
    "print(\"\\nThis equivalence is Lagrangian duality in action:\")\n",
    "print(\"  Penalized form: min L(w) + α·R(w)\")\n",
    "print(\"  Constrained form: min L(w) s.t. R(w) ≤ t\")\n",
    "print(\"  The multiplier α and the constraint bound t are dual to each other.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-33",
   "metadata": {},
   "source": [
    "### Why This Matters in Machine Learning\n",
    "\n",
    "| Optimization Concept | ML Application | How It's Used |\n",
    "|----------------------|----------------|---------------|\n",
    "| **Objective function** | Loss function | Measures how wrong the model is |\n",
    "| **Constraints** | Regularization, fairness constraints | Limits model complexity or enforces properties |\n",
    "| **Feasible region** | Weight space satisfying constraints | Set of allowed model parameters |\n",
    "| **Convexity** | Guarantees on convergence | Convex losses guarantee finding the best model |\n",
    "| **Lagrange multipliers** | SVM dual, regularization theory | Enable kernel trick, explain regularization |\n",
    "| **KKT conditions** | Support vectors, active constraints | Identify which data points matter |\n",
    "| **Duality** | SVM formulation, ELBO in VAEs | Provides alternative problem views |\n",
    "| **Linear programming** | Network flow, assignment, scheduling | Combinatorial ML problems |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-34",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercises\n",
    "\n",
    "### Exercise 1: Formulate and Solve an LP\n",
    "\n",
    "A bakery makes cakes and cookies.\n",
    "- Each cake uses 3 cups of flour and 1 egg, and sells for \\$8.\n",
    "- Each batch of cookies uses 1 cup of flour and 2 eggs, and sells for \\$5.\n",
    "- The bakery has 12 cups of flour and 8 eggs available.\n",
    "\n",
    "**Task:** Formulate this as an LP and solve it using `scipy.optimize.linprog`. How many cakes and cookie batches should the bakery make to maximize revenue?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCISE 1: Solve the bakery LP\n",
    "def solve_bakery_lp():\n",
    "    \"\"\"\n",
    "    Formulate and solve the bakery LP.\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (n_cakes, n_cookies, max_revenue)\n",
    "    \"\"\"\n",
    "    # TODO: Implement this!\n",
    "    # Hint: linprog MINIMIZES, so negate the objective for maximization.\n",
    "    # Hint: c = [-8, -5] for the negated profit objective\n",
    "    # Hint: A_ub represents [flour_constraint, egg_constraint]\n",
    "    \n",
    "    pass  # Replace with your solution\n",
    "\n",
    "# Test\n",
    "result = solve_bakery_lp()\n",
    "if result is not None:\n",
    "    n_cakes, n_cookies, max_revenue = result\n",
    "    print(f\"Cakes: {n_cakes:.2f}\")\n",
    "    print(f\"Cookie batches: {n_cookies:.2f}\")\n",
    "    print(f\"Maximum revenue: ${max_revenue:.2f}\")\n",
    "    \n",
    "    # Expected: cakes=2.4, cookies=4.8/2=2.8... let's compute\n",
    "    expected_revenue = 34.40\n",
    "    print(f\"\\nExpected revenue: ${expected_revenue:.2f}\")\n",
    "    print(f\"Correct: {np.isclose(max_revenue, expected_revenue, atol=0.1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-36",
   "metadata": {},
   "source": [
    "### Exercise 2: Verify Convexity\n",
    "\n",
    "Write a function that numerically checks whether a 1D function is convex over a given interval by testing the secant line condition at random points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCISE 2: Check convexity numerically\n",
    "def is_convex(f, x_min, x_max, n_tests=1000):\n",
    "    \"\"\"\n",
    "    Numerically check if a function is convex over [x_min, x_max].\n",
    "    \n",
    "    A function is convex if for all x, y in the interval and lambda in [0,1]:\n",
    "        f(lambda*x + (1-lambda)*y) <= lambda*f(x) + (1-lambda)*f(y)\n",
    "    \n",
    "    Args:\n",
    "        f: Function to test\n",
    "        x_min, x_max: Interval endpoints\n",
    "        n_tests: Number of random tests\n",
    "    \n",
    "    Returns:\n",
    "        True if all tests pass (function appears convex), False otherwise\n",
    "    \"\"\"\n",
    "    # TODO: Implement this!\n",
    "    # Hint: For each test, pick random x, y in [x_min, x_max]\n",
    "    #       and random lambda in [0, 1], then check the inequality.\n",
    "    \n",
    "    pass  # Replace with your solution\n",
    "\n",
    "# Test with known functions\n",
    "f_quadratic = lambda x: x**2          # convex\n",
    "f_absolute = lambda x: np.abs(x)       # convex\n",
    "f_sine = lambda x: np.sin(x)           # NOT convex over [-pi, pi]\n",
    "f_exp = lambda x: np.exp(x)            # convex\n",
    "\n",
    "if is_convex is not None and is_convex(f_quadratic, -5, 5) is not None:\n",
    "    print(f\"x²: convex = {is_convex(f_quadratic, -5, 5)}\")\n",
    "    print(f\"|x|: convex = {is_convex(f_absolute, -5, 5)}\")\n",
    "    print(f\"sin(x) on [-π,π]: convex = {is_convex(f_sine, -np.pi, np.pi)}\")\n",
    "    print(f\"eˣ: convex = {is_convex(f_exp, -5, 5)}\")\n",
    "    print(f\"\\nExpected: True, True, False, True\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-38",
   "metadata": {},
   "source": [
    "### Exercise 3: Lagrange Multipliers by Hand (with Verification)\n",
    "\n",
    "Solve this problem analytically, then verify with `scipy.optimize.minimize`:\n",
    "\n",
    "$$\\min_{x,y} \\; x^2 + 2y^2 \\quad \\text{subject to} \\quad x + y = 3$$\n",
    "\n",
    "**Steps:**\n",
    "1. Write the Lagrangian: $\\mathcal{L} = x^2 + 2y^2 + \\lambda(x + y - 3)$\n",
    "2. Set partial derivatives to zero and solve\n",
    "3. Verify numerically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCISE 3: Lagrange multipliers\n",
    "def solve_lagrange_problem():\n",
    "    \"\"\"\n",
    "    Solve: min x^2 + 2y^2 subject to x + y = 3\n",
    "    \n",
    "    Analytical steps:\n",
    "    L = x^2 + 2y^2 + lambda*(x + y - 3)\n",
    "    dL/dx = 2x + lambda = 0      → x = -lambda/2\n",
    "    dL/dy = 4y + lambda = 0      → y = -lambda/4\n",
    "    dL/dlambda = x + y - 3 = 0   → -lambda/2 - lambda/4 = 3\n",
    "                                  → -3*lambda/4 = 3\n",
    "                                  → lambda = -4\n",
    "    So: x = 2, y = 1, lambda = -4\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (x_opt, y_opt, lambda_opt, f_opt)\n",
    "    \"\"\"\n",
    "    # TODO: Return the analytical solution\n",
    "    # Hint: Follow the steps in the docstring above\n",
    "    \n",
    "    pass  # Replace with your solution\n",
    "\n",
    "# Numerical verification\n",
    "result_num = minimize(\n",
    "    lambda xy: xy[0]**2 + 2*xy[1]**2,\n",
    "    x0=[0, 0],\n",
    "    method='SLSQP',\n",
    "    constraints={'type': 'eq', 'fun': lambda xy: xy[0] + xy[1] - 3}\n",
    ")\n",
    "\n",
    "print(\"=== Numerical Solution ===\")\n",
    "print(f\"x = {result_num.x[0]:.4f}, y = {result_num.x[1]:.4f}\")\n",
    "print(f\"f(x,y) = {result_num.fun:.4f}\")\n",
    "\n",
    "if solve_lagrange_problem is not None and solve_lagrange_problem() is not None:\n",
    "    x_opt, y_opt, lambda_opt, f_opt = solve_lagrange_problem()\n",
    "    print(f\"\\n=== Your Analytical Solution ===\")\n",
    "    print(f\"x = {x_opt}, y = {y_opt}, λ = {lambda_opt}\")\n",
    "    print(f\"f(x,y) = {f_opt}\")\n",
    "    print(f\"\\nMatch: {np.allclose([x_opt, y_opt], result_num.x, atol=0.01)}\")\n",
    "    print(f\"Expected: x=2, y=1, λ=-4, f=6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-40",
   "metadata": {},
   "source": [
    "### Exercise 4: Optimization Landscape Explorer\n",
    "\n",
    "Write a function that takes a 2D objective function and visualizes:\n",
    "1. The contour plot\n",
    "2. The gradient descent path from a given starting point\n",
    "3. The final (approximate) optimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCISE 4: Build an optimization landscape explorer\n",
    "def explore_landscape(f, grad_f, x0, lr=0.01, n_steps=200,\n",
    "                      x_range=(-5, 5), y_range=(-5, 5)):\n",
    "    \"\"\"\n",
    "    Visualize a 2D optimization landscape with gradient descent path.\n",
    "    \n",
    "    Args:\n",
    "        f: Objective function f(x, y) -> scalar\n",
    "        grad_f: Gradient function grad_f(x, y) -> (df/dx, df/dy)\n",
    "        x0: Starting point [x, y]\n",
    "        lr: Learning rate\n",
    "        n_steps: Number of gradient descent steps\n",
    "        x_range: (min, max) for x axis\n",
    "        y_range: (min, max) for y axis\n",
    "    \"\"\"\n",
    "    # TODO: Implement this!\n",
    "    # Step 1: Create meshgrid and compute Z = f(X, Y)\n",
    "    # Step 2: Run gradient descent, storing the path\n",
    "    # Step 3: Plot contours + path + start/end markers\n",
    "    # Hint: Use ax.contourf for filled contours and ax.plot for the path\n",
    "    \n",
    "    pass  # Replace with your solution\n",
    "\n",
    "# Test with Rosenbrock function (a classic test function)\n",
    "f_rosen = lambda x, y: (1 - x)**2 + 100*(y - x**2)**2\n",
    "grad_rosen = lambda x, y: (\n",
    "    -2*(1 - x) - 400*x*(y - x**2),\n",
    "    200*(y - x**2)\n",
    ")\n",
    "\n",
    "print(\"Implement explore_landscape() to visualize gradient descent on the\")\n",
    "print(\"Rosenbrock function. The minimum is at (1, 1).\")\n",
    "print(\"Try different learning rates and starting points!\")\n",
    "\n",
    "# Uncomment after implementing:\n",
    "# explore_landscape(f_rosen, grad_rosen, x0=[-1, -1], lr=0.001, n_steps=5000,\n",
    "#                   x_range=(-2, 2), y_range=(-1, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-42",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "- **Optimization** is the process of finding the best solution from a feasible set. It requires an objective function, decision variables, and (optionally) constraints.\n",
    "- **Linear programming** optimizes a linear objective subject to linear constraints. The solution always occurs at a vertex of the feasible polytope.\n",
    "- **The Simplex method** solves LPs by hopping between adjacent vertices, always improving the objective.\n",
    "- **Duality** provides an alternative view of any LP. Strong duality means primal and dual have the same optimal value.\n",
    "- **Convexity** is the key property that guarantees local minima are global minima. Most classical ML algorithms are convex.\n",
    "- **Lagrange multipliers** solve equality-constrained problems by requiring gradient alignment at the optimum.\n",
    "- **KKT conditions** generalize Lagrange multipliers to inequality constraints. Complementary slackness identifies active constraints.\n",
    "- **ML is optimization**: SVMs solve QPs, regularization is dual to constraints, and loss functions are designed to be convex."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-43",
   "metadata": {},
   "source": [
    "### Connection to Machine Learning\n",
    "\n",
    "| Concept from this Notebook | Where You Will See It in ML |\n",
    "|---------------------------|-----------------------------|\n",
    "| Objective function | Every loss function (MSE, cross-entropy, hinge) |\n",
    "| Feasible region / constraints | Regularization ($\\ell_1$, $\\ell_2$), fairness constraints |\n",
    "| Convexity | Guarantees for logistic regression, SVM, LASSO |\n",
    "| Non-convexity | Neural network training challenges |\n",
    "| Lagrange multipliers / KKT | SVM support vectors, dual formulations |\n",
    "| Duality | Kernel trick in SVMs, ELBO in variational inference |\n",
    "| Linear programming | Resource allocation, network optimization |\n",
    "| Gradient descent (preview) | The topic of the next notebook! |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-44",
   "metadata": {},
   "source": [
    "### Checklist\n",
    "\n",
    "Before moving on, make sure you can:\n",
    "\n",
    "- [ ] Define an optimization problem with objective, variables, and constraints\n",
    "- [ ] Formulate an LP in standard form and solve it with `linprog`\n",
    "- [ ] Explain why LP solutions occur at vertices\n",
    "- [ ] Describe the Simplex method's vertex-hopping strategy\n",
    "- [ ] State weak and strong duality theorems\n",
    "- [ ] Distinguish convex from non-convex functions\n",
    "- [ ] Explain why convexity guarantees a global optimum\n",
    "- [ ] Set up and solve a Lagrangian for equality constraints\n",
    "- [ ] State the four KKT conditions and explain complementary slackness\n",
    "- [ ] Frame an SVM as a constrained optimization problem\n",
    "- [ ] Explain regularization as a Lagrangian constraint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-45",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "Continue to **Part 1.6: Gradient-Based Optimization** where we will cover:\n",
    "- Gradient descent and its variants (SGD, momentum, Adam)\n",
    "- Learning rate schedules and convergence theory\n",
    "- Automatic differentiation\n",
    "- How these methods actually train neural networks\n",
    "\n",
    "**Looking ahead:** Now that you understand *what* optimization is and *when* it works well (convexity), the next notebook focuses on *how* we actually solve optimization problems in practice — with gradients. Every deep learning training loop is gradient descent applied to a (usually non-convex) loss function."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
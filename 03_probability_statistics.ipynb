{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Part 1.3: Probability & Statistics for Deep Learning \u2014 The Formula 1 Edition\n\nProbability and statistics are essential for understanding:\n- How models make predictions (probabilistic outputs)\n- How we train models (maximum likelihood)\n- How we measure uncertainty and information\n\n**The F1 Connection**: Formula 1 is a sport drowning in probability. Will it rain at Spa? What's the chance of a safety car at Monaco? How do lap times distribute around the mean? Every race strategy decision \u2014 when to pit, which tire compound to choose, whether to risk a one-stop \u2014 is a bet against a probability distribution. The teams that model these distributions best win championships.\n\n## Learning Objectives\n- [ ] Work with common probability distributions\n- [ ] Apply Bayes' theorem to update beliefs\n- [ ] Derive MLE estimators for simple distributions\n- [ ] Calculate entropy and KL divergence\n\n---"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from scipy.special import comb\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 1. Probability Basics\n\n### Random Variables\n\nA **random variable** is a variable whose value is determined by a random process.\n\n- **Discrete**: Takes on countable values (e.g., coin flips, dice rolls)\n- **Continuous**: Takes on any value in a range (e.g., height, temperature)\n\n**F1 analogy**: A driver's finishing position is a discrete random variable (1st, 2nd, ..., DNF). Their lap time is a continuous random variable \u2014 it can be 1:31.204 or 1:31.205 or anything in between.\n\n### Probability Distributions\n\nA **probability distribution** describes the likelihood of each possible outcome.\n\n- **PMF** (Probability Mass Function): For discrete variables, $P(X = x)$\n- **PDF** (Probability Density Function): For continuous variables, $f(x)$\n\n**F1 analogy**: The PMF is like a grid of starting positions with the probability of each driver winning from that slot. The PDF is like the smooth curve of lap time variation \u2014 you can't ask \"what's the probability of exactly 1:31.204?\" but you can ask \"what's the probability of a lap between 1:31 and 1:32?\""
  },
  {
   "cell_type": "markdown",
   "source": "### Deep Dive: What is a Probability Distribution?\n\nA probability distribution answers a fundamental question: **\"What outcomes are possible, and how likely is each one?\"**\n\nThink of it as a complete recipe for uncertainty:\n- It lists every possible outcome\n- It assigns a probability (or density) to each outcome\n- All probabilities sum to 1 (something must happen!)\n\n**The Key Insight**: A distribution captures *everything* we know about a random process. Once you have the distribution, you can compute any probability, expectation, or uncertainty measure.\n\n**F1 analogy**: An F1 strategist's entire job is building probability distributions. Before a race, they model: the distribution of possible lap times on each tire compound, the probability of rain in each 10-minute window, the likelihood of a safety car on each lap. The team with the best distributions makes the best pit stop calls.\n\n#### Discrete vs Continuous Distributions\n\n| Aspect | Discrete | Continuous | F1 Example |\n|--------|----------|------------|------------|\n| **Possible values** | Countable (finite or infinite) | Uncountable (any value in a range) | Finishing position (1st-20th, DNF) vs. lap time (continuous) |\n| **Probability function** | PMF: P(X = x) gives exact probability | PDF: f(x) gives density, not probability | P(win from pole) = 0.45 vs. lap time density curve |\n| **Finding probabilities** | Sum: P(a \u2264 X \u2264 b) = \u03a3 P(X = x) | Integrate: P(a \u2264 X \u2264 b) = \u222bf(x)dx | P(podium) = P(1st) + P(2nd) + P(3rd) vs. P(lap < 1:32) |\n| **Examples** | Coin flips, dice, word counts | Height, temperature, neural network weights | Points scored, pit stops made vs. fuel load, tire degradation rate |\n| **ML applications** | Classification labels, token IDs | Regression targets, latent variables | Predicting race winner vs. predicting lap time |\n\n**Important**: For continuous distributions, P(X = x) = 0 for any specific value! We can only ask about ranges.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## 2. Common Distributions\n\n### 2.1 Bernoulli Distribution\n\nModels a single binary outcome (success/failure, yes/no, 1/0).\n\n$$P(X = 1) = p, \\quad P(X = 0) = 1 - p$$\n\n**In ML**: Binary classification outputs, dropout masks\n\n**F1 analogy**: Will the car finish the race? Every Grand Prix is a Bernoulli trial for each driver \u2014 they either finish (1) or DNF (0). A reliable car might have p = 0.95, while a fragile one has p = 0.70. Dropout in neural networks works the same way: each neuron is an \"engine component\" that randomly fails (is zeroed out) during training."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Bernoulli distribution \u2014 Will the car finish the race?\nfinish_probability = 0.7  # Probability of finishing (no DNF)\n\n# Generate samples: 1000 race starts\nrace_results = np.random.binomial(1, finish_probability, size=1000)\n\nprint(f\"Bernoulli(p={finish_probability}) \u2014 Car Finish Probability\")\nprint(f\"Mean (theoretical): {finish_probability}\")\nprint(f\"Mean (empirical): {race_results.mean():.3f}\")\nprint(f\"Variance (theoretical): {finish_probability * (1-finish_probability):.3f}\")\nprint(f\"Variance (empirical): {race_results.var():.3f}\")\n\n# Visualize\nplt.figure(figsize=(8, 4))\nplt.bar([0, 1], [1-finish_probability, finish_probability], width=0.4, alpha=0.7)\nplt.xticks([0, 1], ['DNF (0)', 'Finish (1)'])\nplt.ylabel('Probability')\nplt.title(f'Bernoulli Distribution: Will the Car Finish? (p={finish_probability})')\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 2.2 Binomial Distribution\n\nNumber of successes in $n$ independent Bernoulli trials.\n\n$$P(X = k) = \\binom{n}{k} p^k (1-p)^{n-k}$$\n\n**In ML**: Counting successes in multiple trials\n\n**F1 analogy**: If a driver enters 20 races in a season and has a 30% chance of finishing on the podium at each race, the binomial distribution tells us the probability of getting exactly k podiums across the season. \"How many points finishes will this driver collect over a 20-race calendar?\""
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Binomial distribution \u2014 Podium finishes in a season\nn_races = 20  # Races in the season\npodium_prob = 0.3  # Probability of podium at each race\n\n# PMF\nk = np.arange(0, n_races+1)\npmf = stats.binom.pmf(k, n_races, podium_prob)\n\nplt.figure(figsize=(10, 4))\nplt.bar(k, pmf, alpha=0.7)\nplt.xlabel('Number of Podium Finishes (k)')\nplt.ylabel('P(X = k)')\nplt.title(f'Binomial Distribution: Podiums in a {n_races}-Race Season (p={podium_prob})')\nplt.axvline(x=n_races*podium_prob, color='red', linestyle='--', label=f'Expected podiums = np = {n_races*podium_prob}')\nplt.legend()\nplt.show()\n\nprint(f\"Expected podiums: E[X] = np = {n_races*podium_prob}\")\nprint(f\"Variance: Var[X] = np(1-p) = {n_races*podium_prob*(1-podium_prob):.2f}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 2.3 Categorical Distribution\n\nGeneralization of Bernoulli to $K$ categories.\n\n$$P(X = k) = p_k, \\quad \\sum_{k=1}^K p_k = 1$$\n\n**In ML**: Multi-class classification (softmax output)\n\n**F1 analogy**: Predicting the race winner is a categorical distribution across all 20 drivers. The favorites might have P(Verstappen wins) = 0.40, P(Hamilton wins) = 0.25, and the remaining probability spread across the field. A softmax output in a neural network works exactly the same way \u2014 probabilities across categories that must sum to 1."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Categorical distribution \u2014 Predicting the race winner\nteams = ['Red Bull', 'Mercedes', 'Ferrari', 'McLaren']\nwin_probabilities = [0.4, 0.35, 0.15, 0.1]\n\n# Generate samples: simulate 1000 race outcomes\nrace_outcomes = np.random.choice(len(teams), size=1000, p=win_probabilities)\n\nplt.figure(figsize=(10, 4))\n\nplt.subplot(1, 2, 1)\nplt.bar(teams, win_probabilities, alpha=0.7, color='steelblue')\nplt.ylabel('Win Probability')\nplt.title('Pre-Race Win Probabilities (True)')\n\nplt.subplot(1, 2, 2)\nempirical_wins = [np.mean(race_outcomes == i) for i in range(len(teams))]\nplt.bar(teams, empirical_wins, alpha=0.7, color='coral')\nplt.ylabel('Win Frequency')\nplt.title('Simulated Race Wins (1000 races)')\n\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 2.4 Gaussian (Normal) Distribution\n\nThe most important continuous distribution.\n\n$$f(x) = \\frac{1}{\\sigma\\sqrt{2\\pi}} \\exp\\left(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right)$$\n\n**In ML**: \n- Weight initialization\n- Noise in VAEs\n- Regression targets\n- Batch normalization\n\n**F1 analogy**: Lap times follow an approximately normal distribution. A driver's laps cluster around their mean pace (mu), with some natural variation (sigma). A consistent driver has small sigma (tight lap time window), while an erratic driver has large sigma. The same math that describes lap time scatter also describes how neural network weights are initialized \u2014 small random values drawn from a Gaussian."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Gaussian distribution \u2014 Lap time variation\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\n# Different means = different drivers' average pace\nlap_time = np.linspace(85, 100, 200)  # Lap times in seconds\nfor mean_pace in [89, 91, 93, 95]:\n    axes[0].plot(lap_time, stats.norm.pdf(lap_time, mean_pace, 1), label=f'Mean pace={mean_pace}s, \u03c3=1s')\naxes[0].set_xlabel('Lap Time (seconds)')\naxes[0].set_ylabel('Density')\naxes[0].set_title('Effect of Mean Pace (\u03bc) \u2014 Different Drivers')\naxes[0].legend()\n\n# Different standard deviations = different consistency levels\nlap_time = np.linspace(84, 100, 200)\nfor consistency in [0.5, 1, 2, 3]:\n    axes[1].plot(lap_time, stats.norm.pdf(lap_time, 92, consistency), label=f'Mean=92s, \u03c3={consistency}s')\naxes[1].set_xlabel('Lap Time (seconds)')\naxes[1].set_ylabel('Density')\naxes[1].set_title('Effect of Consistency (\u03c3) \u2014 Same Driver, Different Conditions')\naxes[1].legend()\n\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# The 68-95-99.7 rule \u2014 Lap time consistency bands\nmu, sigma = 0, 1\nx = np.linspace(-4, 4, 200)\ny = stats.norm.pdf(x, mu, sigma)\n\nplt.figure(figsize=(10, 6))\nplt.plot(x, y, 'b-', linewidth=2)\n\n# Fill regions\nplt.fill_between(x, y, where=(x >= -3) & (x <= 3), alpha=0.2, color='blue', label='99.7% of laps (\u00b13\u03c3)')\nplt.fill_between(x, y, where=(x >= -2) & (x <= 2), alpha=0.3, color='blue', label='95% of laps (\u00b12\u03c3)')\nplt.fill_between(x, y, where=(x >= -1) & (x <= 1), alpha=0.4, color='blue', label='68% of laps (\u00b11\u03c3)')\n\nplt.xlabel('Deviation from Mean Lap Time (in standard deviations)')\nplt.ylabel('Density')\nplt.title('Lap Time Variation \u2014 The 68-95-99.7 Rule\\n\"68% of laps fall within \u00b11\u03c3 of the driver\\'s average pace\"')\nplt.legend()\nplt.show()\n\n# Verify with scipy\nprint(\"Probability within:\")\nprint(f\"  \u00b11\u03c3: {stats.norm.cdf(1) - stats.norm.cdf(-1):.4f} (68.27%)\")\nprint(f\"  \u00b12\u03c3: {stats.norm.cdf(2) - stats.norm.cdf(-2):.4f} (95.45%)\")\nprint(f\"  \u00b13\u03c3: {stats.norm.cdf(3) - stats.norm.cdf(-3):.4f} (99.73%)\")\nprint(\"\\nF1 insight: A lap outside \u00b13\u03c3 is almost certainly due to\")\nprint(\"traffic, an incident, or a mistake \u2014 not random variation.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 2.5 Multivariate Gaussian\n\nExtension to multiple dimensions:\n\n$$f(\\mathbf{x}) = \\frac{1}{(2\\pi)^{d/2}|\\Sigma|^{1/2}} \\exp\\left(-\\frac{1}{2}(\\mathbf{x}-\\boldsymbol{\\mu})^T \\Sigma^{-1} (\\mathbf{x}-\\boldsymbol{\\mu})\\right)$$\n\nWhere:\n- $\\boldsymbol{\\mu}$: Mean vector\n- $\\Sigma$: Covariance matrix\n\n**F1 analogy**: A single lap time is univariate Gaussian, but a car's full telemetry \u2014 speed, tire temperature, fuel load \u2014 follows a multivariate Gaussian. The covariance matrix captures how these variables relate: when tire temperature goes up, grip goes down (negative correlation). When fuel load drops, lap time improves (also correlated). Understanding these joint distributions is how teams optimize strategy across multiple interacting variables simultaneously."
  },
  {
   "cell_type": "markdown",
   "source": "### Choosing the Right Distribution: A Decision Guide\n\n| Distribution | Use When | Parameters | Example in ML | F1 Parallel |\n|--------------|----------|------------|---------------|-------------|\n| **Bernoulli** | Single yes/no outcome | p (success probability) | Binary classification output, dropout mask | Will the car finish the race? (finish/DNF) |\n| **Binomial** | Count of successes in n trials | n (trials), p (success prob) | Number of correct predictions in batch | How many podiums in a 20-race season? |\n| **Categorical** | Single choice from K options | p\u2081, p\u2082, ..., p\u2096 (probabilities) | Softmax output, token prediction | Which of the 20 drivers wins this race? |\n| **Multinomial** | Counts across K categories | n (trials), p\u2081...p\u2096 | Word counts in document (bag of words) | Finishing position counts across a season |\n| **Gaussian** | Continuous value, symmetric uncertainty | \u03bc (mean), \u03c3 (std dev) | Regression targets, weight initialization | Lap time variation around mean pace |\n| **Multivariate Gaussian** | Multiple correlated continuous values | \u03bc (mean vector), \u03a3 (covariance) | VAE latent space, GP predictions | Joint distribution of speed, tire temp, fuel load |\n\n**The Pattern**: \n- Bernoulli/Binomial are for binary outcomes (yes/no)\n- Categorical/Multinomial are for multi-class outcomes  \n- Gaussian is for continuous outcomes with symmetric uncertainty\n\n**Key ML Connection**: The distribution you choose for your model's output determines your loss function:\n- Categorical output \u2192 Cross-entropy loss\n- Gaussian output \u2192 MSE loss (equivalent to assuming Gaussian noise)",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 2D Gaussian \u2014 Joint distributions of car telemetry variables\nfig, axes = plt.subplots(1, 3, figsize=(15, 5))\n\n# Generate grid for contour plots\nx = np.linspace(-4, 4, 100)\ny = np.linspace(-4, 4, 100)\nX, Y = np.meshgrid(x, y)\npos = np.dstack((X, Y))\n\n# Different covariance matrices representing different telemetry relationships\ncovariances = [\n    (np.array([[1, 0], [0, 1]]), 'Independent Variables\\n(Speed vs. Fuel Load)'),\n    (np.array([[2, 0], [0, 0.5]]), 'Different Variances\\n(Speed varies more than Tire Temp)'),\n    (np.array([[1, 0.8], [0.8, 1]]), 'Correlated Variables\\n(Tire Temp vs. Degradation Rate)')\n]\n\nmean = np.array([0, 0])\n\nfor ax, (cov, title) in zip(axes, covariances):\n    rv = stats.multivariate_normal(mean, cov)\n    Z = rv.pdf(pos)\n    \n    ax.contour(X, Y, Z, levels=10, cmap='viridis')\n    \n    # Draw samples\n    samples = rv.rvs(size=200)\n    ax.scatter(samples[:, 0], samples[:, 1], alpha=0.3, s=10, color='red')\n    \n    ax.set_xlabel('Telemetry Variable 1')\n    ax.set_ylabel('Telemetry Variable 2')\n    ax.set_title(f'{title}\\n\u03a3 = {cov.tolist()}')\n    ax.set_aspect('equal')\n    ax.set_xlim(-4, 4)\n    ax.set_ylim(-4, 4)\n\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## 3. Expected Value and Variance\n\n### Expected Value (Mean)\n\nThe \"average\" outcome weighted by probability:\n\n- Discrete: $E[X] = \\sum_x x \\cdot P(X = x)$\n- Continuous: $E[X] = \\int x \\cdot f(x) dx$\n\n### Variance\n\nMeasures spread around the mean:\n\n$$\\text{Var}(X) = E[(X - E[X])^2] = E[X^2] - (E[X])^2$$\n\n**F1 analogy**: Expected value is the average championship points a driver earns from a given starting position. Starting from pole, E[points] might be 20 (weighted by probability of each finishing position). Variance measures how much the actual result varies \u2014 a driver who always finishes where they qualify has low variance, while one who either wins or DNFs has high variance. Teams use expected points calculations to evaluate strategy decisions: \"Does this pit stop gamble increase our expected points?\""
  },
  {
   "cell_type": "markdown",
   "source": "### Deep Dive: Understanding Each Term in Bayes' Theorem\n\n$$P(\\text{hypothesis}|\\text{data}) = \\frac{P(\\text{data}|\\text{hypothesis}) \\cdot P(\\text{hypothesis})}{P(\\text{data})}$$\n\nLet's break down what each term really means:\n\n| Term | Name | Meaning | Medical Example | F1 Example |\n|------|------|---------|-----------------|------------|\n| **P(H)** | Prior | Your belief *before* seeing any evidence | 1% of population has disease | 30% chance of rain before the race |\n| **P(D\\|H)** | Likelihood | How probable is this evidence *if* hypothesis is true? | 95% chance of positive test *if* you have disease | If it rains, 80% chance the track is wet by lap 10 |\n| **P(D)** | Evidence (Marginal) | Total probability of seeing this evidence | Overall rate of positive tests | Overall probability of a wet track by lap 10 |\n| **P(H\\|D)** | Posterior | Updated belief *after* seeing evidence | Probability you have disease *given* positive test | P(rain) *given* the track is wet at lap 10 |\n\n**The Core Insight**: Bayes' theorem is a *belief update* mechanism:\n```\nNew Belief = (How well evidence supports hypothesis) x (Old Belief) / (How common is this evidence)\n```\n\n**F1 analogy**: Every lap, the strategy team is running Bayes' theorem in their heads. Before the race: P(rain) = 30%. They see dark clouds forming: that's new evidence. P(dark clouds | rain) is high, P(dark clouds | no rain) is low. Their posterior P(rain | dark clouds) shoots up. Now they're preparing wet tires. This is exactly how Bayesian neural networks update their weight distributions given new training data.\n\n**Why the denominator matters**: P(D) normalizes everything. If positive tests are common (many false positives), a positive test is less informative.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Visual: How Bayes' Theorem Updates Beliefs\n# F1 scenario: Predicting rain during a race based on weather radar data\n\nfig, axes = plt.subplots(2, 2, figsize=(14, 10))\n\n# Setup \u2014 Using the medical testing example (the math is identical)\nP_disease = 0.01\nP_positive_given_disease = 0.95      # True positive rate\nP_positive_given_no_disease = 0.05   # False positive rate\n\n# Imagine 10,000 people\nn_people = 10000\nn_sick = int(n_people * P_disease)\nn_healthy = n_people - n_sick\n\n# Among sick people\nsick_test_positive = int(n_sick * P_positive_given_disease)\nsick_test_negative = n_sick - sick_test_positive\n\n# Among healthy people  \nhealthy_test_positive = int(n_healthy * P_positive_given_no_disease)\nhealthy_test_negative = n_healthy - healthy_test_positive\n\n# Plot 1: Prior - Population breakdown\nax = axes[0, 0]\nax.bar(['Sick', 'Healthy'], [n_sick, n_healthy], color=['red', 'green'], alpha=0.7)\nax.set_ylabel('Number of People')\nax.set_title(f'Step 1: PRIOR\\n{n_people:,} people: {n_sick} sick (1%), {n_healthy} healthy (99%)')\nax.set_ylim(0, n_people * 1.1)\nfor i, v in enumerate([n_sick, n_healthy]):\n    ax.text(i, v + 200, str(v), ha='center', fontweight='bold')\n\n# Plot 2: Likelihood - Test results by group\nax = axes[0, 1]\nx = np.arange(2)\nwidth = 0.35\nbars1 = ax.bar(x - width/2, [sick_test_positive, healthy_test_positive], width, \n               label='Test Positive', color='orange', alpha=0.7)\nbars2 = ax.bar(x + width/2, [sick_test_negative, healthy_test_negative], width,\n               label='Test Negative', color='blue', alpha=0.7)\nax.set_xticks(x)\nax.set_xticklabels(['Sick (100)', 'Healthy (9900)'])\nax.set_ylabel('Number of People')\nax.set_title('Step 2: LIKELIHOOD\\nHow the test performs on each group')\nax.legend()\n\n# Plot 3: Evidence - All positive tests\nax = axes[1, 0]\nax.bar(['True Positives\\n(Sick + Positive)', 'False Positives\\n(Healthy + Positive)'], \n       [sick_test_positive, healthy_test_positive], \n       color=['red', 'green'], alpha=0.7)\ntotal_positive = sick_test_positive + healthy_test_positive\nax.set_ylabel('Number of People')\nax.set_title(f'Step 3: EVIDENCE\\nAll positive tests: {total_positive} total\\n'\n             f'P(positive) = {total_positive/n_people:.2%}')\nfor i, v in enumerate([sick_test_positive, healthy_test_positive]):\n    ax.text(i, v + 10, str(v), ha='center', fontweight='bold')\n\n# Plot 4: Posterior - Among positive tests, who is actually sick?\nax = axes[1, 1]\nposterior = sick_test_positive / total_positive\nax.bar(['Actually Sick', 'Actually Healthy'], \n       [sick_test_positive, healthy_test_positive],\n       color=['red', 'green'], alpha=0.7)\nax.set_ylabel('Number of People (with positive test)')\nax.set_title(f'Step 4: POSTERIOR\\nAmong {total_positive} positive tests:\\n'\n             f'P(sick|positive) = {sick_test_positive}/{total_positive} = {posterior:.1%}')\nfor i, v in enumerate([sick_test_positive, healthy_test_positive]):\n    pct = v / total_positive * 100\n    ax.text(i, v + 10, f'{v} ({pct:.1f}%)', ha='center', fontweight='bold')\n\nplt.tight_layout()\nplt.suptitle('Bayes Theorem: Why a 95% Accurate Test Gives Only 16% Confidence\\n'\n             '(Same math applies: a 95% accurate rain radar still misleads when rain is rare)', \n             fontsize=14, fontweight='bold', y=1.02)\nplt.show()\n\nprint(\"\\nThe Counterintuitive Result Explained:\")\nprint(\"=\" * 50)\nprint(f\"Even though the test is 95% accurate:\")\nprint(f\"  - Out of {n_sick} sick people: {sick_test_positive} test positive\")\nprint(f\"  - Out of {n_healthy} healthy people: {healthy_test_positive} ALSO test positive (false positives)\")\nprint(f\"\\nTotal positive tests: {total_positive}\")\nprint(f\"True positives: {sick_test_positive} ({sick_test_positive/total_positive:.1%})\")\nprint(f\"False positives: {healthy_test_positive} ({healthy_test_positive/total_positive:.1%})\")\nprint(f\"\\nThe false positives OVERWHELM the true positives because\")\nprint(f\"healthy people vastly outnumber sick people!\")\nprint(f\"\\nF1 parallel: If your rain radar is 95% accurate but rain only happens\")\nprint(f\"5% of the time, most 'rain detected' alerts are false positives.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Computing expected value \u2014 Expected championship points from a grid position\n# Example: Points distribution from starting P3\nfinishing_positions = np.array([1, 2, 3, 4, 5, 6])\npoints_scored = np.array([25, 18, 15, 12, 10, 8])  # F1 points system\nposition_probabilities = np.array([0.1, 0.1, 0.1, 0.2, 0.2, 0.3])  # Biased toward lower positions\n\n# Expected points\nexpected_points = np.sum(points_scored * position_probabilities)\nprint(f\"E[Points] = \u03a3 points\u00b7P(position) = {expected_points}\")\n\n# Variance in points\nvariance_points = np.sum((points_scored - expected_points)**2 * position_probabilities)\nprint(f\"Var(Points) = E[(Points - E[Points])\u00b2] = {variance_points:.4f}\")\nprint(f\"Std(Points) = \u221aVar(Points) = {np.sqrt(variance_points):.4f}\")\n\n# Verify with sampling\nsampled_positions = np.random.choice(points_scored, size=10000, p=position_probabilities)\nprint(f\"\\nEmpirical mean points: {sampled_positions.mean():.4f}\")\nprint(f\"Empirical variance: {sampled_positions.var():.4f}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## 4. Bayes' Theorem\n\nBayes' theorem tells us how to update beliefs given new evidence:\n\n$$P(A|B) = \\frac{P(B|A) \\cdot P(A)}{P(B)}$$\n\nIn ML terms:\n\n$$P(\\text{hypothesis}|\\text{data}) = \\frac{P(\\text{data}|\\text{hypothesis}) \\cdot P(\\text{hypothesis})}{P(\\text{data})}$$\n\nOr:\n\n$$\\text{Posterior} = \\frac{\\text{Likelihood} \\times \\text{Prior}}{\\text{Evidence}}$$\n\n**F1 analogy**: Bayes' theorem is the mathematical backbone of real-time race strategy. Before the race, the team has a prior belief about tire degradation (say, 0.1s per lap). As laps unfold and actual lap times come in, they update this belief. If the driver's times are dropping faster than expected, the posterior shifts toward higher degradation \u2014 and the team calls an earlier pit stop. Every lap is new evidence, and the strategy wall is constantly computing posteriors."
  },
  {
   "cell_type": "markdown",
   "source": "### Bayes' Theorem in Machine Learning\n\nBayesian thinking is fundamental to many ML techniques:\n\n| Application | Prior P(H) | Likelihood P(D\\|H) | Posterior P(H\\|D) | F1 Parallel |\n|-------------|------------|-------------------|-------------------|-------------|\n| **Naive Bayes Classifier** | Class frequencies in training data | P(features\\|class) assumed independent | P(class\\|features) for prediction | Predicting tire compound from telemetry features |\n| **Bayesian Neural Networks** | Prior on weights (e.g., Gaussian) | P(data\\|weights) from network output | Distribution over weights given data | Uncertainty in lap time predictions |\n| **Bayesian Optimization** | GP prior over objective function | Observations so far | Updated belief about function | Finding optimal car setup (test limited configs) |\n| **Spam Filtering** | Base rate of spam emails | P(words\\|spam) and P(words\\|ham) | P(spam\\|email content) | Filtering valid telemetry from sensor noise |\n| **A/B Testing** | Prior belief about conversion rates | Observed clicks/conversions | Updated belief about which variant wins | Testing two setup configurations mid-weekend |\n\n**The Bayesian vs Frequentist Perspective**:\n- **Frequentist**: Parameters are fixed, unknown constants. We estimate them.\n- **Bayesian**: Parameters have probability distributions. We update our beliefs.\n\nIn deep learning, we're usually frequentist (point estimates via SGD), but Bayesian methods give us uncertainty quantification.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "### Deep Dive: The Intuition Behind Maximum Likelihood\n\n**The Core Question**: Given observed data, what parameters would have made this data *most probable*?\n\nImagine you flip a coin 10 times and get 7 heads. What's the \"most likely\" value of p (probability of heads)?\n\n**MLE answers**: Find the p that maximizes P(7 heads in 10 flips | p)\n\nThe answer is p = 0.7, because:\n- If p = 0.5, getting 7 heads is somewhat unlikely\n- If p = 0.9, getting only 7 heads (not 9) is unlikely\n- p = 0.7 makes our observed data most probable\n\n**F1 analogy**: Imagine you're an engineer trying to estimate the tire degradation rate from lap data. You observe lap times of 92.1, 92.3, 92.5, 92.8, 93.0 seconds over 5 laps. MLE asks: \"What degradation rate makes these observed lap times most probable?\" If you assume lap times increase linearly with degradation, MLE finds the slope that best fits the data \u2014 just like fitting a line through your lap time scatter plot.\n\n**Why Log-Likelihood?**\n1. Products become sums: log(a x b x c) = log(a) + log(b) + log(c)\n2. Numerical stability: Avoids underflow when multiplying many small probabilities\n3. Same maximum: log is monotonic, so argmax is preserved\n\n**The Profound Connection to Loss Functions**:\n\nFor classification with softmax outputs:\n$$\\text{Minimize Cross-Entropy} = \\text{Maximize Log-Likelihood}$$\n\nThey're the same optimization! When you train with cross-entropy loss, you're doing MLE.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Classic example: Safety car prediction\n# Safety cars occur in ~5% of race laps\n# Sensor detects incidents with 90% accuracy\n\nP_safety_car = 0.01  # Prior: probability of safety car on any given lap\nP_sensor_alert_given_incident = 0.95  # Sensitivity (true positive rate)\nP_sensor_alert_given_no_incident = 0.05  # False positive rate (1 - specificity)\n\n# P(alert) = P(alert|incident)P(incident) + P(alert|no incident)P(no incident)\nP_alert = P_sensor_alert_given_incident * P_safety_car + P_sensor_alert_given_no_incident * (1 - P_safety_car)\n\n# Bayes' theorem: P(incident|alert)\nP_incident_given_alert = (P_sensor_alert_given_incident * P_safety_car) / P_alert\n\nprint(\"F1 Safety Car Prediction (Same Math as Medical Testing)\")\nprint(\"=\" * 55)\nprint(f\"Prior P(safety car this lap) = {P_safety_car:.2%}\")\nprint(f\"Sensor sensitivity = {P_sensor_alert_given_incident:.2%}\")\nprint(f\"Sensor specificity = {1 - P_sensor_alert_given_no_incident:.2%}\")\nprint()\nprint(f\"P(sensor alert) = {P_alert:.4f}\")\nprint(f\"P(actual incident | sensor alert) = {P_incident_given_alert:.2%}\")\nprint()\nprint(\"Surprising! Even with an alert from a 95% accurate sensor,\")\nprint(f\"there's only a {P_incident_given_alert:.1%} chance of an actual safety car!\")\nprint(\"This is because incidents are rare on any given lap (low prior).\")"
  },
  {
   "cell_type": "code",
   "source": "# Demonstrating: Cross-Entropy Loss = Negative Log-Likelihood\n# This shows they're mathematically equivalent!\n\nprint(\"Cross-Entropy Loss vs Negative Log-Likelihood\")\nprint(\"=\" * 50)\n\n# Imagine a 3-class tire compound prediction problem\n# True label is Soft compound (class 0), model outputs these probabilities:\ntrue_compound = 0\nmodel_probs = np.array([0.7, 0.2, 0.1])  # Model is fairly confident it's Soft\n\n# Method 1: Cross-Entropy Loss (what we use in practice)\n# CE = -sum(y_true * log(y_pred)) where y_true is one-hot\none_hot = np.array([1, 0, 0])  # One-hot encoding of true compound (Soft)\ncross_entropy_val = -np.sum(one_hot * np.log(model_probs))\nprint(f\"\\nCross-Entropy Loss: -sum(y_true * log(y_pred))\")\nprint(f\"  = -({one_hot[0]} * log({model_probs[0]:.2f}) + {one_hot[1]} * log({model_probs[1]:.2f}) + {one_hot[2]} * log({model_probs[2]:.2f}))\")\nprint(f\"  = -{np.log(model_probs[0]):.4f}\")\nprint(f\"  = {cross_entropy_val:.4f}\")\n\n# Method 2: Negative Log-Likelihood (MLE perspective)\n# NLL = -log(P(true_class))\nneg_log_likelihood = -np.log(model_probs[true_compound])\nprint(f\"\\nNegative Log-Likelihood: -log(P(true_compound))\")\nprint(f\"  = -log({model_probs[true_compound]:.2f})\")\nprint(f\"  = {neg_log_likelihood:.4f}\")\n\nprint(f\"\\nThey're identical! CE = NLL = {cross_entropy_val:.4f}\")\nprint(\"\\nThis means: Training with cross-entropy loss is doing MLE!\")\nprint(\"We're finding network weights that maximize P(correct labels | inputs)\")\n\n# Show how loss changes with confidence\nprint(\"\\n\" + \"=\" * 50)\nprint(\"How loss varies with model confidence (predicting tire compound):\")\nprobs_for_true_compound = [0.1, 0.3, 0.5, 0.7, 0.9, 0.99]\nprint(f\"{'P(correct compound)':<22} {'Cross-Entropy Loss':<20}\")\nprint(\"-\" * 42)\nfor p in probs_for_true_compound:\n    loss = -np.log(p)\n    print(f\"{p:<22.2f} {loss:<20.4f}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Visualize how posterior changes with prior\n# F1 context: How P(rain | radar alert) changes with base rain probability\npriors = np.linspace(0.001, 0.5, 100)\nsensitivity = 0.95\nspecificity = 0.95\n\nposteriors = []\nfor prior in priors:\n    p_positive = sensitivity * prior + (1 - specificity) * (1 - prior)\n    posterior = (sensitivity * prior) / p_positive\n    posteriors.append(posterior)\n\nplt.figure(figsize=(10, 6))\nplt.plot(priors * 100, np.array(posteriors) * 100, 'b-', linewidth=2)\nplt.xlabel('Prior Probability [%]\\n(e.g., base rate of rain at this circuit)')\nplt.ylabel('Posterior Probability [%]\\n(e.g., P(rain | radar alert))')\nplt.title('How the Prior Affects the Posterior (95% Accurate Sensor)\\n'\n          'F1: Low base-rate rain circuits give more false alarms')\nplt.grid(True, alpha=0.3)\n\n# Mark some key points\nfor prior in [0.01, 0.1, 0.5]:\n    p_positive = sensitivity * prior + (1 - specificity) * (1 - prior)\n    posterior = (sensitivity * prior) / p_positive\n    plt.scatter([prior * 100], [posterior * 100], s=100, zorder=5)\n    plt.annotate(f'({prior*100:.0f}%, {posterior*100:.1f}%)', \n                 (prior * 100 + 1, posterior * 100 - 3))\n\nplt.show()"
  },
  {
   "cell_type": "code",
   "source": "# Interactive visualization: The Likelihood Surface\n# F1 context: Estimating mean lap time (mu) and consistency (sigma) from observed laps\n\nfig, axes = plt.subplots(1, 3, figsize=(15, 4))\n\n# Generate data from known distribution (simulated lap times)\nnp.random.seed(42)\ntrue_mean_lap = 3.0  # True mean (offset for math convenience)\ntrue_consistency = 1.5  # True sigma\nlap_times = np.random.normal(true_mean_lap, true_consistency, size=30)\n\n# Plot 1: 1D likelihood for mu (sigma fixed at true value)\nmus = np.linspace(0, 6, 100)\nlog_likelihoods_mu = [np.sum(stats.norm.logpdf(lap_times, mu, true_consistency)) for mu in mus]\n\naxes[0].plot(mus, log_likelihoods_mu, 'b-', linewidth=2)\naxes[0].axvline(x=lap_times.mean(), color='red', linestyle='--', label=f'MLE: {lap_times.mean():.2f}')\naxes[0].axvline(x=true_mean_lap, color='green', linestyle=':', label=f'True: {true_mean_lap}')\naxes[0].set_xlabel('Mean Lap Time (mu)')\naxes[0].set_ylabel('Log-Likelihood')\naxes[0].set_title('Likelihood vs. Mean Pace\\n(consistency fixed)')\naxes[0].legend()\n\n# Plot 2: 1D likelihood for sigma (mu fixed at true value)\nsigmas = np.linspace(0.5, 4, 100)\nlog_likelihoods_sigma = [np.sum(stats.norm.logpdf(lap_times, true_mean_lap, sigma)) for sigma in sigmas]\n\naxes[1].plot(sigmas, log_likelihoods_sigma, 'b-', linewidth=2)\naxes[1].axvline(x=lap_times.std(), color='red', linestyle='--', label=f'MLE: {lap_times.std():.2f}')\naxes[1].axvline(x=true_consistency, color='green', linestyle=':', label=f'True: {true_consistency}')\naxes[1].set_xlabel('Lap Time Consistency (sigma)')\naxes[1].set_ylabel('Log-Likelihood')\naxes[1].set_title('Likelihood vs. Consistency\\n(mean pace fixed)')\naxes[1].legend()\n\n# Plot 3: 2D likelihood surface\nmus_2d = np.linspace(1, 5, 50)\nsigmas_2d = np.linspace(0.5, 3, 50)\nMU, SIGMA = np.meshgrid(mus_2d, sigmas_2d)\n\nLL = np.zeros_like(MU)\nfor i in range(len(sigmas_2d)):\n    for j in range(len(mus_2d)):\n        LL[i, j] = np.sum(stats.norm.logpdf(lap_times, MU[i, j], SIGMA[i, j]))\n\ncontour = axes[2].contourf(MU, SIGMA, LL, levels=30, cmap='viridis')\naxes[2].scatter([lap_times.mean()], [lap_times.std()], color='red', s=150, marker='*', \n                label=f'MLE', zorder=5, edgecolors='white')\naxes[2].scatter([true_mean_lap], [true_consistency], color='white', s=100, marker='o',\n                label=f'True', zorder=5, edgecolors='black')\naxes[2].set_xlabel('Mean Lap Time (mu)')\naxes[2].set_ylabel('Consistency (sigma)')\naxes[2].set_title('2D Log-Likelihood Surface\\n(Finding best mu, sigma from lap data)')\naxes[2].legend()\nplt.colorbar(contour, ax=axes[2], label='Log-Likelihood')\n\nplt.tight_layout()\nplt.show()\n\nprint(\"Key Observations:\")\nprint(\"1. The likelihood surface has a clear peak (the MLE)\")\nprint(\"2. As we move away from the MLE, likelihood decreases\")\nprint(\"3. Gradient ascent on this surface finds the MLE\")\nprint(\"4. This is exactly what neural network training does!\")\nprint(\"\\nF1 insight: MLE finds the mean pace and consistency that best\")\nprint(\"explain the observed lap times \u2014 the same technique teams use\")\nprint(\"to estimate tire degradation rates from stint data.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Deep Dive: Understanding Entropy\n\nEntropy has several intuitive interpretations that all lead to the same formula:\n\n**Interpretation 1: Average Surprise**\n- \"Surprise\" of an event = -log P(event)\n- Rare events (low probability) are more surprising\n- Entropy = average surprise across all possible outcomes\n- H(X) = E[-log P(X)] = \"How surprised will I be on average?\"\n\n**Interpretation 2: Uncertainty**  \n- How uncertain are we about the outcome?\n- Maximum entropy = maximum uncertainty (uniform distribution)\n- Zero entropy = complete certainty (deterministic)\n\n**Interpretation 3: Information Content (Bits)**\n- \"How many yes/no questions do I need to identify the outcome?\"\n- Fair coin: 1 bit (one yes/no question: \"Was it heads?\")\n- Fair 4-sided die: 2 bits (\"Is it 1 or 2?\" then \"Is it the first of those two?\")\n- Biased distributions need fewer questions on average (can ask about likely outcomes first)\n\n**F1 analogy**: Entropy measures the **unpredictability of race results**. A season where one driver dominates (P(Verstappen wins) = 0.9) has low entropy \u2014 you're rarely surprised by the winner. A season with 5 competitive drivers splitting wins equally has high entropy \u2014 every race is a genuine surprise. This is exactly why fans call competitive seasons \"exciting\" \u2014 high entropy = high unpredictability = better entertainment. In ML, softmax temperature controls this same trade-off: low temperature = peaked distribution (confident), high temperature = flat distribution (uncertain).\n\n**Why log base 2?** \n- Gives entropy in \"bits\" - the number of binary questions\n- log base e gives \"nats\" (natural units)\n- They're proportional: 1 nat = 1.44 bits",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Visualizing Entropy as \"Average Surprise\"\n# Surprise of an event = -log2(P(event))\n# F1: How surprised are you when a particular driver wins?\n\nfig, axes = plt.subplots(1, 3, figsize=(15, 4))\n\n# Plot 1: Surprise function\nprobs = np.linspace(0.01, 1, 100)\nsurprise = -np.log2(probs)\n\naxes[0].plot(probs, surprise, 'b-', linewidth=2)\naxes[0].set_xlabel('P(driver wins)')\naxes[0].set_ylabel('Surprise = -log2(P(win))')\naxes[0].set_title('Surprise Function\\n\"How shocked are you by the race winner?\"')\naxes[0].grid(True, alpha=0.3)\naxes[0].annotate('Underdog wins!\\n(high surprise)', xy=(0.1, 3.3), fontsize=10)\naxes[0].annotate('Favorite wins\\n(low surprise)', xy=(0.7, 0.8), fontsize=10)\n\n# Plot 2: Entropy for different championship scenarios\ndistributions = {\n    'Dominant era\\n[1,0,0,0]': [1, 0, 0, 0],\n    'Clear favorite\\n[0.7,0.2,0.1,0]': [0.7, 0.2, 0.1, 0],\n    'Competitive\\n[0.4,0.3,0.2,0.1]': [0.4, 0.3, 0.2, 0.1],\n    'Wide open\\n[0.25,0.25,0.25,0.25]': [0.25, 0.25, 0.25, 0.25],\n}\n\nnames = list(distributions.keys())\nentropies = [entropy(p) for p in distributions.values()]\n\nbars = axes[1].bar(range(len(names)), entropies, color=['darkblue', 'blue', 'steelblue', 'lightblue'])\naxes[1].set_xticks(range(len(names)))\naxes[1].set_xticklabels(names, fontsize=9)\naxes[1].set_ylabel('Entropy (bits)')\naxes[1].set_title('Season Competitiveness = Entropy\\n\"How unpredictable is each race?\"')\naxes[1].set_ylim(0, 2.5)\nfor i, v in enumerate(entropies):\n    axes[1].text(i, v + 0.1, f'{v:.2f}', ha='center', fontweight='bold')\n\n# Plot 3: Why uniform has maximum entropy\n# Show entropy vs \"peakedness\" of distribution (like softmax temperature)\nalphas = np.linspace(0, 5, 50)\nscores = np.array([1, 2, 3, 4])  # Base driver ratings\n\nentropy_values = []\nfor alpha in alphas:\n    if alpha == 0:\n        probs = np.ones(4) / 4  # Uniform \u2014 anyone can win\n    else:\n        logits = alpha * scores\n        probs = np.exp(logits - logits.max())\n        probs = probs / probs.sum()\n    entropy_values.append(entropy(probs))\n\naxes[2].plot(alphas, entropy_values, 'b-', linewidth=2)\naxes[2].set_xlabel('Performance gap (lower = more equal)')\naxes[2].set_ylabel('Entropy (bits)')\naxes[2].set_title('Entropy vs. Field Competitiveness\\n(Like softmax temperature in ML)')\naxes[2].axhline(y=2, color='r', linestyle='--', alpha=0.5, label='Max entropy (anyone can win)')\naxes[2].legend()\naxes[2].grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Entropy Reference Table\n\n| Distribution | Formula | Entropy (bits) | Interpretation | F1 Parallel |\n|--------------|---------|----------------|----------------|-------------|\n| Fair coin | [0.5, 0.5] | 1.00 | 1 yes/no question needed | \"Will the car finish?\" \u2014 pure coin flip |\n| Biased coin (90/10) | [0.9, 0.1] | 0.47 | Less than 1 question on average | Reliable car: almost certainly finishes |\n| Certain outcome | [1, 0] | 0.00 | No uncertainty, no questions needed | Dominant driver: guaranteed win |\n| Fair 4-sided die | [0.25, 0.25, 0.25, 0.25] | 2.00 | 2 yes/no questions needed | 4-way title fight: any of them can win |\n| Fair 8-sided die | [1/8] * 8 | 3.00 | 3 yes/no questions needed | 8 competitive drivers: wide-open field |\n| Fair N-sided die | [1/N] * N | log2(N) | log2(N) questions needed | N equally-matched drivers |\n\n**Pattern**: For a uniform distribution over N outcomes, entropy = log2(N) bits.\n\n**Why Maximum Entropy = Uniform?**\n- Mathematically: Proven via Lagrange multipliers (maximizing H subject to sum = 1)\n- Intuitively: Any preference toward one outcome reduces average surprise\n- Philosophically: Maximum entropy = maximum ignorance = all outcomes equally plausible\n- In F1 terms: The most unpredictable season is when every driver has equal chance of winning",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Naive Bayes Classifier\n\nA simple but effective classifier using Bayes' theorem:\n\n$$P(y|x_1, ..., x_n) \\propto P(y) \\prod_{i=1}^n P(x_i|y)$$\n\nThe \"naive\" assumption is that features are conditionally independent given the class.\n\n**F1 analogy**: Imagine predicting which tire compound a driver is on (Soft/Medium/Hard) based on telemetry features: average speed, tire temperature, and lap time degradation rate. Naive Bayes assumes these features are independent given the compound \u2014 which isn't perfectly true (speed and degradation correlate), but it works surprisingly well in practice, just as it does in spam filtering and text classification."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Simple Naive Bayes from scratch\n# F1 context: Classifying tire compound from telemetry features\nclass NaiveBayesClassifier:\n    def __init__(self):\n        self.class_priors = {}\n        self.feature_params = {}  # (class, feature) -> (mean, std)\n        \n    def fit(self, X, y):\n        \"\"\"Fit Gaussian Naive Bayes.\"\"\"\n        classes = np.unique(y)\n        n_samples = len(y)\n        \n        for c in classes:\n            # Class prior\n            self.class_priors[c] = np.sum(y == c) / n_samples\n            \n            # Feature parameters (Gaussian)\n            X_c = X[y == c]\n            for j in range(X.shape[1]):\n                self.feature_params[(c, j)] = (X_c[:, j].mean(), X_c[:, j].std() + 1e-6)\n                \n    def predict_proba(self, X):\n        \"\"\"Compute class probabilities.\"\"\"\n        classes = list(self.class_priors.keys())\n        n_samples = X.shape[0]\n        probs = np.zeros((n_samples, len(classes)))\n        \n        for i, c in enumerate(classes):\n            # Start with log prior\n            log_prob = np.log(self.class_priors[c])\n            \n            # Add log likelihood for each feature\n            for j in range(X.shape[1]):\n                mean, std = self.feature_params[(c, j)]\n                log_prob += stats.norm.logpdf(X[:, j], mean, std)\n            \n            probs[:, i] = log_prob\n        \n        # Convert to probabilities (softmax of log probs)\n        probs = np.exp(probs - probs.max(axis=1, keepdims=True))\n        probs = probs / probs.sum(axis=1, keepdims=True)\n        \n        return probs\n    \n    def predict(self, X):\n        \"\"\"Predict class labels.\"\"\"\n        probs = self.predict_proba(X)\n        classes = list(self.class_priors.keys())\n        return np.array([classes[i] for i in probs.argmax(axis=1)])\n\n\n# Generate synthetic telemetry data (two tire compounds)\nnp.random.seed(42)\nn_samples = 200\n\n# Compound 0 (Hard): lower avg speed, lower degradation\nhard_compound_telemetry = np.random.randn(n_samples // 2, 2) + np.array([0, 0])\n# Compound 1 (Soft): higher avg speed, higher degradation\nsoft_compound_telemetry = np.random.randn(n_samples // 2, 2) + np.array([3, 3])\n\nX_telemetry = np.vstack([hard_compound_telemetry, soft_compound_telemetry])\ny_compound = np.array([0] * (n_samples // 2) + [1] * (n_samples // 2))\n\n# Train\nclf = NaiveBayesClassifier()\nclf.fit(X_telemetry, y_compound)\n\n# Predict\ny_pred = clf.predict(X_telemetry)\naccuracy = np.mean(y_pred == y_compound)\nprint(f\"Training accuracy: {accuracy:.2%}\")\n\n# Visualize decision boundary\nx_min, x_max = X_telemetry[:, 0].min() - 1, X_telemetry[:, 0].max() + 1\ny_min, y_max = X_telemetry[:, 1].min() - 1, X_telemetry[:, 1].max() + 1\nxx, yy = np.meshgrid(np.linspace(x_min, x_max, 100),\n                     np.linspace(y_min, y_max, 100))\nZ = clf.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n\nplt.figure(figsize=(10, 8))\nplt.contourf(xx, yy, Z, alpha=0.3, cmap='coolwarm')\nplt.scatter(X_telemetry[y_compound==0, 0], X_telemetry[y_compound==0, 1], c='blue', label='Hard Compound', edgecolors='k')\nplt.scatter(X_telemetry[y_compound==1, 0], X_telemetry[y_compound==1, 1], c='red', label='Soft Compound', edgecolors='k')\nplt.xlabel('Average Speed (normalized)')\nplt.ylabel('Tire Degradation Rate (normalized)')\nplt.title('Naive Bayes: Classifying Tire Compound from Telemetry')\nplt.legend()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "source": "### Deep Dive: Understanding KL Divergence\n\nKL divergence measures how \"different\" one distribution is from another. Here are multiple ways to understand it:\n\n**Interpretation 1: Extra Bits for Wrong Encoding**\n- Suppose you design a code optimized for distribution Q\n- But the true data comes from distribution P\n- KL(P || Q) = extra bits needed because you used the wrong distribution\n- If P = Q, you need exactly H(P) bits (optimal)\n- If P != Q, you need H(P) + KL(P||Q) bits (suboptimal)\n\n**Interpretation 2: Information Lost**\n- KL(P || Q) measures information lost when Q is used to approximate P\n- It's the \"distance\" from Q to P (but not symmetric!)\n\n**Interpretation 3: The Fundamental Relationship**\n$$D_{KL}(P || Q) = H(P, Q) - H(P) = \\text{Cross-Entropy} - \\text{Entropy}$$\n\nThis tells us:\n- Cross-entropy = cost of using Q to encode P\n- Entropy = minimum possible cost (using P itself)\n- KL divergence = the \"wasted\" bits from using Q instead of P\n\n**F1 analogy**: KL divergence measures **how different qualifying pace is from race pace**. If a team qualifies brilliantly but fades in the race (different distributions), the KL divergence between their qualifying and race performance is large. A team whose race pace mirrors qualifying (like Red Bull in a dominant season) has low KL divergence. In ML, this exact concept powers knowledge distillation \u2014 measuring how well the student model's distribution matches the teacher's.\n\n**Why Not Symmetric?**\n- KL(P || Q): Cost of using Q when truth is P\n- KL(Q || P): Cost of using P when truth is Q\n- These are different questions!",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Visualizing the KL = CrossEntropy - Entropy relationship\n# And demonstrating asymmetry\n# F1: Qualifying pace (P) vs Race pace (Q)\n\nfig, axes = plt.subplots(1, 3, figsize=(15, 4))\n\n# Example distributions: Qualifying vs Race performance\nquali_pace = np.array([0.6, 0.3, 0.1])  # Qualifying: strong at top positions\nrace_pace = np.array([0.33, 0.33, 0.34])  # Race: much more spread out\n\n# Calculate all quantities\nH_P = entropy(quali_pace)\nH_P_Q = cross_entropy(quali_pace, race_pace)  # Cross-entropy\nKL_P_Q = kl_divergence(quali_pace, race_pace)\n\n# Plot 1: Bar chart showing the relationship\nquantities = ['H(P)\\nEntropy', 'KL(P||Q)\\nDivergence', 'H(P,Q)\\nCross-Entropy']\nvalues = [H_P, KL_P_Q, H_P_Q]\ncolors = ['green', 'red', 'blue']\n\nbars = axes[0].bar(quantities, values, color=colors, alpha=0.7)\naxes[0].set_ylabel('Bits')\naxes[0].set_title('H(P,Q) = H(P) + KL(P||Q)\\nQuali vs Race Pace Gap')\n\n# Add value labels\nfor bar, val in zip(bars, values):\n    axes[0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.05, \n                 f'{val:.3f}', ha='center', fontweight='bold')\n\n# Verify the relationship\naxes[0].text(0.5, 0.85, f'{H_P:.3f} + {KL_P_Q:.3f} = {H_P + KL_P_Q:.3f}', \n             transform=axes[0].transAxes, ha='center', fontsize=11,\n             bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.5))\n\n# Plot 2: Asymmetry visualization\nP = np.array([0.9, 0.1])  # Dominant driver: almost always wins\nQ = np.array([0.5, 0.5])  # Equal competition\n\nkl_pq = kl_divergence(P, Q)\nkl_qp = kl_divergence(Q, P)\n\nx = np.arange(2)\nwidth = 0.35\n\naxes[1].bar(x - width/2, P, width, label='P (dominant era)', color='blue', alpha=0.7)\naxes[1].bar(x + width/2, Q, width, label='Q (equal field)', color='orange', alpha=0.7)\naxes[1].set_xticks(x)\naxes[1].set_xticklabels(['Win', 'Lose'])\naxes[1].set_ylabel('Probability')\naxes[1].set_title(f'KL Asymmetry\\nKL(P||Q)={kl_pq:.3f}, KL(Q||P)={kl_qp:.3f}')\naxes[1].legend()\n\n# Plot 3: Why asymmetry matters in practice\naxes[2].text(0.5, 0.85, 'KL(P || Q) vs KL(Q || P)', fontsize=14, fontweight='bold',\n             ha='center', transform=axes[2].transAxes)\n\nexplanation = \"\"\"\nKL(P || Q): \"How bad is Q as a model of P?\"\n- Averages over P (true distribution)\n- Catastrophic if Q gives 0 probability \n  where P has probability (log(0) = -inf!)\n- Used in: VAE loss, variational inference\n\nKL(Q || P): \"How bad is P as a model of Q?\"  \n- Averages over Q (approximate distribution)\n- Catastrophic if P gives 0 probability\n  where Q has probability\n- Used in: Reverse KL for mode-seeking\n\nIn classification:\n- P = true labels (one-hot), Q = model predictions\n- Cross-entropy = H(P) + KL(P||Q) = KL(P||Q)\n  (since H(P) = 0 for one-hot)\n\nF1: KL(quali || race) != KL(race || quali)\n\"How different is race pace from quali pace\"\nis NOT the same as the reverse!\n\"\"\"\n\naxes[2].text(0.05, 0.75, explanation, fontsize=9, transform=axes[2].transAxes,\n             verticalalignment='top', fontfamily='monospace')\naxes[2].axis('off')\n\nplt.tight_layout()\nplt.show()\n\nprint(\"Key Insight for Classification:\")\nprint(\"When true labels are one-hot, H(P) = 0\")\nprint(\"So: Cross-Entropy Loss = KL(true || predicted)\")\nprint(\"Minimizing cross-entropy = minimizing KL divergence!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Demonstrating KL divergence in Knowledge Distillation\n# F1 context: An experienced race engineer (teacher) training a junior (student)\n\n# Imagine a 5-class race outcome prediction problem\nrace_outcomes = ['Win', 'Podium', 'Points', 'No Points', 'DNF']\n\n# Hard label (ground truth: the driver won)\nhard_label = np.array([1, 0, 0, 0, 0])  # True outcome is 'Win'\n\n# Experienced engineer's prediction (teacher \u2014 soft, nuanced)\n# Notice: teacher thinks podium was likely too (car was competitive)\nsenior_engineer = np.array([0.7, 0.2, 0.05, 0.03, 0.02])\n\n# Junior engineer predictions at different training stages\njunior_untrained = np.array([0.2, 0.2, 0.2, 0.2, 0.2])  # Uniform (no insight)\njunior_learning = np.array([0.5, 0.15, 0.15, 0.1, 0.1])  # Developing intuition\njunior_trained = np.array([0.68, 0.18, 0.07, 0.04, 0.03])  # Well-calibrated\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\n# Plot 1: Compare distributions\nx = np.arange(len(race_outcomes))\nwidth = 0.2\n\naxes[0].bar(x - 1.5*width, hard_label, width, label='Hard Label (result)', color='red', alpha=0.7)\naxes[0].bar(x - 0.5*width, senior_engineer, width, label='Senior Engineer', color='blue', alpha=0.7)\naxes[0].bar(x + 0.5*width, junior_learning, width, label='Junior (learning)', color='green', alpha=0.7)\naxes[0].bar(x + 1.5*width, junior_trained, width, label='Junior (trained)', color='purple', alpha=0.7)\n\naxes[0].set_xticks(x)\naxes[0].set_xticklabels(race_outcomes)\naxes[0].set_ylabel('Probability')\naxes[0].set_title('Knowledge Distillation: Senior to Junior Engineer\\n\"Learning the nuance behind race outcomes\"')\naxes[0].legend()\n\n# Plot 2: KL divergences\njuniors = {\n    'Untrained': junior_untrained,\n    'Learning': junior_learning, \n    'Trained': junior_trained\n}\n\n# KL from hard labels (what standard cross-entropy uses)\nkl_hard = [kl_divergence(hard_label, s) for s in juniors.values()]\n\n# KL from senior engineer's soft labels (knowledge distillation)\nkl_soft = [kl_divergence(senior_engineer, s) for s in juniors.values()]\n\nx = np.arange(len(juniors))\nwidth = 0.35\n\naxes[1].bar(x - width/2, kl_hard, width, label='KL(Result || Junior)', color='red', alpha=0.7)\naxes[1].bar(x + width/2, kl_soft, width, label='KL(Senior || Junior)', color='blue', alpha=0.7)\naxes[1].set_xticks(x)\naxes[1].set_xticklabels(list(juniors.keys()))\naxes[1].set_ylabel('KL Divergence (bits)')\naxes[1].set_title('Loss: Hard Result vs Knowledge Distillation')\naxes[1].legend()\n\nplt.tight_layout()\nplt.show()\n\nprint(\"Why Soft Labels Help:\")\nprint(\"=\" * 50)\nprint(\"Hard label only says: 'The driver won this race'\")\nprint(\"Soft label says: 'The driver won, but podium was likely too,\")\nprint(\"                  DNF was very unlikely given car reliability'\")\nprint(\"\\nThe relationships between outcomes ('dark knowledge') help\")\nprint(\"the junior engineer develop better race intuition!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### KL Divergence in Machine Learning Applications\n\n| Application | P (True/Target) | Q (Approximate/Model) | What KL Measures | F1 Parallel |\n|-------------|-----------------|----------------------|------------------|-------------|\n| **Classification Loss** | One-hot labels | Softmax predictions | How wrong are predictions | How far model's race prediction is from actual result |\n| **VAE Loss** | Posterior q(z\\|x) | Prior p(z), usually N(0,1) | How far latent code is from prior | How far telemetry encoding is from baseline |\n| **Knowledge Distillation** | Teacher softmax | Student softmax | How well student mimics teacher | Junior engineer matching senior's race intuition |\n| **Policy Gradient (PPO)** | Old policy | New policy | Prevents too-large policy updates | Gradual strategy updates between races |\n| **Variational Inference** | True posterior | Variational approx | Quality of approximation | How well simplified model captures real tire behavior |\n\n**The VAE Loss Decomposition**:\n$$\\mathcal{L}_{VAE} = \\underbrace{-\\mathbb{E}_{q(z|x)}[\\log p(x|z)]}_{\\text{Reconstruction Loss}} + \\underbrace{D_{KL}(q(z|x) || p(z))}_{\\text{Regularization}}$$\n\nThe KL term pulls the encoder's latent distribution toward the prior, enabling generation.\n\n**Knowledge Distillation**:\n- Teacher: Large, accurate model with \"soft\" predictions\n- Student: Small model learning to match teacher\n- Loss = KL(Teacher || Student) on softmax outputs\n- Student learns teacher's \"dark knowledge\" (relationships between classes)",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## 5. Maximum Likelihood Estimation (MLE)\n\nMLE finds parameters that maximize the probability of observing the data:\n\n$$\\hat{\\theta}_{MLE} = \\arg\\max_\\theta P(\\text{data}|\\theta) = \\arg\\max_\\theta \\prod_i P(x_i|\\theta)$$\n\nIn practice, we maximize the **log-likelihood** (easier to work with):\n\n$$\\hat{\\theta}_{MLE} = \\arg\\max_\\theta \\sum_i \\log P(x_i|\\theta)$$\n\n**Key insight**: Minimizing cross-entropy loss = maximizing log-likelihood!\n\n**F1 analogy**: MLE is how teams estimate tire degradation rate from lap data. You observe a stint of 15 laps with gradually increasing times. MLE asks: \"What degradation rate per lap makes these observed times most probable?\" The answer is the slope of best fit through the lap time data. This is identical to how neural networks learn: find the parameters (weights) that make the training data most probable."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# MLE for Gaussian parameters \u2014 Estimating a driver's true pace\n# True parameters (unknown to us in practice)\ntrue_mean_pace = 5.0  # True mean lap time offset\ntrue_pace_sigma = 2.0  # True consistency\n\n# Generate observed lap times\nn_laps = 100\nobserved_laps = np.random.normal(true_mean_pace, true_pace_sigma, n_laps)\n\n# MLE estimates (can be derived analytically)\npace_mle = observed_laps.mean()  # Sample mean\nsigma_mle = observed_laps.std()  # Sample std (biased, but MLE)\n\nprint(f\"True parameters: mean pace = {true_mean_pace}, consistency = {true_pace_sigma}\")\nprint(f\"MLE estimates:   mean pace = {pace_mle:.3f}, consistency = {sigma_mle:.3f}\")\n\n# Visualize\nx = np.linspace(true_mean_pace - 4*true_pace_sigma, true_mean_pace + 4*true_pace_sigma, 100)\n\nplt.figure(figsize=(10, 6))\nplt.hist(observed_laps, bins=20, density=True, alpha=0.6, label='Observed lap times')\nplt.plot(x, stats.norm.pdf(x, true_mean_pace, true_pace_sigma), 'g-', linewidth=2, \n         label=f'True: N({true_mean_pace}, {true_pace_sigma}\u00b2)')\nplt.plot(x, stats.norm.pdf(x, pace_mle, sigma_mle), 'r--', linewidth=2,\n         label=f'MLE: N({pace_mle:.2f}, {sigma_mle:.2f}\u00b2)')\nplt.xlabel('Lap Time (offset from baseline)')\nplt.ylabel('Density')\nplt.title('MLE for Lap Time Distribution\\n\"Finding the driver\\'s true pace from observed data\"')\nplt.legend()\nplt.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Visualize the likelihood function \u2014 Finding the best-fit pace parameters\ndef log_likelihood(mu, sigma, data):\n    \"\"\"Compute log-likelihood of data under N(mu, sigma^2).\"\"\"\n    return np.sum(stats.norm.logpdf(data, mu, sigma))\n\n# Create grid of parameters\nmus = np.linspace(3, 7, 50)\nsigmas = np.linspace(1, 4, 50)\nMU, SIGMA = np.meshgrid(mus, sigmas)\n\n# Compute log-likelihood at each point\nLL = np.zeros_like(MU)\nfor i in range(len(sigmas)):\n    for j in range(len(mus)):\n        LL[i, j] = log_likelihood(MU[i, j], SIGMA[i, j], observed_laps)\n\nplt.figure(figsize=(10, 8))\nplt.contourf(MU, SIGMA, LL, levels=30, cmap='viridis')\nplt.colorbar(label='Log-Likelihood')\nplt.scatter([pace_mle], [sigma_mle], color='red', s=200, marker='*', \n            label=f'MLE: (pace={pace_mle:.2f}, consistency={sigma_mle:.2f})', zorder=5)\nplt.scatter([true_mean_pace], [true_pace_sigma], color='white', s=100, marker='o',\n            label=f'True: (pace={true_mean_pace}, consistency={true_pace_sigma})', zorder=5)\nplt.xlabel('Mean Lap Time (mu)')\nplt.ylabel('Consistency / Sigma')\nplt.title('Log-Likelihood Surface for Driver Pace Estimation\\n\"The peak is the MLE \u2014 the best estimate from observed laps\"')\nplt.legend()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### MLE for Bernoulli (Coin Flip / Race Finish)\n\nIf we observe $k$ heads in $n$ flips, the MLE estimate is simply:\n\n$$\\hat{p}_{MLE} = \\frac{k}{n}$$\n\n**F1 analogy**: If a car finishes 14 out of 20 races, the MLE estimate of its reliability is p = 14/20 = 0.70. Simple, elegant, and exactly how teams track reliability statistics."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# MLE for Bernoulli \u2014 Estimating car reliability from race finishes\nreliability_true = 0.7\nn_races = 50\nrace_finishes = np.random.binomial(1, reliability_true, n_races)\nn_finishes = race_finishes.sum()  # Number of races finished\n\nreliability_mle = n_finishes / n_races\n\nprint(f\"True reliability: {reliability_true}\")\nprint(f\"Observed: {n_finishes} finishes in {n_races} races\")\nprint(f\"MLE estimate: reliability = {reliability_mle:.3f}\")\n\n# Visualize likelihood function\np_values = np.linspace(0.01, 0.99, 100)\nlikelihoods = [stats.binom.pmf(n_finishes, n_races, p) for p in p_values]\n\nplt.figure(figsize=(10, 5))\nplt.plot(p_values, likelihoods, 'b-', linewidth=2)\nplt.axvline(x=reliability_mle, color='red', linestyle='--', label=f'MLE: reliability = {reliability_mle:.3f}')\nplt.axvline(x=reliability_true, color='green', linestyle=':', label=f'True: reliability = {reliability_true}')\nplt.xlabel('Reliability (p)')\nplt.ylabel('Likelihood P(data|p)')\nplt.title(f'Likelihood Function: {n_finishes} Finishes in {n_races} Race Starts\\n'\n          f'\"What reliability makes this season most probable?\"')\nplt.legend()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## 6. Information Theory\n\nInformation theory quantifies information and uncertainty.\n\n### Entropy\n\nEntropy measures the \"uncertainty\" or \"information content\" of a distribution:\n\n$$H(X) = -\\sum_x P(x) \\log P(x) = -E[\\log P(X)]$$\n\n**Properties**:\n- Higher entropy = more uncertainty\n- Uniform distribution has maximum entropy\n- Deterministic variable has entropy 0\n\n**F1 analogy**: Entropy is the **excitement level of a championship**. A season where one team dominates has low entropy (boring, predictable). A season with 5 teams in contention has high entropy (thrilling, unpredictable). The 2021 Hamilton-Verstappen title fight had much higher entropy than the 2023 Verstappen dominance. In ML, when your model's softmax output has high entropy, it means the model is uncertain about its prediction \u2014 just like a pundit who says \"anyone could win this race.\""
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def entropy(p):\n    \"\"\"Compute entropy of a discrete distribution.\"\"\"\n    p = np.array(p)\n    p = p[p > 0]  # Avoid log(0)\n    return -np.sum(p * np.log2(p))\n\n# F1 season competitiveness examples (in bits)\nprint(\"Entropy examples \u2014 Race/Season Unpredictability (in bits):\")\nprint(f\"Two equal rivals [0.5, 0.5]: H = {entropy([0.5, 0.5]):.4f} bits\")\nprint(f\"Dominant driver [0.9, 0.1]: H = {entropy([0.9, 0.1]):.4f} bits\")\nprint(f\"Certain winner [1.0, 0.0]: H = {entropy([1.0, 0.0]):.4f} bits\")\nprint(f\"Six equal drivers [1/6]*6: H = {entropy([1/6]*6):.4f} bits\")\nprint(f\"Eight-way fight [1/8]*8: H = {entropy([1/8]*8):.4f} bits\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Entropy of binary distribution as function of p\n# F1: How uncertain is a head-to-head title fight?\np_values = np.linspace(0.001, 0.999, 100)\nentropies = [-p * np.log2(p) - (1-p) * np.log2(1-p) for p in p_values]\n\nplt.figure(figsize=(10, 6))\nplt.plot(p_values, entropies, 'b-', linewidth=2)\nplt.xlabel('P(Driver A wins the championship)')\nplt.ylabel('Entropy (bits)')\nplt.title('Binary Entropy: Excitement of a Two-Way Title Fight\\n'\n          '\"Maximum drama when both drivers have equal chance\"')\nplt.axhline(y=1, color='r', linestyle='--', alpha=0.5, label='Maximum = 1 bit (50/50 fight)')\nplt.axvline(x=0.5, color='g', linestyle='--', alpha=0.5, label='p = 0.5 (equal)')\nplt.legend()\nplt.grid(True, alpha=0.3)\nplt.show()\n\nprint(\"Maximum entropy at p = 0.5 (maximum uncertainty / most exciting)\")\nprint(\"Entropy = 0 when p = 0 or p = 1 (championship already decided)\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Cross-Entropy\n\nCross-entropy measures the \"cost\" of using distribution $Q$ to encode samples from distribution $P$:\n\n$$H(P, Q) = -\\sum_x P(x) \\log Q(x) = -E_P[\\log Q(X)]$$\n\n**In ML**: Cross-entropy loss measures how well predicted probabilities $Q$ match true labels $P$.\n\n**F1 analogy**: Imagine you're a betting house using your model's race predictions (Q) to set odds, but the actual outcomes follow distribution P. Cross-entropy measures how much money you lose because your model doesn't perfectly match reality. The closer your predictions to truth, the lower the cross-entropy \u2014 and the less you lose."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def cross_entropy(p, q):\n    \"\"\"Compute cross-entropy H(P, Q).\"\"\"\n    p = np.array(p)\n    q = np.array(q)\n    # Avoid log(0) by clipping\n    q = np.clip(q, 1e-10, 1.0)\n    return -np.sum(p * np.log2(q))\n\n# Example: True race winner vs model predictions\n# True outcome: Driver A won (class 0)\ntrue_result = np.array([1, 0, 0])  # Driver A won\n\npredictions = [\n    ([0.9, 0.05, 0.05], \"Model confident in Driver A (correct!)\"),\n    ([0.6, 0.2, 0.2], \"Model leans toward A but unsure\"),\n    ([0.33, 0.33, 0.34], \"Model has no idea (uniform)\"),\n    ([0.1, 0.45, 0.45], \"Model confident in wrong driver\"),\n]\n\nprint(\"Cross-entropy loss for different race predictions:\")\nprint(f\"True result: Driver A wins (one-hot: {true_result})\\n\")\n\nfor q, desc in predictions:\n    ce = cross_entropy(true_result, q)\n    print(f\"{desc}\")\n    print(f\"  Prediction: {q}\")\n    print(f\"  Cross-entropy: {ce:.4f} bits\\n\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### KL Divergence\n\nKL divergence measures how different distribution $Q$ is from $P$:\n\n$$D_{KL}(P || Q) = \\sum_x P(x) \\log \\frac{P(x)}{Q(x)} = H(P, Q) - H(P)$$\n\n**Properties**:\n- $D_{KL}(P || Q) \\geq 0$ (always non-negative)\n- $D_{KL}(P || Q) = 0$ if and only if $P = Q$\n- Not symmetric: $D_{KL}(P || Q) \\neq D_{KL}(Q || P)$\n\n**In ML**: Used in VAEs, knowledge distillation, regularization\n\n**F1 analogy**: KL divergence measures how different two performance distributions are. If P is a team's qualifying pace distribution and Q is their race pace distribution, KL(P||Q) quantifies the \"qualifying-to-race translation gap.\" A team that's a qualifying specialist (fast in quali, slow in race) has high KL divergence between these distributions. A team whose race pace reliably mirrors qualifying has low KL divergence \u2014 they \"translate\" Saturday pace to Sunday."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def kl_divergence(p, q):\n    \"\"\"Compute KL divergence D_KL(P || Q).\"\"\"\n    p = np.array(p)\n    q = np.array(q)\n    # Only sum where p > 0\n    mask = p > 0\n    q = np.clip(q, 1e-10, 1.0)\n    return np.sum(p[mask] * np.log2(p[mask] / q[mask]))\n\n# Compare qualifying pace vs race pace distributions\nquali_dist = np.array([0.4, 0.3, 0.2, 0.1])  # Qualifying: tends to be at front\nrace_similar = np.array([0.35, 0.35, 0.2, 0.1])  # Race pace similar to quali\nrace_reversed = np.array([0.1, 0.2, 0.3, 0.4])  # Race pace: drops back (quali specialist)\nrace_uniform = np.array([0.25, 0.25, 0.25, 0.25])  # Race pace: anything can happen\n\nprint(f\"Qualifying distribution = {quali_dist}\")\nprint(f\"\\nKL divergences (how different is race pace from quali?):\")\nprint(f\"  Similar race pace    {race_similar}: {kl_divergence(quali_dist, race_similar):.4f} bits\")\nprint(f\"  Reversed (drops back) {race_reversed}: {kl_divergence(quali_dist, race_reversed):.4f} bits\")\nprint(f\"  Unpredictable race   {race_uniform}: {kl_divergence(quali_dist, race_uniform):.4f} bits\")\n\nprint(f\"\\nNote asymmetry (direction matters!):\")\nprint(f\"  KL(quali || reversed) = {kl_divergence(quali_dist, race_reversed):.4f}\")\nprint(f\"  KL(reversed || quali) = {kl_divergence(race_reversed, quali_dist):.4f}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Visualize KL divergence between two Gaussians\n# F1: How different is one driver's lap time distribution from another's?\ndef kl_gaussian(mu1, sigma1, mu2, sigma2):\n    \"\"\"KL divergence between two univariate Gaussians.\"\"\"\n    return (np.log(sigma2/sigma1) + \n            (sigma1**2 + (mu1 - mu2)**2) / (2 * sigma2**2) - 0.5)\n\n# Driver A's lap time distribution: N(0, 1) (baseline)\nmu_driver_a, sigma_driver_a = 0, 1\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\n# Vary mean pace difference\npace_offsets = np.linspace(-3, 3, 100)\nkls = [kl_gaussian(mu_driver_a, sigma_driver_a, mu, sigma_driver_a) for mu in pace_offsets]\n\naxes[0].plot(pace_offsets, kls, 'b-', linewidth=2)\naxes[0].set_xlabel('Driver B Mean Pace Difference (seconds)')\naxes[0].set_ylabel('KL Divergence (nats)')\naxes[0].set_title('KL Divergence: Same Consistency, Different Pace\\n'\n                   '\"How different is Driver B\\'s pace from Driver A?\"')\naxes[0].grid(True, alpha=0.3)\n\n# Vary consistency\nconsistencies = np.linspace(0.1, 4, 100)\nkls = [kl_gaussian(mu_driver_a, sigma_driver_a, mu_driver_a, sigma) for sigma in consistencies]\n\naxes[1].plot(consistencies, kls, 'r-', linewidth=2)\naxes[1].axvline(x=1, color='g', linestyle='--', alpha=0.5, label='Same consistency as A')\naxes[1].set_xlabel('Driver B Consistency (sigma, seconds)')\naxes[1].set_ylabel('KL Divergence (nats)')\naxes[1].set_title('KL Divergence: Same Pace, Different Consistency\\n'\n                   '\"How different is Driver B\\'s consistency?\"')\naxes[1].legend()\naxes[1].grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## Exercises\n\n### Exercise 1: Bayesian Tire Degradation Inference\n\nUse Bayes' theorem to update beliefs about a tire compound's degradation rate after observing lap times. Just as we used Beta-Binomial conjugacy for coin flips, we'll update our beliefs about the probability that tires are in \"high degradation\" mode based on observed performance drops."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Bayesian inference for tire degradation rate\n# Model: Each lap, we observe if there was a \"performance drop\" (1) or not (0)\n# Prior: Beta(a, b) distribution over the degradation probability p\n# Posterior after k drops in n laps: Beta(a + k, b + n - k)\n\ndef plot_beta_posterior(a_prior, b_prior, n_drops, n_clean_laps):\n    \"\"\"Plot prior and posterior distributions for degradation rate.\"\"\"\n    p = np.linspace(0, 1, 100)\n    \n    # Prior\n    prior = stats.beta.pdf(p, a_prior, b_prior)\n    \n    # Posterior\n    a_post = a_prior + n_drops\n    b_post = b_prior + n_clean_laps\n    posterior = stats.beta.pdf(p, a_post, b_post)\n    \n    plt.figure(figsize=(10, 6))\n    plt.plot(p, prior, 'b--', linewidth=2, label=f'Prior: Beta({a_prior}, {b_prior})')\n    plt.plot(p, posterior, 'r-', linewidth=2, \n             label=f'Posterior: Beta({a_post}, {b_post})')\n    plt.axvline(x=n_drops/(n_drops + n_clean_laps) if (n_drops + n_clean_laps) > 0 else 0.5, \n                color='g', linestyle=':', label=f'MLE: {n_drops/(n_drops + n_clean_laps):.3f}')\n    plt.xlabel('Degradation Rate (p = probability of performance drop per lap)')\n    plt.ylabel('Density')\n    plt.title(f'Bayesian Tire Degradation Inference: {n_drops} drops in {n_drops + n_clean_laps} laps')\n    plt.legend()\n    plt.show()\n    \n    # Posterior statistics\n    post_mean = a_post / (a_post + b_post)\n    print(f\"Posterior mean degradation rate: {post_mean:.4f}\")\n    print(f\"95% credible interval: [{stats.beta.ppf(0.025, a_post, b_post):.4f}, \"\n          f\"{stats.beta.ppf(0.975, a_post, b_post):.4f}]\")\n\n# Start with uniform prior (no prior knowledge about this tire compound)\n# Observe 7 laps with performance drops, 3 clean laps\nplot_beta_posterior(a_prior=1, b_prior=1, n_drops=7, n_clean_laps=3)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# TODO: Experiment with different priors and data\n# What happens with:\n# 1. Strong prior from testing data that tires are durable: Beta(10, 10)\n# 2. More race laps observed: 70 drops, 30 clean laps\n# 3. Prior from testing conflicts with race data (e.g., testing says durable but race says fragile)\n\n# Your experiments here:\n# Try: What if the team tested extensively and believed degradation was moderate?\nplot_beta_posterior(a_prior=10, b_prior=10, n_drops=7, n_clean_laps=3)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Exercise 2: Implement Softmax Cross-Entropy Loss for Race Outcome Prediction"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def softmax(x):\n    \"\"\"Compute softmax.\"\"\"\n    x_shifted = x - np.max(x, axis=-1, keepdims=True)\n    exp_x = np.exp(x_shifted)\n    return exp_x / np.sum(exp_x, axis=-1, keepdims=True)\n\ndef cross_entropy_loss(logits, labels):\n    \"\"\"\n    Compute cross-entropy loss for race outcome prediction.\n    \n    Args:\n        logits: Raw model outputs (before softmax), shape (batch_size, num_classes)\n               e.g., scores for [Win, Podium, Points, DNF]\n        labels: True outcome indices, shape (batch_size,)\n    \n    Returns:\n        Scalar loss value\n    \"\"\"\n    # TODO: Implement\n    # 1. Apply softmax to get probabilities\n    # 2. Extract probability of true outcome\n    # 3. Return negative log probability (averaged over batch)\n    \n    probs = softmax(logits)\n    batch_size = len(labels)\n    # Get probability assigned to correct outcome for each race\n    correct_probs = probs[np.arange(batch_size), labels]\n    # Negative log likelihood\n    loss = -np.mean(np.log(correct_probs + 1e-10))\n    return loss\n\n# Test: Predicting race outcomes for 3 different race weekends\n# Classes: [Win, Podium, Points finish]\nrace_logits = np.array([[2.0, 1.0, 0.1],   # Model thinks Win is likely\n                        [0.1, 2.5, 0.3],   # Model thinks Podium is likely\n                        [0.2, 0.3, 3.0]])  # Model thinks Points finish\ntrue_outcomes = np.array([0, 1, 2])  # Actual results: Win, Podium, Points\n\nloss = cross_entropy_loss(race_logits, true_outcomes)\nprint(f\"Race outcome logits:\\n{race_logits}\")\nprint(f\"Softmax probabilities:\\n{softmax(race_logits).round(4)}\")\nprint(f\"True outcomes: {true_outcomes} (Win=0, Podium=1, Points=2)\")\nprint(f\"Cross-entropy loss: {loss:.4f}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Exercise 3: Information Gain for Pit Stop Strategy Decisions\n\nIn decision trees, we split data to maximize information gain (reduction in entropy). Here, imagine you're deciding whether to split race laps into groups based on a feature (e.g., \"is it raining?\") to better predict outcomes. The split that gives the highest information gain is the most useful for the decision."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def information_gain(parent_labels, left_labels, right_labels):\n    \"\"\"\n    Compute information gain from a split.\n    \n    IG = H(parent) - weighted_avg(H(left), H(right))\n    \n    F1 context: Splitting race data by a condition (e.g., wet vs dry)\n    to better predict outcome (e.g., podium vs no podium).\n    \"\"\"\n    def label_entropy(labels):\n        \"\"\"Compute entropy of label distribution.\"\"\"\n        if len(labels) == 0:\n            return 0\n        _, counts = np.unique(labels, return_counts=True)\n        probs = counts / len(labels)\n        return entropy(probs)\n    \n    n = len(parent_labels)\n    n_left = len(left_labels)\n    n_right = len(right_labels)\n    \n    h_parent = label_entropy(parent_labels)\n    h_left = label_entropy(left_labels)\n    h_right = label_entropy(right_labels)\n    \n    weighted_child = (n_left/n) * h_left + (n_right/n) * h_right\n    \n    return h_parent - weighted_child\n\n# Example: Splitting race results by track condition\n# Parent: mixed results (4 podiums, 6 no-podiums)\nrace_results = np.array([0, 0, 0, 0, 1, 1, 1, 1, 1, 1])  # 0=no podium, 1=podium\n\n# Good split: \"Is it a dry race?\" separates podiums from non-podiums\ndry_races = np.array([0, 0, 0, 0])        # Dry: all no-podiums (clear pattern)\nwet_races = np.array([1, 1, 1, 1, 1, 1])  # Wet: all podiums (rain specialist!)\n\n# Bad split: Random grouping that doesn't separate outcomes\ngroup_a = np.array([0, 0, 1, 1, 1])  # Mixed outcomes\ngroup_b = np.array([0, 0, 1, 1, 1])  # Also mixed\n\nprint(f\"Parent entropy (all races): {entropy([0.4, 0.6]):.4f} bits\")\nprint(f\"\\nGood split (dry vs wet): IG = {information_gain(race_results, dry_races, wet_races):.4f} bits\")\nprint(f\"  -> Track condition perfectly separates outcomes!\")\nprint(f\"\\nBad split (random groups): IG = {information_gain(race_results, group_a, group_b):.4f} bits\")\nprint(f\"  -> No useful separation of outcomes\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## Summary\n\n### Key Concepts and Their F1 Parallels\n\n| Concept | What It Does | F1 Parallel |\n|---------|-------------|-------------|\n| **Probability Distributions** | Describe likelihood of all outcomes | Lap time distributions, race outcome probabilities |\n| **Bernoulli** | Models binary yes/no outcomes | Will the car finish this race? |\n| **Gaussian** | Models continuous symmetric uncertainty | Lap time variation around mean pace |\n| **Bayes' Theorem** | Updates beliefs given evidence (prior x likelihood = posterior) | Updating rain probability as clouds form during a race |\n| **Maximum Likelihood** | Finds parameters that maximize P(data\\|params) | Estimating tire degradation rate from observed lap times |\n| **Entropy** | Measures uncertainty in a distribution | Season competitiveness \u2014 high entropy = anyone can win |\n| **Cross-Entropy** | The loss function for classification | How wrong is your race prediction model? |\n| **KL Divergence** | Measures difference between distributions | Gap between qualifying pace and race pace |\n\n### Connection to Deep Learning\n\n- **Classification**: Softmax outputs a categorical distribution, trained with cross-entropy\n- **Regression**: Often assumes Gaussian noise, uses MSE (= MLE for Gaussian)\n- **VAEs**: Use KL divergence to regularize latent distributions\n- **Dropout**: Samples from Bernoulli to create masks\n- **Bayesian NN**: Treat weights as distributions, use Bayes' theorem\n\n### Checklist\n- [ ] I understand common probability distributions (and can map them to race scenarios)\n- [ ] I can apply Bayes' theorem (like updating rain predictions mid-race)\n- [ ] I understand MLE and its connection to loss functions (like fitting tire degradation curves)\n- [ ] I can compute entropy and KL divergence (like measuring season unpredictability)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "Continue to **Part 1.4: Classical Machine Learning** (Notebook 04), where we'll put probability and statistics to work with practical ML algorithms:\n",
    "- Decision trees, random forests, and gradient boosting\n",
    "- SVMs and kernel methods\n",
    "- Clustering (k-means, DBSCAN)\n",
    "- Model evaluation: cross-validation, ROC curves, confusion matrices\n",
    "- When to use classical ML vs deep learning\n",
    "\n",
    "**Looking ahead with F1**: The probability foundations from this notebook power everything ahead. When we build neural networks, softmax + cross-entropy (from this notebook) becomes our classification loss. When we explore VAEs, KL divergence becomes the regularizer. When we study reinforcement learning, Bayes' theorem helps the agent update its beliefs about the world."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}